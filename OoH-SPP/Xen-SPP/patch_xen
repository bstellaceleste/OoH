Seulement dans ./: .bash_history
Seulement dans ./: .cache
Seulement dans ./: classical_conf_file
Seulement dans ./config: Docs.mk
Seulement dans ./config: Paths.mk
Seulement dans ./config: Stubdom.mk
Seulement dans ./config: Tools.mk
Seulement dans ./config: Toplevel.mk
Seulement dans ./: config.log
Seulement dans ./: config.status
Seulement dans ./: dist
Seulement dans ./docs: config.status
Seulement dans ./docs/man: xl.cfg.pod.5
Seulement dans ./docs/man: xl.pod.1
Seulement dans ./extras/mini-os: .git
Seulement dans ./extras/mini-os/include: list.h
Seulement dans ./extras/mini-os/include: mini-os
Seulement dans ./extras/mini-os/include/x86: mini-os
Seulement dans ./extras: mini-os-remote
diff -aur ./.gitignore ./.gitignore
--- ./.gitignore	2017-12-13 12:37:59.000000000 +0100
+++ ./.gitignore	2020-11-13 20:14:48.000000000 +0100
@@ -170,26 +170,6 @@
 tools/helpers/_paths.h
 tools/helpers/init-xenstore-domain
 tools/helpers/xen-init-dom0
-tools/hotplug/common/hotplugpath.sh
-tools/hotplug/FreeBSD/rc.d/xencommons
-tools/hotplug/FreeBSD/rc.d/xendriverdomain
-tools/hotplug/Linux/init.d/sysconfig.xencommons
-tools/hotplug/Linux/init.d/sysconfig.xendomains
-tools/hotplug/Linux/init.d/xen-watchdog
-tools/hotplug/Linux/init.d/xencommons
-tools/hotplug/Linux/init.d/xendomains
-tools/hotplug/Linux/init.d/xendriverdomain
-tools/hotplug/Linux/launch-xenstore
-tools/hotplug/Linux/systemd/*.conf
-tools/hotplug/Linux/systemd/*.mount
-tools/hotplug/Linux/systemd/*.socket
-tools/hotplug/Linux/systemd/*.service
-tools/hotplug/Linux/vif-setup
-tools/hotplug/Linux/xen-backend.rules
-tools/hotplug/Linux/xen-hotplug-common.sh
-tools/hotplug/Linux/xendomains
-tools/hotplug/NetBSD/rc.d/xencommons
-tools/hotplug/NetBSD/rc.d/xendriverdomain
 tools/include/acpi
 tools/include/xen/*
 tools/include/xen-xsm/*
@@ -239,7 +219,6 @@
 tools/tests/x86_emulator/test_x86_emulator
 tools/tests/x86_emulator/x86_emulate
 tools/tests/xen-access/xen-access
-tools/tests/xenstore/xs-test
 tools/tests/regression/installed/*
 tools/tests/regression/build/*
 tools/tests/regression/downloads/*
@@ -347,12 +326,6 @@
 tools/firmware/rombios/_rombios_.c
 tools/firmware/rombios/rombios.s
 tools/firmware/rombios/rombios.sym
-tools/include/xen-foreign/checker.c
-tools/include/xen-foreign/structs.pyc
-tools/include/xen-foreign/x86_32.h
-tools/include/xen-foreign/x86_64.h
-tools/include/xen-foreign/arm32.h
-tools/include/xen-foreign/arm64.h
 
 .git
 tools/misc/xen-hptool
Seulement dans ./: patch_xen
Seulement dans ./: README.md
Seulement dans ./: spp.patch
Seulement dans ./stubdom: config.log
Seulement dans ./stubdom: config.status
Seulement dans ./stubdom: grub-0.97.tar.gz
Seulement dans ./stubdom: grub-upstream
Seulement dans ./stubdom: lwip-1.3.0.tar.gz
Seulement dans ./stubdom: lwip-x86_32
Seulement dans ./stubdom: lwip-x86_64
Seulement dans ./stubdom: newlib-1.16.0
Seulement dans ./stubdom: newlib-1.16.0.tar.gz
Seulement dans ./stubdom: pciutils-2.2.9.tar.bz2
Seulement dans ./stubdom: polarssl-1.1.4-gpl.tgz
Seulement dans ./stubdom: zlib-1.2.3.tar.gz
Seulement dans ./: .sudo_as_admin_successful
Seulement dans ./tools: config.h
Seulement dans ./tools: config.log
Seulement dans ./tools: config.status
Seulement dans ./tools/firmware: seabios-dir
Seulement dans ./tools/firmware: seabios-dir-remote
Seulement dans ./tools/fuzz/x86_instruction_emulator: asm
Seulement dans ./tools/fuzz/x86_instruction_emulator: x86_emulate
Seulement dans ./tools/fuzz/x86_instruction_emulator: x86-emulate.c
Seulement dans ./tools/fuzz/x86_instruction_emulator: x86-emulate.h
Seulement dans ./tools/hotplug/FreeBSD/rc.d: xencommons
Seulement dans ./tools/hotplug/FreeBSD/rc.d: xendriverdomain
Seulement dans ./tools/hotplug/Linux/init.d: sysconfig.xencommons
Seulement dans ./tools/hotplug/Linux/init.d: sysconfig.xendomains
Seulement dans ./tools/hotplug/Linux/init.d: xencommons
Seulement dans ./tools/hotplug/Linux/init.d: xendomains
Seulement dans ./tools/hotplug/Linux/init.d: xendriverdomain
Seulement dans ./tools/hotplug/Linux/init.d: xen-watchdog
Seulement dans ./tools/hotplug/Linux: launch-xenstore
Seulement dans ./tools/hotplug/Linux/systemd: proc-xen.mount
Seulement dans ./tools/hotplug/Linux/systemd: var-lib-xenstored.mount
Seulement dans ./tools/hotplug/Linux/systemd: xenconsoled.service
Seulement dans ./tools/hotplug/Linux/systemd: xendomains.service
Seulement dans ./tools/hotplug/Linux/systemd: xendriverdomain.service
Seulement dans ./tools/hotplug/Linux/systemd: xen-init-dom0.service
Seulement dans ./tools/hotplug/Linux/systemd: xen-qemu-dom0-disk-backend.service
Seulement dans ./tools/hotplug/Linux/systemd: xenstored.service
Seulement dans ./tools/hotplug/Linux/systemd: xen-watchdog.service
Seulement dans ./tools/hotplug/Linux: vif-setup
Seulement dans ./tools/hotplug/Linux: xendomains
Seulement dans ./tools/hotplug/Linux: xen-hotplug-common.sh
Seulement dans ./tools/hotplug/NetBSD/rc.d: xencommons
Seulement dans ./tools/hotplug/NetBSD/rc.d: xendriverdomain
diff -aur ./tools/include/xen-foreign/reference.size ./tools/include/xen-foreign/reference.size
--- ./tools/include/xen-foreign/reference.size	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/include/xen-foreign/reference.size	2020-11-13 20:14:48.000000000 +0100
@@ -10,5 +10,5 @@
 vcpu_time_info            |      32      32      32      32
 vcpu_info                 |      48      48      64      64
 arch_shared_info          |       0       0      28      48
-shared_info               |    1088    1088    2344    3136
+shared_info               |    1096    1096    2348    3144
 
Seulement dans ./tools/libs/toolcore/include: _xentoolcore_list.h
diff -aur ./tools/libxc/include/xenctrl.h ./tools/libxc/include/xenctrl.h
--- ./tools/libxc/include/xenctrl.h	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/libxc/include/xenctrl.h	2020-11-13 20:14:48.000000000 +0100
@@ -459,6 +459,8 @@
 } xc_dominfo_t;
 
 typedef xen_domctl_getdomaininfo_t xc_domaininfo_t;
+//typedef xen_domctl_vtf_pids_t xc_vtf_pidinfo_t;
+typedef xen_sysctl_vtf_getcpuinfo_t xc_vtf_cpuinfo_t; 
 
 typedef union 
 {
@@ -2592,7 +2594,7 @@
  * The operations are asynchronous and the hypervisor may take a while
  * to complete them. The `timeout` offers an option to expire the
  * operation if it could not be completed within the specified time
- * (in ns). Value of 0 means let hypervisor decide the best timeout.
+ * (in ns). Value of 0 means let hypervisor decide the best timeout. 
  */
 int xc_livepatch_apply(xc_interface *xch, char *name, uint32_t timeout);
 int xc_livepatch_revert(xc_interface *xch, char *name, uint32_t timeout);
@@ -2607,6 +2609,13 @@
 int xc_domain_cacheflush(xc_interface *xch, uint32_t domid,
                          xen_pfn_t start_pfn, xen_pfn_t nr_pfns);
 
+
+int xc_vtf(xc_interface *xch, int arg, xc_vtf_cpuinfo_t *xcinfo, char *hw, uint32_t pid_list[25]);
+int xc_domain_enable_logdirty(xc_interface *xch, uint32_t dom, int is_vtf, uint32_t pid_list[25]);
+int xc_domain_disable_logdirty(xc_interface *xch, uint32_t dom, int is_vtf, uint32_t pid_list[25]);
+int xc_collect_dirty_logs(xc_interface *xch, uint32_t dom);
+int xc_clean_dirty_bitmap(xc_interface *xch, uint32_t dom);
+
 /* Compat shims */
 #include "xenctrl_compat.h"
 
Seulement dans ./tools/libxc: _xc_cpuid_autogen.h
diff -aur ./tools/libxc/xc_domain.c ./tools/libxc/xc_domain.c
--- ./tools/libxc/xc_domain.c	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/libxc/xc_domain.c	2020-11-13 20:14:48.000000000 +0100
@@ -23,9 +23,25 @@
 #include "xc_core.h"
 #include "xg_private.h"
 #include "xg_save_restore.h"
+
 #include <xen/memory.h>
 #include <xen/hvm/hvm_op.h>
 
+#include <sched.h>
+#include <unistd.h>
+#include <sys/resource.h>
+#include <sys/ioctl.h>
+
+//#define SCHED_NORMAL 0
+#define SCHED_VTF 7
+
+/* Definitions related to ioctl when enabling PML */
+#define UIO_DEVICE "/dev/uio0" /* Think of passing this trough arguments */
+/****************************/
+#define IO_MAGIC_PML 'a'
+#define IO_ENABLE_PML _IOW(IO_MAGIC_PML, 0, int) //_IOW('a', 'a', uint32_t)
+#define IO_DISABLE_PML _IOW(IO_MAGIC_PML, 1, int)
+
 int xc_domain_create(xc_interface *xch, uint32_t ssidref,
                      xen_domain_handle_t handle, uint32_t flags,
                      uint32_t *pdomid, xc_domain_configuration_t *config)
@@ -686,6 +702,7 @@
 
     memset(&domctl, 0, sizeof(domctl));
 
+    //domctl.u.vtf.cmd.action = 0;
     domctl.cmd = XEN_DOMCTL_shadow_op;
     domctl.domain = domid;
     domctl.u.shadow_op.op     = sop;
@@ -2433,8 +2450,197 @@
     DECLARE_DOMCTL;
     domctl.cmd = XEN_DOMCTL_soft_reset;
     domctl.domain = domid;
-    return do_domctl(xch, &domctl);
+    return do_domctl(xch, &domctl); 
+}
+
+int xc_vtf(xc_interface *xch, int arg, xc_vtf_cpuinfo_t *xcinfo, char *hw, uint32_t pid_list[25])
+{
+    int ret = 0; 
+    uint32_t dom = -1;
+    //int uiofd, priority, pid;
+
+    DECLARE_SYSCTL;
+    DECLARE_HYPERCALL_BOUNCE(xcinfo, sizeof(*xcinfo), XC_HYPERCALL_BUFFER_BOUNCE_OUT);
+    printf("xc_vtf\n");
+    switch (arg)
+    {
+    case 1: //vtf list
+        if ( xc_hypercall_bounce_pre(xch, xcinfo) )
+            return -1;
+         
+        sysctl.cmd = XEN_SYSCTL_vtf;
+        sysctl.u.vtf.check = 1;
+        sysctl.u.vtf.cmd.action = XEN_SYSCTL_vtf_action_list;
+        set_xen_guest_handle(sysctl.u.vtf.buffer, xcinfo);
+        ret = xc_sysctl(xch, &sysctl); 
+        xc_hypercall_bounce_post(xch, xcinfo);
+        break;
+
+    case 2: //vtf enabole
+        if (!strcmp(hw, "PML"))
+        {
+            /*for (int i = 0; pid_list[i] != (int)(uintptr_t)NULL && i < 25; i++)
+            {
+                priority = getpriority(PRIO_PROCESS, pid_list[i]);
+
+                if (priority != -1)
+                {
+                    const struct sched_param sp = {
+                        .sched_priority = priority,
+                    };
+                    ret = sched_setscheduler(pid_list[i], SCHED_VTF, &sp);
+
+                    // try to send this pid to the module via ioctl 
+                    uiofd = open(UIO_DEVICE, O_RDWR); //
+                    if (uiofd < 0)
+                    {
+                        fprintf(stderr, "Cannot open %s: %s\n", UIO_DEVICE, strerror(errno));
+                        return -1;
+                    }
+
+                    pid = pid_list[i];
+                    ioctl(uiofd, IO_ENABLE_PML, &pid);
+
+                    close(uiofd);
+                }
+            }*/
+            ret = xc_domain_enable_logdirty(xch, dom, 1, pid_list);
+        }
+        else if (!strcmp(hw, "EPT"))
+        {
+        }
+
+        break;
+
+    case 3: //vtf disable
+        if (!strcmp(hw, "PML"))
+        {
+            /*for (int i = 0; pid_list[i] != (int)(uintptr_t)NULL && i < 25; i++)
+            {
+                pid = pid_list[i];
+
+                uiofd = open(UIO_DEVICE, O_RDWR); //
+                if (uiofd < 0)
+                {
+                    fprintf(stderr, "Cannot open %s: %s\n", UIO_DEVICE, strerror(errno));
+                    return -1;
+                }
+                
+                ioctl(uiofd, IO_DISABLE_PML, &pid);
+
+                close(uiofd);
+            }*/
+            ret = xc_domain_disable_logdirty(xch, dom, 1, pid_list);
+        }
+        else if (!strcmp(hw, "EPT"))
+        {
+        }
+
+        break;
+    }
+
+    return ret;
+}
+
+int xc_domain_enable_logdirty(xc_interface *xch, uint32_t dom, int is_vtf, uint32_t pid_list[25])
+{
+    int rc;//, i=0; 
+    DECLARE_DOMCTL;
+    memset(&domctl, 0, sizeof(domctl));
+
+    printf("xc_domain_enable_logdirty\n");
+    
+    if(is_vtf) {
+        memcpy(domctl.u.vtf.pids, pid_list, 25*sizeof(int));    
+        domctl.cmd = XEN_DOMCTL_vtf;
+        domctl.u.vtf.hw = XEN_DOMCTL_vtf_hw_PML;
+    }
+    else 
+    {
+        domctl.cmd = XEN_DOMCTL_shadow_op;
+        domctl.domain = (domid_t)dom;
+    }
+
+    domctl.u.shadow_op.op     = XEN_DOMCTL_SHADOW_OP_ENABLE_LOGDIRTY;
+
+    rc = do_domctl(xch, &domctl);
+
+    return rc;
+}
+
+int xc_domain_disable_logdirty(xc_interface *xch, uint32_t dom, int is_vtf, uint32_t pid_list[25])
+{
+    int rc;
+    DECLARE_DOMCTL;
+    memset(&domctl, 0, sizeof(domctl));
+
+    if(is_vtf) {
+        memcpy(domctl.u.vtf.pids, pid_list, 25*sizeof(int));  
+        domctl.cmd = XEN_DOMCTL_vtf;
+        domctl.u.vtf.hw = XEN_DOMCTL_vtf_hw_PML;
+    }
+    else 
+    {
+        domctl.cmd = XEN_DOMCTL_shadow_op;
+        domctl.domain = (domid_t)dom;
+    }
+
+    domctl.u.shadow_op.op     = XEN_DOMCTL_SHADOW_OP_OFF;
+
+    rc = do_domctl(xch, &domctl);
+
+    return rc;
 }
+
+int xc_collect_dirty_logs(xc_interface *xch, uint32_t dom)
+{
+    int rc;
+    unsigned long p2m_size=1045504;
+    xen_pfn_t nr_pfns;
+    unsigned long *db=malloc(sizeof(unsigned long) * p2m_size);
+
+    DECLARE_DOMCTL;
+    DECLARE_HYPERCALL_BOUNCE(db, p2m_size * sizeof(*db), XC_HYPERCALL_BUFFER_BOUNCE_OUT);
+    memset(&domctl, 0, sizeof(domctl));
+
+    if(xc_domain_nr_gpfns(xch, (domid_t)dom, &nr_pfns)<0)
+    {
+        PERROR("Unable to obtain p2m_size");
+        //goto out;
+    }
+
+    domctl.cmd = XEN_DOMCTL_shadow_op;
+    domctl.domain = (domid_t)dom;
+    domctl.u.shadow_op.op     = XEN_DOMCTL_SHADOW_OP_PEEK;
+    domctl.u.shadow_op.pages  = p2m_size;
+    set_xen_guest_handle(domctl.u.shadow_op.dirty_bitmap, db);
+
+    rc = do_domctl(xch, &domctl);
+    xc_hypercall_bounce_post(xch, db);
+    
+    //out:
+      //  return rc;
+    return rc;
+}
+
+int xc_clean_dirty_bitmap(xc_interface *xch, uint32_t dom)
+{
+    int rc;
+    unsigned long p2m_size=1045504;
+
+    DECLARE_DOMCTL;
+    memset(&domctl, 0, sizeof(domctl));
+
+    domctl.cmd = XEN_DOMCTL_shadow_op;
+    domctl.domain = (domid_t)dom;
+    domctl.u.shadow_op.op     = XEN_DOMCTL_SHADOW_OP_CLEAN;
+    domctl.u.shadow_op.pages  = p2m_size;
+
+    rc = do_domctl(xch, &domctl);
+
+    return rc;
+}
+
 /*
  * Local variables:
  * mode: C
diff -aur ./tools/libxc/xc_misc.c ./tools/libxc/xc_misc.c
--- ./tools/libxc/xc_misc.c	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/libxc/xc_misc.c	2020-11-13 20:14:48.000000000 +0100
@@ -214,6 +214,9 @@
     int ret;
     DECLARE_SYSCTL;
 
+    if(put_info->vtf_cmd)
+        sysctl.u.vtf.check = True;
+
     sysctl.cmd = XEN_SYSCTL_physinfo;
 
     memcpy(&sysctl.u.physinfo, put_info, sizeof(*put_info));
diff -aur ./tools/libxc/xc_sr_restore.c ./tools/libxc/xc_sr_restore.c
--- ./tools/libxc/xc_sr_restore.c	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/libxc/xc_sr_restore.c	2020-11-13 20:14:48.000000000 +0100
@@ -745,6 +745,7 @@
     do
     {
         rc = read_record(ctx, ctx->fd, &rec);
+
         if ( rc )
         {
             if ( ctx->restore.buffer_all_records )
@@ -784,6 +785,7 @@
         }
 
     } while ( rec.type != REC_TYPE_END );
+    
 
  remus_failover:
 
diff -aur ./tools/libxc/xc_sr_save.c ./tools/libxc/xc_sr_save.c
--- ./tools/libxc/xc_sr_save.c	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/libxc/xc_sr_save.c	2020-11-13 20:14:48.000000000 +0100
@@ -52,7 +52,7 @@
 static int write_end_record(struct xc_sr_context *ctx)
 {
     struct xc_sr_record end = { REC_TYPE_END, 0, NULL };
-
+    
     return write_record(ctx, &end);
 }
 
@@ -938,10 +938,13 @@
             }
         }
     } while ( ctx->save.checkpointed != XC_MIG_STREAM_NONE );
+    
 
     xc_report_progress_single(xch, "End of stream");
 
     rc = write_end_record(ctx);
+
+
     if ( rc )
         goto err;
 
diff -aur ./tools/libxl/libxl.c ./tools/libxl/libxl.c
--- ./tools/libxl/libxl.c	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/libxl/libxl.c	2020-11-13 20:14:48.000000000 +0100
@@ -357,7 +357,11 @@
     int rc;
     long l;
     GC_INIT(ctx);
-
+    
+    if(physinfo->domain_unpriv){
+       xcphysinfo.vtf_cmd = 1;
+       //printf("%d\n", (int)xcphysinfo.vtf_cmd);
+    }
     rc = xc_physinfo(ctx->xch, &xcphysinfo);
     if (rc != 0) {
         LOGE(ERROR, "getting physinfo");
@@ -775,6 +779,39 @@
         (*dst)[i] = (*src)[i];
 }
 
+int libxl_vtf(libxl_ctx *ctx, int arg, char *hw, uint32_t pid_list[25])
+{
+    int ret = 0;
+    xc_vtf_cpuinfo_t xcinfo;
+    
+    GC_INIT(ctx); 
+     
+    switch (arg)
+    {
+    case 1:
+        ret = xc_vtf(ctx->xch, arg, &xcinfo, hw, pid_list);
+        printf("VMX: Supported advanced features:\n");
+        if(xcinfo.pml)
+            printf("   - PML: Page Modification Logging.\n");
+        if(xcinfo.ept)
+            printf("   - EPT: Extended Page Table.\n");
+        break;
+
+    case 2:
+    case 3:
+        //printf("libxl_vtf --- arg = %d\n", arg);
+        ret = xc_vtf(ctx->xch, arg, &xcinfo, hw, pid_list);
+        break;
+    
+    default:
+        break;
+    }
+
+    GC_FREE;
+
+    return ret;
+}
+
 /*
  * Local variables:
  * mode: C
diff -aur ./tools/libxl/libxl_domain.c ./tools/libxl/libxl_domain.c
--- ./tools/libxl/libxl_domain.c	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/libxl/libxl_domain.c	2020-11-13 20:14:48.000000000 +0100
@@ -1733,6 +1733,30 @@
     return rc;
 }
 
+int libxl_domain_enable_logdirty(libxl_ctx *ctx, uint32_t domid)
+{
+    int ret;
+    GC_INIT(ctx);
+
+    printf("libxl_enable_logdirty: libxl_domain.c\n");
+    ret = xc_domain_enable_logdirty(ctx->xch, domid, 0, NULL);
+    GC_FREE;
+
+    return ret;
+}
+
+int libxl_domain_disable_logdirty(libxl_ctx *ctx, uint32_t domid)
+{
+    int ret;
+    GC_INIT(ctx);
+
+    printf("libxl_disable_logdirty: libxl_domain.c\n");
+    ret = xc_domain_disable_logdirty(ctx->xch, domid, 0, NULL);
+    GC_FREE;
+
+    return ret;
+}
+
 /*
  * Local variables:
  * mode: C
diff -aur ./tools/libxl/libxl.h ./tools/libxl/libxl.h
--- ./tools/libxl/libxl.h	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/libxl/libxl.h	2020-11-13 20:14:48.000000000 +0100
@@ -2320,6 +2320,13 @@
 int libxl_qemu_monitor_command(libxl_ctx *ctx, uint32_t domid,
                                const char *command_line, char **output);
 
+
+int libxl_vtf(libxl_ctx *ctx, int arg, char *hw, uint32_t pid_list[25]);
+int libxl_domain_disable_logdirty(libxl_ctx *ctx, uint32_t domid);
+int libxl_domain_enable_logdirty(libxl_ctx *ctx, uint32_t domid);
+int libxl_collect_dirty_logs(libxl_ctx *ctx, uint32_t domid);
+int libxl_clean_dirty_bitmap(libxl_ctx *ctx, uint32_t domid);
+
 #include <libxl_event.h>
 
 #endif /* LIBXL_H */
diff -aur ./tools/libxl/libxl_internal.h ./tools/libxl/libxl_internal.h
--- ./tools/libxl/libxl_internal.h	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/libxl/libxl_internal.h	2020-11-13 20:14:48.000000000 +0100
@@ -4281,7 +4281,7 @@
 void libxl__xcinfo2xlinfo(libxl_ctx *ctx,
                           const xc_domaininfo_t *xcinfo,
                           libxl_dominfo *xlinfo);
-
+                          
 /* Macros used to compare device identifier. Returns true if the two
  * devices have same identifier. */
 #define COMPARE_DEVID(a, b) ((a)->devid == (b)->devid)
diff -aur ./tools/libxl/libxl_mem.c ./tools/libxl/libxl_mem.c
--- ./tools/libxl/libxl_mem.c	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/libxl/libxl_mem.c	2020-11-13 20:14:48.000000000 +0100
@@ -593,6 +593,30 @@
     return rc;
 }
 
+int libxl_collect_dirty_logs(libxl_ctx *ctx, uint32_t domid)
+{
+    int ret;
+    GC_INIT(ctx);
+
+    //printf("libxl_collect_dirty_logs: libxl_mem.c\n");
+    ret = xc_collect_dirty_logs(ctx->xch, domid);
+    GC_FREE;
+
+    return ret;
+}
+
+int libxl_clean_dirty_bitmap(libxl_ctx *ctx, uint32_t domid)
+{
+    int ret;
+    GC_INIT(ctx);
+
+    //printf("libxl_collect_dirty_logs: libxl_mem.c\n");
+    ret = xc_clean_dirty_bitmap(ctx->xch, domid);
+    GC_FREE;
+
+    return ret;
+}
+
 /*
  * Local variables:
  * mode: C
diff -aur ./tools/libxl/libxl_save_helper.c ./tools/libxl/libxl_save_helper.c
--- ./tools/libxl/libxl_save_helper.c	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/libxl/libxl_save_helper.c	2020-11-13 20:14:48.000000000 +0100
@@ -294,6 +294,8 @@
                               console_domid, hvm, pae,
                               stream_type,
                               &helper_restore_callbacks, send_back_fd);
+        
+
         helper_stub_restore_results(store_mfn,console_mfn,0);
         complete(r);
 
diff -aur ./tools/libxl/libxl_types.idl ./tools/libxl/libxl_types.idl
--- ./tools/libxl/libxl_types.idl	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/libxl/libxl_types.idl	2020-11-13 20:14:48.000000000 +0100
@@ -43,6 +43,11 @@
 # Constants / Enumerations
 #
 
+libxl_domain_unpriv = Enumeration("domain_unpriv", [
+    (0, "DOM0"),
+    (1, "DOMU"),
+])
+
 libxl_error = Enumeration("error", [
     (-1, "NONSPECIFIC"),
     (-2, "VERSION"),
@@ -901,6 +906,7 @@
     ], dir=DIR_OUT)
 
 libxl_physinfo = Struct("physinfo", [
+    ("domain_unpriv", libxl_domain_unpriv),
     ("threads_per_core", uint32),
     ("cores_per_socket", uint32),
 
diff -aur ./tools/libxl/libxlu_cfg_l.c ./tools/libxl/libxlu_cfg_l.c
--- ./tools/libxl/libxlu_cfg_l.c	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/libxl/libxlu_cfg_l.c	2020-11-13 20:14:48.000000000 +0100
@@ -8,12 +8,246 @@
 
 #define FLEX_SCANNER
 #define YY_FLEX_MAJOR_VERSION 2
-#define YY_FLEX_MINOR_VERSION 5
-#define YY_FLEX_SUBMINOR_VERSION 39
+#define YY_FLEX_MINOR_VERSION 6
+#define YY_FLEX_SUBMINOR_VERSION 4
 #if YY_FLEX_SUBMINOR_VERSION > 0
 #define FLEX_BETA
 #endif
 
+#ifdef yy_create_buffer
+#define xlu__cfg_yy_create_buffer_ALREADY_DEFINED
+#else
+#define yy_create_buffer xlu__cfg_yy_create_buffer
+#endif
+
+#ifdef yy_delete_buffer
+#define xlu__cfg_yy_delete_buffer_ALREADY_DEFINED
+#else
+#define yy_delete_buffer xlu__cfg_yy_delete_buffer
+#endif
+
+#ifdef yy_scan_buffer
+#define xlu__cfg_yy_scan_buffer_ALREADY_DEFINED
+#else
+#define yy_scan_buffer xlu__cfg_yy_scan_buffer
+#endif
+
+#ifdef yy_scan_string
+#define xlu__cfg_yy_scan_string_ALREADY_DEFINED
+#else
+#define yy_scan_string xlu__cfg_yy_scan_string
+#endif
+
+#ifdef yy_scan_bytes
+#define xlu__cfg_yy_scan_bytes_ALREADY_DEFINED
+#else
+#define yy_scan_bytes xlu__cfg_yy_scan_bytes
+#endif
+
+#ifdef yy_init_buffer
+#define xlu__cfg_yy_init_buffer_ALREADY_DEFINED
+#else
+#define yy_init_buffer xlu__cfg_yy_init_buffer
+#endif
+
+#ifdef yy_flush_buffer
+#define xlu__cfg_yy_flush_buffer_ALREADY_DEFINED
+#else
+#define yy_flush_buffer xlu__cfg_yy_flush_buffer
+#endif
+
+#ifdef yy_load_buffer_state
+#define xlu__cfg_yy_load_buffer_state_ALREADY_DEFINED
+#else
+#define yy_load_buffer_state xlu__cfg_yy_load_buffer_state
+#endif
+
+#ifdef yy_switch_to_buffer
+#define xlu__cfg_yy_switch_to_buffer_ALREADY_DEFINED
+#else
+#define yy_switch_to_buffer xlu__cfg_yy_switch_to_buffer
+#endif
+
+#ifdef yypush_buffer_state
+#define xlu__cfg_yypush_buffer_state_ALREADY_DEFINED
+#else
+#define yypush_buffer_state xlu__cfg_yypush_buffer_state
+#endif
+
+#ifdef yypop_buffer_state
+#define xlu__cfg_yypop_buffer_state_ALREADY_DEFINED
+#else
+#define yypop_buffer_state xlu__cfg_yypop_buffer_state
+#endif
+
+#ifdef yyensure_buffer_stack
+#define xlu__cfg_yyensure_buffer_stack_ALREADY_DEFINED
+#else
+#define yyensure_buffer_stack xlu__cfg_yyensure_buffer_stack
+#endif
+
+#ifdef yylex
+#define xlu__cfg_yylex_ALREADY_DEFINED
+#else
+#define yylex xlu__cfg_yylex
+#endif
+
+#ifdef yyrestart
+#define xlu__cfg_yyrestart_ALREADY_DEFINED
+#else
+#define yyrestart xlu__cfg_yyrestart
+#endif
+
+#ifdef yylex_init
+#define xlu__cfg_yylex_init_ALREADY_DEFINED
+#else
+#define yylex_init xlu__cfg_yylex_init
+#endif
+
+#ifdef yylex_init_extra
+#define xlu__cfg_yylex_init_extra_ALREADY_DEFINED
+#else
+#define yylex_init_extra xlu__cfg_yylex_init_extra
+#endif
+
+#ifdef yylex_destroy
+#define xlu__cfg_yylex_destroy_ALREADY_DEFINED
+#else
+#define yylex_destroy xlu__cfg_yylex_destroy
+#endif
+
+#ifdef yyget_debug
+#define xlu__cfg_yyget_debug_ALREADY_DEFINED
+#else
+#define yyget_debug xlu__cfg_yyget_debug
+#endif
+
+#ifdef yyset_debug
+#define xlu__cfg_yyset_debug_ALREADY_DEFINED
+#else
+#define yyset_debug xlu__cfg_yyset_debug
+#endif
+
+#ifdef yyget_extra
+#define xlu__cfg_yyget_extra_ALREADY_DEFINED
+#else
+#define yyget_extra xlu__cfg_yyget_extra
+#endif
+
+#ifdef yyset_extra
+#define xlu__cfg_yyset_extra_ALREADY_DEFINED
+#else
+#define yyset_extra xlu__cfg_yyset_extra
+#endif
+
+#ifdef yyget_in
+#define xlu__cfg_yyget_in_ALREADY_DEFINED
+#else
+#define yyget_in xlu__cfg_yyget_in
+#endif
+
+#ifdef yyset_in
+#define xlu__cfg_yyset_in_ALREADY_DEFINED
+#else
+#define yyset_in xlu__cfg_yyset_in
+#endif
+
+#ifdef yyget_out
+#define xlu__cfg_yyget_out_ALREADY_DEFINED
+#else
+#define yyget_out xlu__cfg_yyget_out
+#endif
+
+#ifdef yyset_out
+#define xlu__cfg_yyset_out_ALREADY_DEFINED
+#else
+#define yyset_out xlu__cfg_yyset_out
+#endif
+
+#ifdef yyget_leng
+#define xlu__cfg_yyget_leng_ALREADY_DEFINED
+#else
+#define yyget_leng xlu__cfg_yyget_leng
+#endif
+
+#ifdef yyget_text
+#define xlu__cfg_yyget_text_ALREADY_DEFINED
+#else
+#define yyget_text xlu__cfg_yyget_text
+#endif
+
+#ifdef yyget_lineno
+#define xlu__cfg_yyget_lineno_ALREADY_DEFINED
+#else
+#define yyget_lineno xlu__cfg_yyget_lineno
+#endif
+
+#ifdef yyset_lineno
+#define xlu__cfg_yyset_lineno_ALREADY_DEFINED
+#else
+#define yyset_lineno xlu__cfg_yyset_lineno
+#endif
+
+#ifdef yyget_column
+#define xlu__cfg_yyget_column_ALREADY_DEFINED
+#else
+#define yyget_column xlu__cfg_yyget_column
+#endif
+
+#ifdef yyset_column
+#define xlu__cfg_yyset_column_ALREADY_DEFINED
+#else
+#define yyset_column xlu__cfg_yyset_column
+#endif
+
+#ifdef yywrap
+#define xlu__cfg_yywrap_ALREADY_DEFINED
+#else
+#define yywrap xlu__cfg_yywrap
+#endif
+
+#ifdef yyget_lval
+#define xlu__cfg_yyget_lval_ALREADY_DEFINED
+#else
+#define yyget_lval xlu__cfg_yyget_lval
+#endif
+
+#ifdef yyset_lval
+#define xlu__cfg_yyset_lval_ALREADY_DEFINED
+#else
+#define yyset_lval xlu__cfg_yyset_lval
+#endif
+
+#ifdef yyget_lloc
+#define xlu__cfg_yyget_lloc_ALREADY_DEFINED
+#else
+#define yyget_lloc xlu__cfg_yyget_lloc
+#endif
+
+#ifdef yyset_lloc
+#define xlu__cfg_yyset_lloc_ALREADY_DEFINED
+#else
+#define yyset_lloc xlu__cfg_yyset_lloc
+#endif
+
+#ifdef yyalloc
+#define xlu__cfg_yyalloc_ALREADY_DEFINED
+#else
+#define yyalloc xlu__cfg_yyalloc
+#endif
+
+#ifdef yyrealloc
+#define xlu__cfg_yyrealloc_ALREADY_DEFINED
+#else
+#define yyrealloc xlu__cfg_yyrealloc
+#endif
+
+#ifdef yyfree
+#define xlu__cfg_yyfree_ALREADY_DEFINED
+#else
+#define yyfree xlu__cfg_yyfree
+#endif
+
 /* First, we deal with  platform-specific or compiler-specific issues. */
 
 /* begin standard C headers. */
@@ -84,40 +318,32 @@
 #define UINT32_MAX             (4294967295U)
 #endif
 
+#ifndef SIZE_MAX
+#define SIZE_MAX               (~(size_t)0)
+#endif
+
 #endif /* ! C99 */
 
 #endif /* ! FLEXINT_H */
 
-#ifdef __cplusplus
-
-/* The "const" storage-class-modifier is valid. */
-#define YY_USE_CONST
+/* begin standard C++ headers. */
 
-#else	/* ! __cplusplus */
-
-/* C99 requires __STDC__ to be defined as 1. */
-#if defined (__STDC__)
-
-#define YY_USE_CONST
-
-#endif	/* defined (__STDC__) */
-#endif	/* ! __cplusplus */
-
-#ifdef YY_USE_CONST
+/* TODO: this is always defined, so inline it */
 #define yyconst const
+
+#if defined(__GNUC__) && __GNUC__ >= 3
+#define yynoreturn __attribute__((__noreturn__))
 #else
-#define yyconst
+#define yynoreturn
 #endif
 
 /* Returned upon end-of-file. */
 #define YY_NULL 0
 
-/* Promotes a possibly negative, possibly signed char to an unsigned
- * integer for use as an array index.  If the signed char is negative,
- * we want to instead treat it as an 8-bit unsigned char, hence the
- * double cast.
+/* Promotes a possibly negative, possibly signed char to an
+ *   integer in range [0..255] for use as an array index.
  */
-#define YY_SC_TO_UI(c) ((unsigned int) (unsigned char) c)
+#define YY_SC_TO_UI(c) ((YY_CHAR) (c))
 
 /* An opaque pointer. */
 #ifndef YY_TYPEDEF_YY_SCANNER_T
@@ -141,20 +367,16 @@
  * definition of BEGIN.
  */
 #define BEGIN yyg->yy_start = 1 + 2 *
-
 /* Translate the current start state into a value that can be later handed
  * to BEGIN to return to the state.  The YYSTATE alias is for lex
  * compatibility.
  */
 #define YY_START ((yyg->yy_start - 1) / 2)
 #define YYSTATE YY_START
-
 /* Action number for EOF rule of a given start state. */
 #define YY_STATE_EOF(state) (YY_END_OF_BUFFER + state + 1)
-
 /* Special action meaning "start processing a new file". */
-#define YY_NEW_FILE xlu__cfg_yyrestart(yyin ,yyscanner )
-
+#define YY_NEW_FILE yyrestart( yyin , yyscanner )
 #define YY_END_OF_BUFFER_CHAR 0
 
 /* Size of default input buffer. */
@@ -187,10 +409,10 @@
 #define EOB_ACT_CONTINUE_SCAN 0
 #define EOB_ACT_END_OF_FILE 1
 #define EOB_ACT_LAST_MATCH 2
-
+    
     /* Note: We specifically omit the test for yy_rule_can_match_eol because it requires
      *       access to the local variable yy_act. Since yyless() is a macro, it would break
-     *       existing scanners that call yyless() from OUTSIDE xlu__cfg_yylex. 
+     *       existing scanners that call yyless() from OUTSIDE yylex.
      *       One obvious solution it to make yy_act a global. I tried that, and saw
      *       a 5% performance hit in a non-yylineno scanner, because yy_act is
      *       normally declared as a register variable-- so it is not worth it.
@@ -223,7 +445,6 @@
 		YY_DO_BEFORE_ACTION; /* set up yytext again */ \
 		} \
 	while ( 0 )
-
 #define unput(c) yyunput( c, yyg->yytext_ptr , yyscanner )
 
 #ifndef YY_STRUCT_YY_BUFFER_STATE
@@ -238,12 +459,12 @@
 	/* Size of input buffer in bytes, not including room for EOB
 	 * characters.
 	 */
-	yy_size_t yy_buf_size;
+	int yy_buf_size;
 
 	/* Number of characters read into yy_ch_buf, not including EOB
 	 * characters.
 	 */
-	yy_size_t yy_n_chars;
+	int yy_n_chars;
 
 	/* Whether we "own" the buffer - i.e., we know we created it,
 	 * and can realloc() it to grow it, and should free() it to
@@ -266,7 +487,7 @@
 
     int yy_bs_lineno; /**< The line count. */
     int yy_bs_column; /**< The column count. */
-    
+
 	/* Whether to try to fill the input buffer when we reach the
 	 * end of it.
 	 */
@@ -283,7 +504,7 @@
 	 * possible backing-up.
 	 *
 	 * When we actually see the EOF, we change the status to "new"
-	 * (via xlu__cfg_yyrestart()), so that the user can continue scanning by
+	 * (via yyrestart()), so that the user can continue scanning by
 	 * just pointing yyin at a new input file.
 	 */
 #define YY_BUFFER_EOF_PENDING 2
@@ -300,71 +521,65 @@
 #define YY_CURRENT_BUFFER ( yyg->yy_buffer_stack \
                           ? yyg->yy_buffer_stack[yyg->yy_buffer_stack_top] \
                           : NULL)
-
 /* Same as previous macro, but useful when we know that the buffer stack is not
  * NULL or when we need an lvalue. For internal use only.
  */
 #define YY_CURRENT_BUFFER_LVALUE yyg->yy_buffer_stack[yyg->yy_buffer_stack_top]
 
-void xlu__cfg_yyrestart (FILE *input_file ,yyscan_t yyscanner );
-void xlu__cfg_yy_switch_to_buffer (YY_BUFFER_STATE new_buffer ,yyscan_t yyscanner );
-YY_BUFFER_STATE xlu__cfg_yy_create_buffer (FILE *file,int size ,yyscan_t yyscanner );
-void xlu__cfg_yy_delete_buffer (YY_BUFFER_STATE b ,yyscan_t yyscanner );
-void xlu__cfg_yy_flush_buffer (YY_BUFFER_STATE b ,yyscan_t yyscanner );
-void xlu__cfg_yypush_buffer_state (YY_BUFFER_STATE new_buffer ,yyscan_t yyscanner );
-void xlu__cfg_yypop_buffer_state (yyscan_t yyscanner );
-
-static void xlu__cfg_yyensure_buffer_stack (yyscan_t yyscanner );
-static void xlu__cfg_yy_load_buffer_state (yyscan_t yyscanner );
-static void xlu__cfg_yy_init_buffer (YY_BUFFER_STATE b,FILE *file ,yyscan_t yyscanner );
-
-#define YY_FLUSH_BUFFER xlu__cfg_yy_flush_buffer(YY_CURRENT_BUFFER ,yyscanner)
-
-YY_BUFFER_STATE xlu__cfg_yy_scan_buffer (char *base,yy_size_t size ,yyscan_t yyscanner );
-YY_BUFFER_STATE xlu__cfg_yy_scan_string (yyconst char *yy_str ,yyscan_t yyscanner );
-YY_BUFFER_STATE xlu__cfg_yy_scan_bytes (yyconst char *bytes,yy_size_t len ,yyscan_t yyscanner );
-
-void *xlu__cfg_yyalloc (yy_size_t ,yyscan_t yyscanner );
-void *xlu__cfg_yyrealloc (void *,yy_size_t ,yyscan_t yyscanner );
-void xlu__cfg_yyfree (void * ,yyscan_t yyscanner );
-
-#define yy_new_buffer xlu__cfg_yy_create_buffer
+void yyrestart ( FILE *input_file , yyscan_t yyscanner );
+void yy_switch_to_buffer ( YY_BUFFER_STATE new_buffer , yyscan_t yyscanner );
+YY_BUFFER_STATE yy_create_buffer ( FILE *file, int size , yyscan_t yyscanner );
+void yy_delete_buffer ( YY_BUFFER_STATE b , yyscan_t yyscanner );
+void yy_flush_buffer ( YY_BUFFER_STATE b , yyscan_t yyscanner );
+void yypush_buffer_state ( YY_BUFFER_STATE new_buffer , yyscan_t yyscanner );
+void yypop_buffer_state ( yyscan_t yyscanner );
+
+static void yyensure_buffer_stack ( yyscan_t yyscanner );
+static void yy_load_buffer_state ( yyscan_t yyscanner );
+static void yy_init_buffer ( YY_BUFFER_STATE b, FILE *file , yyscan_t yyscanner );
+#define YY_FLUSH_BUFFER yy_flush_buffer( YY_CURRENT_BUFFER , yyscanner)
+
+YY_BUFFER_STATE yy_scan_buffer ( char *base, yy_size_t size , yyscan_t yyscanner );
+YY_BUFFER_STATE yy_scan_string ( const char *yy_str , yyscan_t yyscanner );
+YY_BUFFER_STATE yy_scan_bytes ( const char *bytes, int len , yyscan_t yyscanner );
+
+void *yyalloc ( yy_size_t , yyscan_t yyscanner );
+void *yyrealloc ( void *, yy_size_t , yyscan_t yyscanner );
+void yyfree ( void * , yyscan_t yyscanner );
 
+#define yy_new_buffer yy_create_buffer
 #define yy_set_interactive(is_interactive) \
 	{ \
 	if ( ! YY_CURRENT_BUFFER ){ \
-        xlu__cfg_yyensure_buffer_stack (yyscanner); \
+        yyensure_buffer_stack (yyscanner); \
 		YY_CURRENT_BUFFER_LVALUE =    \
-            xlu__cfg_yy_create_buffer(yyin,YY_BUF_SIZE ,yyscanner); \
+            yy_create_buffer( yyin, YY_BUF_SIZE , yyscanner); \
 	} \
 	YY_CURRENT_BUFFER_LVALUE->yy_is_interactive = is_interactive; \
 	}
-
 #define yy_set_bol(at_bol) \
 	{ \
 	if ( ! YY_CURRENT_BUFFER ){\
-        xlu__cfg_yyensure_buffer_stack (yyscanner); \
+        yyensure_buffer_stack (yyscanner); \
 		YY_CURRENT_BUFFER_LVALUE =    \
-            xlu__cfg_yy_create_buffer(yyin,YY_BUF_SIZE ,yyscanner); \
+            yy_create_buffer( yyin, YY_BUF_SIZE , yyscanner); \
 	} \
 	YY_CURRENT_BUFFER_LVALUE->yy_at_bol = at_bol; \
 	}
-
 #define YY_AT_BOL() (YY_CURRENT_BUFFER_LVALUE->yy_at_bol)
 
-#define xlu__cfg_yywrap(yyscanner) 1
+#define xlu__cfg_yywrap(yyscanner) (/*CONSTCOND*/1)
 #define YY_SKIP_YYWRAP
-
-typedef unsigned char YY_CHAR;
+typedef flex_uint8_t YY_CHAR;
 
 typedef int yy_state_type;
 
 #define yytext_ptr yytext_r
 
-static yy_state_type yy_get_previous_state (yyscan_t yyscanner );
-static yy_state_type yy_try_NUL_trans (yy_state_type current_state  ,yyscan_t yyscanner);
-static int yy_get_next_buffer (yyscan_t yyscanner );
-static void yy_fatal_error (yyconst char msg[] ,yyscan_t yyscanner );
+static yy_state_type yy_get_previous_state ( yyscan_t yyscanner );
+static yy_state_type yy_try_NUL_trans ( yy_state_type current_state  , yyscan_t yyscanner);
+static int yy_get_next_buffer ( yyscan_t yyscanner );
+static void yynoreturn yy_fatal_error ( const char* msg , yyscan_t yyscanner );
 
 /* Done after the current pattern has been matched and before the
  * corresponding action - sets up yytext.
@@ -372,11 +587,10 @@
 #define YY_DO_BEFORE_ACTION \
 	yyg->yytext_ptr = yy_bp; \
 	yyg->yytext_ptr -= yyg->yy_more_len; \
-	yyleng = (size_t) (yy_cp - yyg->yytext_ptr); \
+	yyleng = (int) (yy_cp - yyg->yytext_ptr); \
 	yyg->yy_hold_char = *yy_cp; \
 	*yy_cp = '\0'; \
 	yyg->yy_c_buf_p = yy_cp;
-
 #define YY_NUM_RULES 16
 #define YY_END_OF_BUFFER 17
 /* This struct is not used in this scanner,
@@ -386,7 +600,7 @@
 	flex_int32_t yy_verify;
 	flex_int32_t yy_nxt;
 	};
-static yyconst flex_int16_t yy_accept[35] =
+static const flex_int16_t yy_accept[35] =
     {   0,
         0,    0,   14,   14,   17,   13,    3,    9,   13,   13,
        13,   12,    4,    2,    8,    7,    5,    6,    1,   14,
@@ -394,7 +608,7 @@
         2,    1,   14,    0
     } ;
 
-static yyconst flex_int32_t yy_ec[256] =
+static const YY_CHAR yy_ec[256] =
     {   0,
         1,    1,    1,    1,    1,    1,    1,    1,    2,    3,
         1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
@@ -426,13 +640,13 @@
         1,    1,    1,    1,    1
     } ;
 
-static yyconst flex_int32_t yy_meta[19] =
+static const YY_CHAR yy_meta[19] =
     {   0,
         1,    2,    3,    1,    1,    1,    1,    1,    4,    4,
         1,    1,    1,    1,    1,    4,    4,    4
     } ;
 
-static yyconst flex_int16_t yy_base[41] =
+static const flex_int16_t yy_base[41] =
     {   0,
         0,    0,   17,   19,   44,   58,   58,   58,   19,   28,
        18,   58,   58,   17,   58,   58,   58,   58,    0,    0,
@@ -440,7 +654,7 @@
        20,    0,    0,   58,   37,   41,   45,   49,   22,   53
     } ;
 
-static yyconst flex_int16_t yy_def[41] =
+static const flex_int16_t yy_def[41] =
     {   0,
        34,    1,   35,   35,   34,   34,   34,   34,   36,   37,
        38,   34,   34,   34,   34,   34,   34,   34,   39,   40,
@@ -448,7 +662,7 @@
        34,   39,   40,    0,   34,   34,   34,   34,   34,   34
     } ;
 
-static yyconst flex_int16_t yy_nxt[77] =
+static const flex_int16_t yy_nxt[77] =
     {   0,
         6,    7,    8,    9,   10,   11,   12,   13,   12,   14,
        15,   16,   17,    6,   18,    6,   19,   19,   21,   22,
@@ -460,7 +674,7 @@
        34,   34,   34,   34,   34,   34
     } ;
 
-static yyconst flex_int16_t yy_chk[77] =
+static const flex_int16_t yy_chk[77] =
     {   0,
         1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
         1,    1,    1,    1,    1,    1,    1,    1,    3,    3,
@@ -473,7 +687,7 @@
     } ;
 
 /* Table of booleans, true if rule could match eol. */
-static yyconst flex_int32_t yy_rule_can_match_eol[17] =
+static const flex_int32_t yy_rule_can_match_eol[17] =
     {   0,
 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,     };
 
@@ -520,8 +734,9 @@
 int xlu__cfg_yyget_column(yyscan_t yyscanner);
 void xlu__cfg_yyset_column(int  column_no, yyscan_t yyscanner);
 
+#line 738 "libxlu_cfg_l.c"
 
-#line 525 "libxlu_cfg_l.c"
+#line 740 "libxlu_cfg_l.c"
 
 #define INITIAL 0
 #define lexerr 1
@@ -551,8 +766,8 @@
     size_t yy_buffer_stack_max; /**< capacity of stack. */
     YY_BUFFER_STATE * yy_buffer_stack; /**< Stack as an array. */
     char yy_hold_char;
-    yy_size_t yy_n_chars;
-    yy_size_t yyleng_r;
+    int yy_n_chars;
+    int yyleng_r;
     char *yy_c_buf_p;
     int yy_init;
     int yy_start;
@@ -576,7 +791,7 @@
 
     }; /* end struct yyguts_t */
 
-static int yy_init_globals (yyscan_t yyscanner );
+static int yy_init_globals ( yyscan_t yyscanner );
 
     /* This must go here because YYSTYPE and YYLTYPE are included
      * from bison output in section 1.*/
@@ -584,50 +799,50 @@
     
     #    define yylloc yyg->yylloc_r
     
-int xlu__cfg_yylex_init (yyscan_t* scanner);
+int yylex_init (yyscan_t* scanner);
 
-int xlu__cfg_yylex_init_extra (YY_EXTRA_TYPE user_defined,yyscan_t* scanner);
+int yylex_init_extra ( YY_EXTRA_TYPE user_defined, yyscan_t* scanner);
 
 /* Accessor methods to globals.
    These are made visible to non-reentrant scanners for convenience. */
 
-int xlu__cfg_yylex_destroy (yyscan_t yyscanner );
+int yylex_destroy ( yyscan_t yyscanner );
 
-int xlu__cfg_yyget_debug (yyscan_t yyscanner );
+int yyget_debug ( yyscan_t yyscanner );
 
-void xlu__cfg_yyset_debug (int debug_flag ,yyscan_t yyscanner );
+void yyset_debug ( int debug_flag , yyscan_t yyscanner );
 
-YY_EXTRA_TYPE xlu__cfg_yyget_extra (yyscan_t yyscanner );
+YY_EXTRA_TYPE yyget_extra ( yyscan_t yyscanner );
 
-void xlu__cfg_yyset_extra (YY_EXTRA_TYPE user_defined ,yyscan_t yyscanner );
+void yyset_extra ( YY_EXTRA_TYPE user_defined , yyscan_t yyscanner );
 
-FILE *xlu__cfg_yyget_in (yyscan_t yyscanner );
+FILE *yyget_in ( yyscan_t yyscanner );
 
-void xlu__cfg_yyset_in  (FILE * in_str ,yyscan_t yyscanner );
+void yyset_in  ( FILE * _in_str , yyscan_t yyscanner );
 
-FILE *xlu__cfg_yyget_out (yyscan_t yyscanner );
+FILE *yyget_out ( yyscan_t yyscanner );
 
-void xlu__cfg_yyset_out  (FILE * out_str ,yyscan_t yyscanner );
+void yyset_out  ( FILE * _out_str , yyscan_t yyscanner );
 
-yy_size_t xlu__cfg_yyget_leng (yyscan_t yyscanner );
+			int yyget_leng ( yyscan_t yyscanner );
 
-char *xlu__cfg_yyget_text (yyscan_t yyscanner );
+char *yyget_text ( yyscan_t yyscanner );
 
-int xlu__cfg_yyget_lineno (yyscan_t yyscanner );
+int yyget_lineno ( yyscan_t yyscanner );
 
-void xlu__cfg_yyset_lineno (int line_number ,yyscan_t yyscanner );
+void yyset_lineno ( int _line_number , yyscan_t yyscanner );
 
-int xlu__cfg_yyget_column  (yyscan_t yyscanner );
+int yyget_column  ( yyscan_t yyscanner );
 
-void xlu__cfg_yyset_column (int column_no ,yyscan_t yyscanner );
+void yyset_column ( int _column_no , yyscan_t yyscanner );
 
-YYSTYPE * xlu__cfg_yyget_lval (yyscan_t yyscanner );
+YYSTYPE * yyget_lval ( yyscan_t yyscanner );
 
-void xlu__cfg_yyset_lval (YYSTYPE * yylval_param ,yyscan_t yyscanner );
+void yyset_lval ( YYSTYPE * yylval_param , yyscan_t yyscanner );
 
-       YYLTYPE *xlu__cfg_yyget_lloc (yyscan_t yyscanner );
+       YYLTYPE *yyget_lloc ( yyscan_t yyscanner );
     
-        void xlu__cfg_yyset_lloc (YYLTYPE * yylloc_param ,yyscan_t yyscanner );
+        void yyset_lloc ( YYLTYPE * yylloc_param , yyscan_t yyscanner );
     
 /* Macros after this point can all be overridden by user definitions in
  * section 1.
@@ -635,26 +850,29 @@
 
 #ifndef YY_SKIP_YYWRAP
 #ifdef __cplusplus
-extern "C" int xlu__cfg_yywrap (yyscan_t yyscanner );
+extern "C" int yywrap ( yyscan_t yyscanner );
 #else
-extern int xlu__cfg_yywrap (yyscan_t yyscanner );
+extern int yywrap ( yyscan_t yyscanner );
 #endif
 #endif
 
+#ifndef YY_NO_UNPUT
+    
+#endif
+
 #ifndef yytext_ptr
-static void yy_flex_strncpy (char *,yyconst char *,int ,yyscan_t yyscanner);
+static void yy_flex_strncpy ( char *, const char *, int , yyscan_t yyscanner);
 #endif
 
 #ifdef YY_NEED_STRLEN
-static int yy_flex_strlen (yyconst char * ,yyscan_t yyscanner);
+static int yy_flex_strlen ( const char * , yyscan_t yyscanner);
 #endif
 
 #ifndef YY_NO_INPUT
-
 #ifdef __cplusplus
-static int yyinput (yyscan_t yyscanner );
+static int yyinput ( yyscan_t yyscanner );
 #else
-static int input (yyscan_t yyscanner );
+static int input ( yyscan_t yyscanner );
 #endif
 
 #endif
@@ -674,7 +892,7 @@
 /* This used to be an fputs(), but since the string might contain NUL's,
  * we now use fwrite().
  */
-#define ECHO do { if (fwrite( yytext, yyleng, 1, yyout )) {} } while (0)
+#define ECHO do { if (fwrite( yytext, (size_t) yyleng, 1, yyout )) {} } while (0)
 #endif
 
 /* Gets input and stuffs it into "buf".  number of characters read, or YY_NULL,
@@ -698,7 +916,7 @@
 	else \
 		{ \
 		errno=0; \
-		while ( (result = fread(buf, 1, (yy_size_t) max_size, yyin)) == 0 && ferror(yyin)) \
+		while ( (result = (int) fread(buf, 1, (yy_size_t) max_size, yyin)) == 0 && ferror(yyin)) \
 			{ \
 			if( errno != EINTR) \
 				{ \
@@ -739,10 +957,10 @@
 #ifndef YY_DECL
 #define YY_DECL_IS_OURS 1
 
-extern int xlu__cfg_yylex \
-               (YYSTYPE * yylval_param,YYLTYPE * yylloc_param ,yyscan_t yyscanner);
+extern int yylex \
+               (YYSTYPE * yylval_param, YYLTYPE * yylloc_param , yyscan_t yyscanner);
 
-#define YY_DECL int xlu__cfg_yylex \
+#define YY_DECL int yylex \
                (YYSTYPE * yylval_param, YYLTYPE * yylloc_param , yyscan_t yyscanner)
 #endif /* !YY_DECL */
 
@@ -755,7 +973,7 @@
 
 /* Code executed at the end of each rule. */
 #ifndef YY_BREAK
-#define YY_BREAK break;
+#define YY_BREAK /*LINTED*/break;
 #endif
 
 #define YY_RULE_SETUP \
@@ -765,9 +983,9 @@
  */
 YY_DECL
 {
-	register yy_state_type yy_current_state;
-	register char *yy_cp, *yy_bp;
-	register int yy_act;
+	yy_state_type yy_current_state;
+	char *yy_cp, *yy_bp;
+	int yy_act;
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
 
     yylval = yylval_param;
@@ -792,26 +1010,26 @@
 			yyout = stdout;
 
 		if ( ! YY_CURRENT_BUFFER ) {
-			xlu__cfg_yyensure_buffer_stack (yyscanner);
+			yyensure_buffer_stack (yyscanner);
 			YY_CURRENT_BUFFER_LVALUE =
-				xlu__cfg_yy_create_buffer(yyin,YY_BUF_SIZE ,yyscanner);
+				yy_create_buffer( yyin, YY_BUF_SIZE , yyscanner);
 		}
 
-		xlu__cfg_yy_load_buffer_state(yyscanner );
+		yy_load_buffer_state( yyscanner );
 		}
 
 	{
 #line 53 "libxlu_cfg_l.l"
 
 
-#line 808 "libxlu_cfg_l.c"
+#line 1026 "libxlu_cfg_l.c"
 
-	while ( 1 )		/* loops until end-of-file is reached */
+	while ( /*CONSTCOND*/1 )		/* loops until end-of-file is reached */
 		{
 		yyg->yy_more_len = 0;
 		if ( yyg->yy_more_flag )
 			{
-			yyg->yy_more_len = yyg->yy_c_buf_p - yyg->yytext_ptr;
+			yyg->yy_more_len = (int) (yyg->yy_c_buf_p - yyg->yytext_ptr);
 			yyg->yy_more_flag = 0;
 			}
 		yy_cp = yyg->yy_c_buf_p;
@@ -828,7 +1046,7 @@
 yy_match:
 		do
 			{
-			register YY_CHAR yy_c = yy_ec[YY_SC_TO_UI(*yy_cp)] ;
+			YY_CHAR yy_c = yy_ec[YY_SC_TO_UI(*yy_cp)] ;
 			if ( yy_accept[yy_current_state] )
 				{
 				yyg->yy_last_accepting_state = yy_current_state;
@@ -838,9 +1056,9 @@
 				{
 				yy_current_state = (int) yy_def[yy_current_state];
 				if ( yy_current_state >= 35 )
-					yy_c = yy_meta[(unsigned int) yy_c];
+					yy_c = yy_meta[yy_c];
 				}
-			yy_current_state = yy_nxt[yy_base[yy_current_state] + (unsigned int) yy_c];
+			yy_current_state = yy_nxt[yy_base[yy_current_state] + yy_c];
 			++yy_cp;
 			}
 		while ( yy_current_state != 34 );
@@ -854,10 +1072,10 @@
 
 		if ( yy_act != YY_END_OF_BUFFER && yy_rule_can_match_eol[yy_act] )
 			{
-			yy_size_t yyl;
+			int yyl;
 			for ( yyl = yyg->yy_more_len; yyl < yyleng; ++yyl )
 				if ( yytext[yyl] == '\n' )
-					   
+					
     do{ yylineno++;
         yycolumn=0;
     }while(0)
@@ -983,7 +1201,7 @@
 #line 104 "libxlu_cfg_l.l"
 YY_FATAL_ERROR( "flex scanner jammed" );
 	YY_BREAK
-#line 987 "libxlu_cfg_l.c"
+#line 1205 "libxlu_cfg_l.c"
 case YY_STATE_EOF(INITIAL):
 case YY_STATE_EOF(lexerr):
 	yyterminate();
@@ -1002,7 +1220,7 @@
 			/* We're scanning a new file or input source.  It's
 			 * possible that this happened because the user
 			 * just pointed yyin at a new source and called
-			 * xlu__cfg_yylex().  If so, then we have to assure
+			 * yylex().  If so, then we have to assure
 			 * consistency between YY_CURRENT_BUFFER and our
 			 * globals.  Here is the right place to do so, because
 			 * this is the first action (other than possibly a
@@ -1063,7 +1281,7 @@
 				{
 				yyg->yy_did_buffer_switch_on_eof = 0;
 
-				if ( xlu__cfg_yywrap(yyscanner ) )
+				if ( yywrap( yyscanner ) )
 					{
 					/* Note: because we've taken care in
 					 * yy_get_next_buffer() to have set up
@@ -1117,7 +1335,7 @@
 	} /* end of action switch */
 		} /* end of scanning one token */
 	} /* end of user's declarations */
-} /* end of xlu__cfg_yylex */
+} /* end of yylex */
 
 /* yy_get_next_buffer - try to read in a new buffer
  *
@@ -1129,9 +1347,9 @@
 static int yy_get_next_buffer (yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
-	register char *dest = YY_CURRENT_BUFFER_LVALUE->yy_ch_buf;
-	register char *source = yyg->yytext_ptr;
-	register int number_to_move, i;
+	char *dest = YY_CURRENT_BUFFER_LVALUE->yy_ch_buf;
+	char *source = yyg->yytext_ptr;
+	int number_to_move, i;
 	int ret_val;
 
 	if ( yyg->yy_c_buf_p > &YY_CURRENT_BUFFER_LVALUE->yy_ch_buf[yyg->yy_n_chars + 1] )
@@ -1160,7 +1378,7 @@
 	/* Try to read more data. */
 
 	/* First move last chars to start of buffer. */
-	number_to_move = (int) (yyg->yy_c_buf_p - yyg->yytext_ptr) - 1;
+	number_to_move = (int) (yyg->yy_c_buf_p - yyg->yytext_ptr - 1);
 
 	for ( i = 0; i < number_to_move; ++i )
 		*(dest++) = *(source++);
@@ -1187,7 +1405,7 @@
 
 			if ( b->yy_is_our_buffer )
 				{
-				yy_size_t new_size = b->yy_buf_size * 2;
+				int new_size = b->yy_buf_size * 2;
 
 				if ( new_size <= 0 )
 					b->yy_buf_size += b->yy_buf_size / 8;
@@ -1196,11 +1414,12 @@
 
 				b->yy_ch_buf = (char *)
 					/* Include room in for 2 EOB chars. */
-					xlu__cfg_yyrealloc((void *) b->yy_ch_buf,b->yy_buf_size + 2 ,yyscanner );
+					yyrealloc( (void *) b->yy_ch_buf,
+							 (yy_size_t) (b->yy_buf_size + 2) , yyscanner );
 				}
 			else
 				/* Can't grow it, we don't own it. */
-				b->yy_ch_buf = 0;
+				b->yy_ch_buf = NULL;
 
 			if ( ! b->yy_ch_buf )
 				YY_FATAL_ERROR(
@@ -1228,7 +1447,7 @@
 		if ( number_to_move == YY_MORE_ADJ )
 			{
 			ret_val = EOB_ACT_END_OF_FILE;
-			xlu__cfg_yyrestart(yyin  ,yyscanner);
+			yyrestart( yyin  , yyscanner);
 			}
 
 		else
@@ -1242,12 +1461,15 @@
 	else
 		ret_val = EOB_ACT_CONTINUE_SCAN;
 
-	if ((yy_size_t) (yyg->yy_n_chars + number_to_move) > YY_CURRENT_BUFFER_LVALUE->yy_buf_size) {
+	if ((yyg->yy_n_chars + number_to_move) > YY_CURRENT_BUFFER_LVALUE->yy_buf_size) {
 		/* Extend the array by 50%, plus the number we really need. */
-		yy_size_t new_size = yyg->yy_n_chars + number_to_move + (yyg->yy_n_chars >> 1);
-		YY_CURRENT_BUFFER_LVALUE->yy_ch_buf = (char *) xlu__cfg_yyrealloc((void *) YY_CURRENT_BUFFER_LVALUE->yy_ch_buf,new_size ,yyscanner );
+		int new_size = yyg->yy_n_chars + number_to_move + (yyg->yy_n_chars >> 1);
+		YY_CURRENT_BUFFER_LVALUE->yy_ch_buf = (char *) yyrealloc(
+			(void *) YY_CURRENT_BUFFER_LVALUE->yy_ch_buf, (yy_size_t) new_size , yyscanner );
 		if ( ! YY_CURRENT_BUFFER_LVALUE->yy_ch_buf )
 			YY_FATAL_ERROR( "out of dynamic memory in yy_get_next_buffer()" );
+		/* "- 2" to take care of EOB's */
+		YY_CURRENT_BUFFER_LVALUE->yy_buf_size = (int) (new_size - 2);
 	}
 
 	yyg->yy_n_chars += number_to_move;
@@ -1263,15 +1485,15 @@
 
     static yy_state_type yy_get_previous_state (yyscan_t yyscanner)
 {
-	register yy_state_type yy_current_state;
-	register char *yy_cp;
+	yy_state_type yy_current_state;
+	char *yy_cp;
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
 
 	yy_current_state = yyg->yy_start;
 
 	for ( yy_cp = yyg->yytext_ptr + YY_MORE_ADJ; yy_cp < yyg->yy_c_buf_p; ++yy_cp )
 		{
-		register YY_CHAR yy_c = (*yy_cp ? yy_ec[YY_SC_TO_UI(*yy_cp)] : 1);
+		YY_CHAR yy_c = (*yy_cp ? yy_ec[YY_SC_TO_UI(*yy_cp)] : 1);
 		if ( yy_accept[yy_current_state] )
 			{
 			yyg->yy_last_accepting_state = yy_current_state;
@@ -1281,9 +1503,9 @@
 			{
 			yy_current_state = (int) yy_def[yy_current_state];
 			if ( yy_current_state >= 35 )
-				yy_c = yy_meta[(unsigned int) yy_c];
+				yy_c = yy_meta[yy_c];
 			}
-		yy_current_state = yy_nxt[yy_base[yy_current_state] + (unsigned int) yy_c];
+		yy_current_state = yy_nxt[yy_base[yy_current_state] + yy_c];
 		}
 
 	return yy_current_state;
@@ -1296,11 +1518,11 @@
  */
     static yy_state_type yy_try_NUL_trans  (yy_state_type yy_current_state , yyscan_t yyscanner)
 {
-	register int yy_is_jam;
+	int yy_is_jam;
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner; /* This var may be unused depending upon options. */
-	register char *yy_cp = yyg->yy_c_buf_p;
+	char *yy_cp = yyg->yy_c_buf_p;
 
-	register YY_CHAR yy_c = 1;
+	YY_CHAR yy_c = 1;
 	if ( yy_accept[yy_current_state] )
 		{
 		yyg->yy_last_accepting_state = yy_current_state;
@@ -1310,15 +1532,19 @@
 		{
 		yy_current_state = (int) yy_def[yy_current_state];
 		if ( yy_current_state >= 35 )
-			yy_c = yy_meta[(unsigned int) yy_c];
+			yy_c = yy_meta[yy_c];
 		}
-	yy_current_state = yy_nxt[yy_base[yy_current_state] + (unsigned int) yy_c];
+	yy_current_state = yy_nxt[yy_base[yy_current_state] + yy_c];
 	yy_is_jam = (yy_current_state == 34);
 
 	(void)yyg;
 	return yy_is_jam ? 0 : yy_current_state;
 }
 
+#ifndef YY_NO_UNPUT
+
+#endif
+
 #ifndef YY_NO_INPUT
 #ifdef __cplusplus
     static int yyinput (yyscan_t yyscanner)
@@ -1344,7 +1570,7 @@
 
 		else
 			{ /* need more input */
-			yy_size_t offset = yyg->yy_c_buf_p - yyg->yytext_ptr;
+			int offset = (int) (yyg->yy_c_buf_p - yyg->yytext_ptr);
 			++yyg->yy_c_buf_p;
 
 			switch ( yy_get_next_buffer( yyscanner ) )
@@ -1361,14 +1587,14 @@
 					 */
 
 					/* Reset buffer status. */
-					xlu__cfg_yyrestart(yyin ,yyscanner);
+					yyrestart( yyin , yyscanner);
 
 					/*FALLTHROUGH*/
 
 				case EOB_ACT_END_OF_FILE:
 					{
-					if ( xlu__cfg_yywrap(yyscanner ) )
-						return EOF;
+					if ( yywrap( yyscanner ) )
+						return 0;
 
 					if ( ! yyg->yy_did_buffer_switch_on_eof )
 						YY_NEW_FILE;
@@ -1391,7 +1617,7 @@
 	yyg->yy_hold_char = *++yyg->yy_c_buf_p;
 
 	if ( c == '\n' )
-		   
+		
     do{ yylineno++;
         yycolumn=0;
     }while(0)
@@ -1406,34 +1632,34 @@
  * @param yyscanner The scanner object.
  * @note This function does not reset the start condition to @c INITIAL .
  */
-    void xlu__cfg_yyrestart  (FILE * input_file , yyscan_t yyscanner)
+    void yyrestart  (FILE * input_file , yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
 
 	if ( ! YY_CURRENT_BUFFER ){
-        xlu__cfg_yyensure_buffer_stack (yyscanner);
+        yyensure_buffer_stack (yyscanner);
 		YY_CURRENT_BUFFER_LVALUE =
-            xlu__cfg_yy_create_buffer(yyin,YY_BUF_SIZE ,yyscanner);
+            yy_create_buffer( yyin, YY_BUF_SIZE , yyscanner);
 	}
 
-	xlu__cfg_yy_init_buffer(YY_CURRENT_BUFFER,input_file ,yyscanner);
-	xlu__cfg_yy_load_buffer_state(yyscanner );
+	yy_init_buffer( YY_CURRENT_BUFFER, input_file , yyscanner);
+	yy_load_buffer_state( yyscanner );
 }
 
 /** Switch to a different input buffer.
  * @param new_buffer The new input buffer.
  * @param yyscanner The scanner object.
  */
-    void xlu__cfg_yy_switch_to_buffer  (YY_BUFFER_STATE  new_buffer , yyscan_t yyscanner)
+    void yy_switch_to_buffer  (YY_BUFFER_STATE  new_buffer , yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
 
 	/* TODO. We should be able to replace this entire function body
 	 * with
-	 *		xlu__cfg_yypop_buffer_state();
-	 *		xlu__cfg_yypush_buffer_state(new_buffer);
+	 *		yypop_buffer_state();
+	 *		yypush_buffer_state(new_buffer);
      */
-	xlu__cfg_yyensure_buffer_stack (yyscanner);
+	yyensure_buffer_stack (yyscanner);
 	if ( YY_CURRENT_BUFFER == new_buffer )
 		return;
 
@@ -1446,17 +1672,17 @@
 		}
 
 	YY_CURRENT_BUFFER_LVALUE = new_buffer;
-	xlu__cfg_yy_load_buffer_state(yyscanner );
+	yy_load_buffer_state( yyscanner );
 
 	/* We don't actually know whether we did this switch during
-	 * EOF (xlu__cfg_yywrap()) processing, but the only time this flag
-	 * is looked at is after xlu__cfg_yywrap() is called, so it's safe
+	 * EOF (yywrap()) processing, but the only time this flag
+	 * is looked at is after yywrap() is called, so it's safe
 	 * to go ahead and always set it.
 	 */
 	yyg->yy_did_buffer_switch_on_eof = 1;
 }
 
-static void xlu__cfg_yy_load_buffer_state  (yyscan_t yyscanner)
+static void yy_load_buffer_state  (yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
 	yyg->yy_n_chars = YY_CURRENT_BUFFER_LVALUE->yy_n_chars;
@@ -1471,35 +1697,35 @@
  * @param yyscanner The scanner object.
  * @return the allocated buffer state.
  */
-    YY_BUFFER_STATE xlu__cfg_yy_create_buffer  (FILE * file, int  size , yyscan_t yyscanner)
+    YY_BUFFER_STATE yy_create_buffer  (FILE * file, int  size , yyscan_t yyscanner)
 {
 	YY_BUFFER_STATE b;
     
-	b = (YY_BUFFER_STATE) xlu__cfg_yyalloc(sizeof( struct yy_buffer_state ) ,yyscanner );
+	b = (YY_BUFFER_STATE) yyalloc( sizeof( struct yy_buffer_state ) , yyscanner );
 	if ( ! b )
-		YY_FATAL_ERROR( "out of dynamic memory in xlu__cfg_yy_create_buffer()" );
+		YY_FATAL_ERROR( "out of dynamic memory in yy_create_buffer()" );
 
 	b->yy_buf_size = size;
 
 	/* yy_ch_buf has to be 2 characters longer than the size given because
 	 * we need to put in 2 end-of-buffer characters.
 	 */
-	b->yy_ch_buf = (char *) xlu__cfg_yyalloc(b->yy_buf_size + 2 ,yyscanner );
+	b->yy_ch_buf = (char *) yyalloc( (yy_size_t) (b->yy_buf_size + 2) , yyscanner );
 	if ( ! b->yy_ch_buf )
-		YY_FATAL_ERROR( "out of dynamic memory in xlu__cfg_yy_create_buffer()" );
+		YY_FATAL_ERROR( "out of dynamic memory in yy_create_buffer()" );
 
 	b->yy_is_our_buffer = 1;
 
-	xlu__cfg_yy_init_buffer(b,file ,yyscanner);
+	yy_init_buffer( b, file , yyscanner);
 
 	return b;
 }
 
 /** Destroy the buffer.
- * @param b a buffer created with xlu__cfg_yy_create_buffer()
+ * @param b a buffer created with yy_create_buffer()
  * @param yyscanner The scanner object.
  */
-    void xlu__cfg_yy_delete_buffer (YY_BUFFER_STATE  b , yyscan_t yyscanner)
+    void yy_delete_buffer (YY_BUFFER_STATE  b , yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
 
@@ -1510,28 +1736,28 @@
 		YY_CURRENT_BUFFER_LVALUE = (YY_BUFFER_STATE) 0;
 
 	if ( b->yy_is_our_buffer )
-		xlu__cfg_yyfree((void *) b->yy_ch_buf ,yyscanner );
+		yyfree( (void *) b->yy_ch_buf , yyscanner );
 
-	xlu__cfg_yyfree((void *) b ,yyscanner );
+	yyfree( (void *) b , yyscanner );
 }
 
 /* Initializes or reinitializes a buffer.
  * This function is sometimes called more than once on the same buffer,
- * such as during a xlu__cfg_yyrestart() or at EOF.
+ * such as during a yyrestart() or at EOF.
  */
-    static void xlu__cfg_yy_init_buffer  (YY_BUFFER_STATE  b, FILE * file , yyscan_t yyscanner)
+    static void yy_init_buffer  (YY_BUFFER_STATE  b, FILE * file , yyscan_t yyscanner)
 
 {
 	int oerrno = errno;
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
 
-	xlu__cfg_yy_flush_buffer(b ,yyscanner);
+	yy_flush_buffer( b , yyscanner);
 
 	b->yy_input_file = file;
 	b->yy_fill_buffer = 1;
 
-    /* If b is the current buffer, then xlu__cfg_yy_init_buffer was _probably_
-     * called from xlu__cfg_yyrestart() or through yy_get_next_buffer.
+    /* If b is the current buffer, then yy_init_buffer was _probably_
+     * called from yyrestart() or through yy_get_next_buffer.
      * In that case, we don't want to reset the lineno or column.
      */
     if (b != YY_CURRENT_BUFFER){
@@ -1548,7 +1774,7 @@
  * @param b the buffer state to be flushed, usually @c YY_CURRENT_BUFFER.
  * @param yyscanner The scanner object.
  */
-    void xlu__cfg_yy_flush_buffer (YY_BUFFER_STATE  b , yyscan_t yyscanner)
+    void yy_flush_buffer (YY_BUFFER_STATE  b , yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
 	if ( ! b )
@@ -1569,7 +1795,7 @@
 	b->yy_buffer_status = YY_BUFFER_NEW;
 
 	if ( b == YY_CURRENT_BUFFER )
-		xlu__cfg_yy_load_buffer_state(yyscanner );
+		yy_load_buffer_state( yyscanner );
 }
 
 /** Pushes the new state onto the stack. The new state becomes
@@ -1578,15 +1804,15 @@
  *  @param new_buffer The new state.
  *  @param yyscanner The scanner object.
  */
-void xlu__cfg_yypush_buffer_state (YY_BUFFER_STATE new_buffer , yyscan_t yyscanner)
+void yypush_buffer_state (YY_BUFFER_STATE new_buffer , yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
 	if (new_buffer == NULL)
 		return;
 
-	xlu__cfg_yyensure_buffer_stack(yyscanner);
+	yyensure_buffer_stack(yyscanner);
 
-	/* This block is copied from xlu__cfg_yy_switch_to_buffer. */
+	/* This block is copied from yy_switch_to_buffer. */
 	if ( YY_CURRENT_BUFFER )
 		{
 		/* Flush out information for old buffer. */
@@ -1600,8 +1826,8 @@
 		yyg->yy_buffer_stack_top++;
 	YY_CURRENT_BUFFER_LVALUE = new_buffer;
 
-	/* copied from xlu__cfg_yy_switch_to_buffer. */
-	xlu__cfg_yy_load_buffer_state(yyscanner );
+	/* copied from yy_switch_to_buffer. */
+	yy_load_buffer_state( yyscanner );
 	yyg->yy_did_buffer_switch_on_eof = 1;
 }
 
@@ -1609,19 +1835,19 @@
  *  The next element becomes the new top.
  *  @param yyscanner The scanner object.
  */
-void xlu__cfg_yypop_buffer_state (yyscan_t yyscanner)
+void yypop_buffer_state (yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
 	if (!YY_CURRENT_BUFFER)
 		return;
 
-	xlu__cfg_yy_delete_buffer(YY_CURRENT_BUFFER ,yyscanner);
+	yy_delete_buffer(YY_CURRENT_BUFFER , yyscanner);
 	YY_CURRENT_BUFFER_LVALUE = NULL;
 	if (yyg->yy_buffer_stack_top > 0)
 		--yyg->yy_buffer_stack_top;
 
 	if (YY_CURRENT_BUFFER) {
-		xlu__cfg_yy_load_buffer_state(yyscanner );
+		yy_load_buffer_state( yyscanner );
 		yyg->yy_did_buffer_switch_on_eof = 1;
 	}
 }
@@ -1629,7 +1855,7 @@
 /* Allocates the stack if it does not exist.
  *  Guarantees space for at least one push.
  */
-static void xlu__cfg_yyensure_buffer_stack (yyscan_t yyscanner)
+static void yyensure_buffer_stack (yyscan_t yyscanner)
 {
 	yy_size_t num_to_alloc;
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
@@ -1640,15 +1866,15 @@
 		 * scanner will even need a stack. We use 2 instead of 1 to avoid an
 		 * immediate realloc on the next call.
          */
-		num_to_alloc = 1;
-		yyg->yy_buffer_stack = (struct yy_buffer_state**)xlu__cfg_yyalloc
+      num_to_alloc = 1; /* After all that talk, this was set to 1 anyways... */
+		yyg->yy_buffer_stack = (struct yy_buffer_state**)yyalloc
 								(num_to_alloc * sizeof(struct yy_buffer_state*)
 								, yyscanner);
 		if ( ! yyg->yy_buffer_stack )
-			YY_FATAL_ERROR( "out of dynamic memory in xlu__cfg_yyensure_buffer_stack()" );
-								  
+			YY_FATAL_ERROR( "out of dynamic memory in yyensure_buffer_stack()" );
+
 		memset(yyg->yy_buffer_stack, 0, num_to_alloc * sizeof(struct yy_buffer_state*));
-				
+
 		yyg->yy_buffer_stack_max = num_to_alloc;
 		yyg->yy_buffer_stack_top = 0;
 		return;
@@ -1657,15 +1883,15 @@
 	if (yyg->yy_buffer_stack_top >= (yyg->yy_buffer_stack_max) - 1){
 
 		/* Increase the buffer to prepare for a possible push. */
-		int grow_size = 8 /* arbitrary grow size */;
+		yy_size_t grow_size = 8 /* arbitrary grow size */;
 
 		num_to_alloc = yyg->yy_buffer_stack_max + grow_size;
-		yyg->yy_buffer_stack = (struct yy_buffer_state**)xlu__cfg_yyrealloc
+		yyg->yy_buffer_stack = (struct yy_buffer_state**)yyrealloc
 								(yyg->yy_buffer_stack,
 								num_to_alloc * sizeof(struct yy_buffer_state*)
 								, yyscanner);
 		if ( ! yyg->yy_buffer_stack )
-			YY_FATAL_ERROR( "out of dynamic memory in xlu__cfg_yyensure_buffer_stack()" );
+			YY_FATAL_ERROR( "out of dynamic memory in yyensure_buffer_stack()" );
 
 		/* zero only the new slots.*/
 		memset(yyg->yy_buffer_stack + yyg->yy_buffer_stack_max, 0, grow_size * sizeof(struct yy_buffer_state*));
@@ -1677,9 +1903,9 @@
  * @param base the character buffer
  * @param size the size in bytes of the character buffer
  * @param yyscanner The scanner object.
- * @return the newly allocated buffer state object. 
+ * @return the newly allocated buffer state object.
  */
-YY_BUFFER_STATE xlu__cfg_yy_scan_buffer  (char * base, yy_size_t  size , yyscan_t yyscanner)
+YY_BUFFER_STATE yy_scan_buffer  (char * base, yy_size_t  size , yyscan_t yyscanner)
 {
 	YY_BUFFER_STATE b;
     
@@ -1687,69 +1913,69 @@
 	     base[size-2] != YY_END_OF_BUFFER_CHAR ||
 	     base[size-1] != YY_END_OF_BUFFER_CHAR )
 		/* They forgot to leave room for the EOB's. */
-		return 0;
+		return NULL;
 
-	b = (YY_BUFFER_STATE) xlu__cfg_yyalloc(sizeof( struct yy_buffer_state ) ,yyscanner );
+	b = (YY_BUFFER_STATE) yyalloc( sizeof( struct yy_buffer_state ) , yyscanner );
 	if ( ! b )
-		YY_FATAL_ERROR( "out of dynamic memory in xlu__cfg_yy_scan_buffer()" );
+		YY_FATAL_ERROR( "out of dynamic memory in yy_scan_buffer()" );
 
-	b->yy_buf_size = size - 2;	/* "- 2" to take care of EOB's */
+	b->yy_buf_size = (int) (size - 2);	/* "- 2" to take care of EOB's */
 	b->yy_buf_pos = b->yy_ch_buf = base;
 	b->yy_is_our_buffer = 0;
-	b->yy_input_file = 0;
+	b->yy_input_file = NULL;
 	b->yy_n_chars = b->yy_buf_size;
 	b->yy_is_interactive = 0;
 	b->yy_at_bol = 1;
 	b->yy_fill_buffer = 0;
 	b->yy_buffer_status = YY_BUFFER_NEW;
 
-	xlu__cfg_yy_switch_to_buffer(b ,yyscanner );
+	yy_switch_to_buffer( b , yyscanner );
 
 	return b;
 }
 
-/** Setup the input buffer state to scan a string. The next call to xlu__cfg_yylex() will
+/** Setup the input buffer state to scan a string. The next call to yylex() will
  * scan from a @e copy of @a str.
  * @param yystr a NUL-terminated string to scan
  * @param yyscanner The scanner object.
  * @return the newly allocated buffer state object.
  * @note If you want to scan bytes that may contain NUL values, then use
- *       xlu__cfg_yy_scan_bytes() instead.
+ *       yy_scan_bytes() instead.
  */
-YY_BUFFER_STATE xlu__cfg_yy_scan_string (yyconst char * yystr , yyscan_t yyscanner)
+YY_BUFFER_STATE yy_scan_string (const char * yystr , yyscan_t yyscanner)
 {
     
-	return xlu__cfg_yy_scan_bytes(yystr,strlen(yystr) ,yyscanner);
+	return yy_scan_bytes( yystr, (int) strlen(yystr) , yyscanner);
 }
 
-/** Setup the input buffer state to scan the given bytes. The next call to xlu__cfg_yylex() will
+/** Setup the input buffer state to scan the given bytes. The next call to yylex() will
  * scan from a @e copy of @a bytes.
  * @param yybytes the byte buffer to scan
  * @param _yybytes_len the number of bytes in the buffer pointed to by @a bytes.
  * @param yyscanner The scanner object.
  * @return the newly allocated buffer state object.
  */
-YY_BUFFER_STATE xlu__cfg_yy_scan_bytes  (yyconst char * yybytes, yy_size_t  _yybytes_len , yyscan_t yyscanner)
+YY_BUFFER_STATE yy_scan_bytes  (const char * yybytes, int  _yybytes_len , yyscan_t yyscanner)
 {
 	YY_BUFFER_STATE b;
 	char *buf;
 	yy_size_t n;
-	yy_size_t i;
+	int i;
     
 	/* Get memory for full buffer, including space for trailing EOB's. */
-	n = _yybytes_len + 2;
-	buf = (char *) xlu__cfg_yyalloc(n ,yyscanner );
+	n = (yy_size_t) (_yybytes_len + 2);
+	buf = (char *) yyalloc( n , yyscanner );
 	if ( ! buf )
-		YY_FATAL_ERROR( "out of dynamic memory in xlu__cfg_yy_scan_bytes()" );
+		YY_FATAL_ERROR( "out of dynamic memory in yy_scan_bytes()" );
 
 	for ( i = 0; i < _yybytes_len; ++i )
 		buf[i] = yybytes[i];
 
 	buf[_yybytes_len] = buf[_yybytes_len+1] = YY_END_OF_BUFFER_CHAR;
 
-	b = xlu__cfg_yy_scan_buffer(buf,n ,yyscanner);
+	b = yy_scan_buffer( buf, n , yyscanner);
 	if ( ! b )
-		YY_FATAL_ERROR( "bad buffer in xlu__cfg_yy_scan_bytes()" );
+		YY_FATAL_ERROR( "bad buffer in yy_scan_bytes()" );
 
 	/* It's okay to grow etc. this buffer, and we should throw it
 	 * away when we're done.
@@ -1763,9 +1989,11 @@
 #define YY_EXIT_FAILURE 2
 #endif
 
-static void yy_fatal_error (yyconst char* msg , yyscan_t yyscanner)
+static void yynoreturn yy_fatal_error (const char* msg , yyscan_t yyscanner)
 {
-    	(void) fprintf( stderr, "%s\n", msg );
+	struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
+	(void)yyg;
+	fprintf( stderr, "%s\n", msg );
 	exit( YY_EXIT_FAILURE );
 }
 
@@ -1791,7 +2019,7 @@
 /** Get the user-defined data for this scanner.
  * @param yyscanner The scanner object.
  */
-YY_EXTRA_TYPE xlu__cfg_yyget_extra  (yyscan_t yyscanner)
+YY_EXTRA_TYPE yyget_extra  (yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
     return yyextra;
@@ -1800,10 +2028,10 @@
 /** Get the current line number.
  * @param yyscanner The scanner object.
  */
-int xlu__cfg_yyget_lineno  (yyscan_t yyscanner)
+int yyget_lineno  (yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
-    
+
         if (! YY_CURRENT_BUFFER)
             return 0;
     
@@ -1813,10 +2041,10 @@
 /** Get the current column number.
  * @param yyscanner The scanner object.
  */
-int xlu__cfg_yyget_column  (yyscan_t yyscanner)
+int yyget_column  (yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
-    
+
         if (! YY_CURRENT_BUFFER)
             return 0;
     
@@ -1826,7 +2054,7 @@
 /** Get the input stream.
  * @param yyscanner The scanner object.
  */
-FILE *xlu__cfg_yyget_in  (yyscan_t yyscanner)
+FILE *yyget_in  (yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
     return yyin;
@@ -1835,7 +2063,7 @@
 /** Get the output stream.
  * @param yyscanner The scanner object.
  */
-FILE *xlu__cfg_yyget_out  (yyscan_t yyscanner)
+FILE *yyget_out  (yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
     return yyout;
@@ -1844,7 +2072,7 @@
 /** Get the length of the current token.
  * @param yyscanner The scanner object.
  */
-yy_size_t xlu__cfg_yyget_leng  (yyscan_t yyscanner)
+int yyget_leng  (yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
     return yyleng;
@@ -1854,7 +2082,7 @@
  * @param yyscanner The scanner object.
  */
 
-char *xlu__cfg_yyget_text  (yyscan_t yyscanner)
+char *yyget_text  (yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
     return yytext;
@@ -1864,93 +2092,93 @@
  * @param user_defined The data to be associated with this scanner.
  * @param yyscanner The scanner object.
  */
-void xlu__cfg_yyset_extra (YY_EXTRA_TYPE  user_defined , yyscan_t yyscanner)
+void yyset_extra (YY_EXTRA_TYPE  user_defined , yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
     yyextra = user_defined ;
 }
 
 /** Set the current line number.
- * @param line_number
+ * @param _line_number line number
  * @param yyscanner The scanner object.
  */
-void xlu__cfg_yyset_lineno (int  line_number , yyscan_t yyscanner)
+void yyset_lineno (int  _line_number , yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
 
         /* lineno is only valid if an input buffer exists. */
         if (! YY_CURRENT_BUFFER )
-           YY_FATAL_ERROR( "xlu__cfg_yyset_lineno called with no buffer" );
+           YY_FATAL_ERROR( "yyset_lineno called with no buffer" );
     
-    yylineno = line_number;
+    yylineno = _line_number;
 }
 
 /** Set the current column.
- * @param line_number
+ * @param _column_no column number
  * @param yyscanner The scanner object.
  */
-void xlu__cfg_yyset_column (int  column_no , yyscan_t yyscanner)
+void yyset_column (int  _column_no , yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
 
         /* column is only valid if an input buffer exists. */
         if (! YY_CURRENT_BUFFER )
-           YY_FATAL_ERROR( "xlu__cfg_yyset_column called with no buffer" );
+           YY_FATAL_ERROR( "yyset_column called with no buffer" );
     
-    yycolumn = column_no;
+    yycolumn = _column_no;
 }
 
 /** Set the input stream. This does not discard the current
  * input buffer.
- * @param in_str A readable stream.
+ * @param _in_str A readable stream.
  * @param yyscanner The scanner object.
- * @see xlu__cfg_yy_switch_to_buffer
+ * @see yy_switch_to_buffer
  */
-void xlu__cfg_yyset_in (FILE *  in_str , yyscan_t yyscanner)
+void yyset_in (FILE *  _in_str , yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
-    yyin = in_str ;
+    yyin = _in_str ;
 }
 
-void xlu__cfg_yyset_out (FILE *  out_str , yyscan_t yyscanner)
+void yyset_out (FILE *  _out_str , yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
-    yyout = out_str ;
+    yyout = _out_str ;
 }
 
-int xlu__cfg_yyget_debug  (yyscan_t yyscanner)
+int yyget_debug  (yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
     return yy_flex_debug;
 }
 
-void xlu__cfg_yyset_debug (int  bdebug , yyscan_t yyscanner)
+void yyset_debug (int  _bdebug , yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
-    yy_flex_debug = bdebug ;
+    yy_flex_debug = _bdebug ;
 }
 
 /* Accessor methods for yylval and yylloc */
 
-YYSTYPE * xlu__cfg_yyget_lval  (yyscan_t yyscanner)
+YYSTYPE * yyget_lval  (yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
     return yylval;
 }
 
-void xlu__cfg_yyset_lval (YYSTYPE *  yylval_param , yyscan_t yyscanner)
+void yyset_lval (YYSTYPE *  yylval_param , yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
     yylval = yylval_param;
 }
 
-YYLTYPE *xlu__cfg_yyget_lloc  (yyscan_t yyscanner)
+YYLTYPE *yyget_lloc  (yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
     return yylloc;
 }
     
-void xlu__cfg_yyset_lloc (YYLTYPE *  yylloc_param , yyscan_t yyscanner)
+void yyset_lloc (YYLTYPE *  yylloc_param , yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
     yylloc = yylloc_param;
@@ -1958,20 +2186,18 @@
     
 /* User-visible API */
 
-/* xlu__cfg_yylex_init is special because it creates the scanner itself, so it is
+/* yylex_init is special because it creates the scanner itself, so it is
  * the ONLY reentrant function that doesn't take the scanner as the last argument.
  * That's why we explicitly handle the declaration, instead of using our macros.
  */
-
-int xlu__cfg_yylex_init(yyscan_t* ptr_yy_globals)
-
+int yylex_init(yyscan_t* ptr_yy_globals)
 {
     if (ptr_yy_globals == NULL){
         errno = EINVAL;
         return 1;
     }
 
-    *ptr_yy_globals = (yyscan_t) xlu__cfg_yyalloc ( sizeof( struct yyguts_t ), NULL );
+    *ptr_yy_globals = (yyscan_t) yyalloc ( sizeof( struct yyguts_t ), NULL );
 
     if (*ptr_yy_globals == NULL){
         errno = ENOMEM;
@@ -1984,39 +2210,37 @@
     return yy_init_globals ( *ptr_yy_globals );
 }
 
-/* xlu__cfg_yylex_init_extra has the same functionality as xlu__cfg_yylex_init, but follows the
+/* yylex_init_extra has the same functionality as yylex_init, but follows the
  * convention of taking the scanner as the last argument. Note however, that
  * this is a *pointer* to a scanner, as it will be allocated by this call (and
  * is the reason, too, why this function also must handle its own declaration).
- * The user defined value in the first argument will be available to xlu__cfg_yyalloc in
+ * The user defined value in the first argument will be available to yyalloc in
  * the yyextra field.
  */
-
-int xlu__cfg_yylex_init_extra(YY_EXTRA_TYPE yy_user_defined,yyscan_t* ptr_yy_globals )
-
+int yylex_init_extra( YY_EXTRA_TYPE yy_user_defined, yyscan_t* ptr_yy_globals )
 {
     struct yyguts_t dummy_yyguts;
 
-    xlu__cfg_yyset_extra (yy_user_defined, &dummy_yyguts);
+    yyset_extra (yy_user_defined, &dummy_yyguts);
 
     if (ptr_yy_globals == NULL){
         errno = EINVAL;
         return 1;
     }
-	
-    *ptr_yy_globals = (yyscan_t) xlu__cfg_yyalloc ( sizeof( struct yyguts_t ), &dummy_yyguts );
-	
+
+    *ptr_yy_globals = (yyscan_t) yyalloc ( sizeof( struct yyguts_t ), &dummy_yyguts );
+
     if (*ptr_yy_globals == NULL){
         errno = ENOMEM;
         return 1;
     }
-    
+
     /* By setting to 0xAA, we expose bugs in
     yy_init_globals. Leave at 0x00 for releases. */
     memset(*ptr_yy_globals,0x00,sizeof(struct yyguts_t));
-    
-    xlu__cfg_yyset_extra (yy_user_defined, *ptr_yy_globals);
-    
+
+    yyset_extra (yy_user_defined, *ptr_yy_globals);
+
     return yy_init_globals ( *ptr_yy_globals );
 }
 
@@ -2024,13 +2248,13 @@
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
     /* Initialization is the same as for the non-reentrant scanner.
-     * This function is called from xlu__cfg_yylex_destroy(), so don't allocate here.
+     * This function is called from yylex_destroy(), so don't allocate here.
      */
 
-    yyg->yy_buffer_stack = 0;
+    yyg->yy_buffer_stack = NULL;
     yyg->yy_buffer_stack_top = 0;
     yyg->yy_buffer_stack_max = 0;
-    yyg->yy_c_buf_p = (char *) 0;
+    yyg->yy_c_buf_p = NULL;
     yyg->yy_init = 0;
     yyg->yy_start = 0;
 
@@ -2043,42 +2267,42 @@
     yyin = stdin;
     yyout = stdout;
 #else
-    yyin = (FILE *) 0;
-    yyout = (FILE *) 0;
+    yyin = NULL;
+    yyout = NULL;
 #endif
 
     /* For future reference: Set errno on error, since we are called by
-     * xlu__cfg_yylex_init()
+     * yylex_init()
      */
     return 0;
 }
 
-/* xlu__cfg_yylex_destroy is for both reentrant and non-reentrant scanners. */
-int xlu__cfg_yylex_destroy  (yyscan_t yyscanner)
+/* yylex_destroy is for both reentrant and non-reentrant scanners. */
+int yylex_destroy  (yyscan_t yyscanner)
 {
     struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
 
     /* Pop the buffer stack, destroying each element. */
 	while(YY_CURRENT_BUFFER){
-		xlu__cfg_yy_delete_buffer(YY_CURRENT_BUFFER ,yyscanner );
+		yy_delete_buffer( YY_CURRENT_BUFFER , yyscanner );
 		YY_CURRENT_BUFFER_LVALUE = NULL;
-		xlu__cfg_yypop_buffer_state(yyscanner);
+		yypop_buffer_state(yyscanner);
 	}
 
 	/* Destroy the stack itself. */
-	xlu__cfg_yyfree(yyg->yy_buffer_stack ,yyscanner);
+	yyfree(yyg->yy_buffer_stack , yyscanner);
 	yyg->yy_buffer_stack = NULL;
 
     /* Destroy the start condition stack. */
-        xlu__cfg_yyfree(yyg->yy_start_stack ,yyscanner );
+        yyfree( yyg->yy_start_stack , yyscanner );
         yyg->yy_start_stack = NULL;
 
     /* Reset the globals. This is important in a non-reentrant scanner so the next time
-     * xlu__cfg_yylex() is called, initialization will occur. */
+     * yylex() is called, initialization will occur. */
     yy_init_globals( yyscanner);
 
     /* Destroy the main struct (reentrant only). */
-    xlu__cfg_yyfree ( yyscanner , yyscanner );
+    yyfree ( yyscanner , yyscanner );
     yyscanner = NULL;
     return 0;
 }
@@ -2088,18 +2312,21 @@
  */
 
 #ifndef yytext_ptr
-static void yy_flex_strncpy (char* s1, yyconst char * s2, int n , yyscan_t yyscanner)
+static void yy_flex_strncpy (char* s1, const char * s2, int n , yyscan_t yyscanner)
 {
-	register int i;
+	struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
+	(void)yyg;
+
+	int i;
 	for ( i = 0; i < n; ++i )
 		s1[i] = s2[i];
 }
 #endif
 
 #ifdef YY_NEED_STRLEN
-static int yy_flex_strlen (yyconst char * s , yyscan_t yyscanner)
+static int yy_flex_strlen (const char * s , yyscan_t yyscanner)
 {
-	register int n;
+	int n;
 	for ( n = 0; s[n]; ++n )
 		;
 
@@ -2107,13 +2334,18 @@
 }
 #endif
 
-void *xlu__cfg_yyalloc (yy_size_t  size , yyscan_t yyscanner)
+void *yyalloc (yy_size_t  size , yyscan_t yyscanner)
 {
-	return (void *) malloc( size );
+	struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
+	(void)yyg;
+	return malloc(size);
 }
 
-void *xlu__cfg_yyrealloc  (void * ptr, yy_size_t  size , yyscan_t yyscanner)
+void *yyrealloc  (void * ptr, yy_size_t  size , yyscan_t yyscanner)
 {
+	struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
+	(void)yyg;
+
 	/* The cast to (char *) in the following accommodates both
 	 * implementations that use char* generic pointers, and those
 	 * that use void* generic pointers.  It works with the latter
@@ -2121,14 +2353,16 @@
 	 * any pointer type to void*, and deal with argument conversions
 	 * as though doing an assignment.
 	 */
-	return (void *) realloc( (char *) ptr, size );
+	return realloc(ptr, size);
 }
 
-void xlu__cfg_yyfree (void * ptr , yyscan_t yyscanner)
+void yyfree (void * ptr , yyscan_t yyscanner)
 {
-	free( (char *) ptr );	/* see xlu__cfg_yyrealloc() for (char *) cast */
+	struct yyguts_t * yyg = (struct yyguts_t*)yyscanner;
+	(void)yyg;
+	free( (char *) ptr );	/* see yyrealloc() for (char *) cast */
 }
 
 #define YYTABLES_NAME "yytables"
 
-#line 103 "libxlu_cfg_l.l"
+#line 104 "libxlu_cfg_l.l"
diff -aur ./tools/libxl/libxlu_cfg_l.h ./tools/libxl/libxlu_cfg_l.h
--- ./tools/libxl/libxlu_cfg_l.h	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/libxl/libxlu_cfg_l.h	2020-11-13 20:14:48.000000000 +0100
@@ -12,12 +12,246 @@
 
 #define FLEX_SCANNER
 #define YY_FLEX_MAJOR_VERSION 2
-#define YY_FLEX_MINOR_VERSION 5
-#define YY_FLEX_SUBMINOR_VERSION 39
+#define YY_FLEX_MINOR_VERSION 6
+#define YY_FLEX_SUBMINOR_VERSION 4
 #if YY_FLEX_SUBMINOR_VERSION > 0
 #define FLEX_BETA
 #endif
 
+#ifdef yy_create_buffer
+#define xlu__cfg_yy_create_buffer_ALREADY_DEFINED
+#else
+#define yy_create_buffer xlu__cfg_yy_create_buffer
+#endif
+
+#ifdef yy_delete_buffer
+#define xlu__cfg_yy_delete_buffer_ALREADY_DEFINED
+#else
+#define yy_delete_buffer xlu__cfg_yy_delete_buffer
+#endif
+
+#ifdef yy_scan_buffer
+#define xlu__cfg_yy_scan_buffer_ALREADY_DEFINED
+#else
+#define yy_scan_buffer xlu__cfg_yy_scan_buffer
+#endif
+
+#ifdef yy_scan_string
+#define xlu__cfg_yy_scan_string_ALREADY_DEFINED
+#else
+#define yy_scan_string xlu__cfg_yy_scan_string
+#endif
+
+#ifdef yy_scan_bytes
+#define xlu__cfg_yy_scan_bytes_ALREADY_DEFINED
+#else
+#define yy_scan_bytes xlu__cfg_yy_scan_bytes
+#endif
+
+#ifdef yy_init_buffer
+#define xlu__cfg_yy_init_buffer_ALREADY_DEFINED
+#else
+#define yy_init_buffer xlu__cfg_yy_init_buffer
+#endif
+
+#ifdef yy_flush_buffer
+#define xlu__cfg_yy_flush_buffer_ALREADY_DEFINED
+#else
+#define yy_flush_buffer xlu__cfg_yy_flush_buffer
+#endif
+
+#ifdef yy_load_buffer_state
+#define xlu__cfg_yy_load_buffer_state_ALREADY_DEFINED
+#else
+#define yy_load_buffer_state xlu__cfg_yy_load_buffer_state
+#endif
+
+#ifdef yy_switch_to_buffer
+#define xlu__cfg_yy_switch_to_buffer_ALREADY_DEFINED
+#else
+#define yy_switch_to_buffer xlu__cfg_yy_switch_to_buffer
+#endif
+
+#ifdef yypush_buffer_state
+#define xlu__cfg_yypush_buffer_state_ALREADY_DEFINED
+#else
+#define yypush_buffer_state xlu__cfg_yypush_buffer_state
+#endif
+
+#ifdef yypop_buffer_state
+#define xlu__cfg_yypop_buffer_state_ALREADY_DEFINED
+#else
+#define yypop_buffer_state xlu__cfg_yypop_buffer_state
+#endif
+
+#ifdef yyensure_buffer_stack
+#define xlu__cfg_yyensure_buffer_stack_ALREADY_DEFINED
+#else
+#define yyensure_buffer_stack xlu__cfg_yyensure_buffer_stack
+#endif
+
+#ifdef yylex
+#define xlu__cfg_yylex_ALREADY_DEFINED
+#else
+#define yylex xlu__cfg_yylex
+#endif
+
+#ifdef yyrestart
+#define xlu__cfg_yyrestart_ALREADY_DEFINED
+#else
+#define yyrestart xlu__cfg_yyrestart
+#endif
+
+#ifdef yylex_init
+#define xlu__cfg_yylex_init_ALREADY_DEFINED
+#else
+#define yylex_init xlu__cfg_yylex_init
+#endif
+
+#ifdef yylex_init_extra
+#define xlu__cfg_yylex_init_extra_ALREADY_DEFINED
+#else
+#define yylex_init_extra xlu__cfg_yylex_init_extra
+#endif
+
+#ifdef yylex_destroy
+#define xlu__cfg_yylex_destroy_ALREADY_DEFINED
+#else
+#define yylex_destroy xlu__cfg_yylex_destroy
+#endif
+
+#ifdef yyget_debug
+#define xlu__cfg_yyget_debug_ALREADY_DEFINED
+#else
+#define yyget_debug xlu__cfg_yyget_debug
+#endif
+
+#ifdef yyset_debug
+#define xlu__cfg_yyset_debug_ALREADY_DEFINED
+#else
+#define yyset_debug xlu__cfg_yyset_debug
+#endif
+
+#ifdef yyget_extra
+#define xlu__cfg_yyget_extra_ALREADY_DEFINED
+#else
+#define yyget_extra xlu__cfg_yyget_extra
+#endif
+
+#ifdef yyset_extra
+#define xlu__cfg_yyset_extra_ALREADY_DEFINED
+#else
+#define yyset_extra xlu__cfg_yyset_extra
+#endif
+
+#ifdef yyget_in
+#define xlu__cfg_yyget_in_ALREADY_DEFINED
+#else
+#define yyget_in xlu__cfg_yyget_in
+#endif
+
+#ifdef yyset_in
+#define xlu__cfg_yyset_in_ALREADY_DEFINED
+#else
+#define yyset_in xlu__cfg_yyset_in
+#endif
+
+#ifdef yyget_out
+#define xlu__cfg_yyget_out_ALREADY_DEFINED
+#else
+#define yyget_out xlu__cfg_yyget_out
+#endif
+
+#ifdef yyset_out
+#define xlu__cfg_yyset_out_ALREADY_DEFINED
+#else
+#define yyset_out xlu__cfg_yyset_out
+#endif
+
+#ifdef yyget_leng
+#define xlu__cfg_yyget_leng_ALREADY_DEFINED
+#else
+#define yyget_leng xlu__cfg_yyget_leng
+#endif
+
+#ifdef yyget_text
+#define xlu__cfg_yyget_text_ALREADY_DEFINED
+#else
+#define yyget_text xlu__cfg_yyget_text
+#endif
+
+#ifdef yyget_lineno
+#define xlu__cfg_yyget_lineno_ALREADY_DEFINED
+#else
+#define yyget_lineno xlu__cfg_yyget_lineno
+#endif
+
+#ifdef yyset_lineno
+#define xlu__cfg_yyset_lineno_ALREADY_DEFINED
+#else
+#define yyset_lineno xlu__cfg_yyset_lineno
+#endif
+
+#ifdef yyget_column
+#define xlu__cfg_yyget_column_ALREADY_DEFINED
+#else
+#define yyget_column xlu__cfg_yyget_column
+#endif
+
+#ifdef yyset_column
+#define xlu__cfg_yyset_column_ALREADY_DEFINED
+#else
+#define yyset_column xlu__cfg_yyset_column
+#endif
+
+#ifdef yywrap
+#define xlu__cfg_yywrap_ALREADY_DEFINED
+#else
+#define yywrap xlu__cfg_yywrap
+#endif
+
+#ifdef yyget_lval
+#define xlu__cfg_yyget_lval_ALREADY_DEFINED
+#else
+#define yyget_lval xlu__cfg_yyget_lval
+#endif
+
+#ifdef yyset_lval
+#define xlu__cfg_yyset_lval_ALREADY_DEFINED
+#else
+#define yyset_lval xlu__cfg_yyset_lval
+#endif
+
+#ifdef yyget_lloc
+#define xlu__cfg_yyget_lloc_ALREADY_DEFINED
+#else
+#define yyget_lloc xlu__cfg_yyget_lloc
+#endif
+
+#ifdef yyset_lloc
+#define xlu__cfg_yyset_lloc_ALREADY_DEFINED
+#else
+#define yyset_lloc xlu__cfg_yyset_lloc
+#endif
+
+#ifdef yyalloc
+#define xlu__cfg_yyalloc_ALREADY_DEFINED
+#else
+#define yyalloc xlu__cfg_yyalloc
+#endif
+
+#ifdef yyrealloc
+#define xlu__cfg_yyrealloc_ALREADY_DEFINED
+#else
+#define yyrealloc xlu__cfg_yyrealloc
+#endif
+
+#ifdef yyfree
+#define xlu__cfg_yyfree_ALREADY_DEFINED
+#else
+#define yyfree xlu__cfg_yyfree
+#endif
+
 /* First, we deal with  platform-specific or compiler-specific issues. */
 
 /* begin standard C headers. */
@@ -88,29 +322,23 @@
 #define UINT32_MAX             (4294967295U)
 #endif
 
+#ifndef SIZE_MAX
+#define SIZE_MAX               (~(size_t)0)
+#endif
+
 #endif /* ! C99 */
 
 #endif /* ! FLEXINT_H */
 
-#ifdef __cplusplus
-
-/* The "const" storage-class-modifier is valid. */
-#define YY_USE_CONST
-
-#else	/* ! __cplusplus */
+/* begin standard C++ headers. */
 
-/* C99 requires __STDC__ to be defined as 1. */
-#if defined (__STDC__)
-
-#define YY_USE_CONST
-
-#endif	/* defined (__STDC__) */
-#endif	/* ! __cplusplus */
-
-#ifdef YY_USE_CONST
+/* TODO: this is always defined, so inline it */
 #define yyconst const
+
+#if defined(__GNUC__) && __GNUC__ >= 3
+#define yynoreturn __attribute__((__noreturn__))
 #else
-#define yyconst
+#define yynoreturn
 #endif
 
 /* An opaque pointer. */
@@ -165,12 +393,12 @@
 	/* Size of input buffer in bytes, not including room for EOB
 	 * characters.
 	 */
-	yy_size_t yy_buf_size;
+	int yy_buf_size;
 
 	/* Number of characters read into yy_ch_buf, not including EOB
 	 * characters.
 	 */
-	yy_size_t yy_n_chars;
+	int yy_n_chars;
 
 	/* Whether we "own" the buffer - i.e., we know we created it,
 	 * and can realloc() it to grow it, and should free() it to
@@ -193,7 +421,7 @@
 
     int yy_bs_lineno; /**< The line count. */
     int yy_bs_column; /**< The column count. */
-    
+
 	/* Whether to try to fill the input buffer when we reach the
 	 * end of it.
 	 */
@@ -204,23 +432,23 @@
 	};
 #endif /* !YY_STRUCT_YY_BUFFER_STATE */
 
-void xlu__cfg_yyrestart (FILE *input_file ,yyscan_t yyscanner );
-void xlu__cfg_yy_switch_to_buffer (YY_BUFFER_STATE new_buffer ,yyscan_t yyscanner );
-YY_BUFFER_STATE xlu__cfg_yy_create_buffer (FILE *file,int size ,yyscan_t yyscanner );
-void xlu__cfg_yy_delete_buffer (YY_BUFFER_STATE b ,yyscan_t yyscanner );
-void xlu__cfg_yy_flush_buffer (YY_BUFFER_STATE b ,yyscan_t yyscanner );
-void xlu__cfg_yypush_buffer_state (YY_BUFFER_STATE new_buffer ,yyscan_t yyscanner );
-void xlu__cfg_yypop_buffer_state (yyscan_t yyscanner );
-
-YY_BUFFER_STATE xlu__cfg_yy_scan_buffer (char *base,yy_size_t size ,yyscan_t yyscanner );
-YY_BUFFER_STATE xlu__cfg_yy_scan_string (yyconst char *yy_str ,yyscan_t yyscanner );
-YY_BUFFER_STATE xlu__cfg_yy_scan_bytes (yyconst char *bytes,yy_size_t len ,yyscan_t yyscanner );
-
-void *xlu__cfg_yyalloc (yy_size_t ,yyscan_t yyscanner );
-void *xlu__cfg_yyrealloc (void *,yy_size_t ,yyscan_t yyscanner );
-void xlu__cfg_yyfree (void * ,yyscan_t yyscanner );
+void yyrestart ( FILE *input_file , yyscan_t yyscanner );
+void yy_switch_to_buffer ( YY_BUFFER_STATE new_buffer , yyscan_t yyscanner );
+YY_BUFFER_STATE yy_create_buffer ( FILE *file, int size , yyscan_t yyscanner );
+void yy_delete_buffer ( YY_BUFFER_STATE b , yyscan_t yyscanner );
+void yy_flush_buffer ( YY_BUFFER_STATE b , yyscan_t yyscanner );
+void yypush_buffer_state ( YY_BUFFER_STATE new_buffer , yyscan_t yyscanner );
+void yypop_buffer_state ( yyscan_t yyscanner );
+
+YY_BUFFER_STATE yy_scan_buffer ( char *base, yy_size_t size , yyscan_t yyscanner );
+YY_BUFFER_STATE yy_scan_string ( const char *yy_str , yyscan_t yyscanner );
+YY_BUFFER_STATE yy_scan_bytes ( const char *bytes, int len , yyscan_t yyscanner );
+
+void *yyalloc ( yy_size_t , yyscan_t yyscanner );
+void *yyrealloc ( void *, yy_size_t , yyscan_t yyscanner );
+void yyfree ( void * , yyscan_t yyscanner );
 
-#define xlu__cfg_yywrap(yyscanner) 1
+#define xlu__cfg_yywrap(yyscanner) (/*CONSTCOND*/1)
 #define YY_SKIP_YYWRAP
 
 #define yytext_ptr yytext_r
@@ -243,50 +471,50 @@
 #define YY_EXTRA_TYPE void *
 #endif
 
-int xlu__cfg_yylex_init (yyscan_t* scanner);
+int yylex_init (yyscan_t* scanner);
 
-int xlu__cfg_yylex_init_extra (YY_EXTRA_TYPE user_defined,yyscan_t* scanner);
+int yylex_init_extra ( YY_EXTRA_TYPE user_defined, yyscan_t* scanner);
 
 /* Accessor methods to globals.
    These are made visible to non-reentrant scanners for convenience. */
 
-int xlu__cfg_yylex_destroy (yyscan_t yyscanner );
+int yylex_destroy ( yyscan_t yyscanner );
 
-int xlu__cfg_yyget_debug (yyscan_t yyscanner );
+int yyget_debug ( yyscan_t yyscanner );
 
-void xlu__cfg_yyset_debug (int debug_flag ,yyscan_t yyscanner );
+void yyset_debug ( int debug_flag , yyscan_t yyscanner );
 
-YY_EXTRA_TYPE xlu__cfg_yyget_extra (yyscan_t yyscanner );
+YY_EXTRA_TYPE yyget_extra ( yyscan_t yyscanner );
 
-void xlu__cfg_yyset_extra (YY_EXTRA_TYPE user_defined ,yyscan_t yyscanner );
+void yyset_extra ( YY_EXTRA_TYPE user_defined , yyscan_t yyscanner );
 
-FILE *xlu__cfg_yyget_in (yyscan_t yyscanner );
+FILE *yyget_in ( yyscan_t yyscanner );
 
-void xlu__cfg_yyset_in  (FILE * in_str ,yyscan_t yyscanner );
+void yyset_in  ( FILE * _in_str , yyscan_t yyscanner );
 
-FILE *xlu__cfg_yyget_out (yyscan_t yyscanner );
+FILE *yyget_out ( yyscan_t yyscanner );
 
-void xlu__cfg_yyset_out  (FILE * out_str ,yyscan_t yyscanner );
+void yyset_out  ( FILE * _out_str , yyscan_t yyscanner );
 
-yy_size_t xlu__cfg_yyget_leng (yyscan_t yyscanner );
+			int yyget_leng ( yyscan_t yyscanner );
 
-char *xlu__cfg_yyget_text (yyscan_t yyscanner );
+char *yyget_text ( yyscan_t yyscanner );
 
-int xlu__cfg_yyget_lineno (yyscan_t yyscanner );
+int yyget_lineno ( yyscan_t yyscanner );
 
-void xlu__cfg_yyset_lineno (int line_number ,yyscan_t yyscanner );
+void yyset_lineno ( int _line_number , yyscan_t yyscanner );
 
-int xlu__cfg_yyget_column  (yyscan_t yyscanner );
+int yyget_column  ( yyscan_t yyscanner );
 
-void xlu__cfg_yyset_column (int column_no ,yyscan_t yyscanner );
+void yyset_column ( int _column_no , yyscan_t yyscanner );
 
-YYSTYPE * xlu__cfg_yyget_lval (yyscan_t yyscanner );
+YYSTYPE * yyget_lval ( yyscan_t yyscanner );
 
-void xlu__cfg_yyset_lval (YYSTYPE * yylval_param ,yyscan_t yyscanner );
+void yyset_lval ( YYSTYPE * yylval_param , yyscan_t yyscanner );
 
-       YYLTYPE *xlu__cfg_yyget_lloc (yyscan_t yyscanner );
+       YYLTYPE *yyget_lloc ( yyscan_t yyscanner );
     
-        void xlu__cfg_yyset_lloc (YYLTYPE * yylloc_param ,yyscan_t yyscanner );
+        void yyset_lloc ( YYLTYPE * yylloc_param , yyscan_t yyscanner );
     
 /* Macros after this point can all be overridden by user definitions in
  * section 1.
@@ -294,18 +522,18 @@
 
 #ifndef YY_SKIP_YYWRAP
 #ifdef __cplusplus
-extern "C" int xlu__cfg_yywrap (yyscan_t yyscanner );
+extern "C" int yywrap ( yyscan_t yyscanner );
 #else
-extern int xlu__cfg_yywrap (yyscan_t yyscanner );
+extern int yywrap ( yyscan_t yyscanner );
 #endif
 #endif
 
 #ifndef yytext_ptr
-static void yy_flex_strncpy (char *,yyconst char *,int ,yyscan_t yyscanner);
+static void yy_flex_strncpy ( char *, const char *, int , yyscan_t yyscanner);
 #endif
 
 #ifdef YY_NEED_STRLEN
-static int yy_flex_strlen (yyconst char * ,yyscan_t yyscanner);
+static int yy_flex_strlen ( const char * , yyscan_t yyscanner);
 #endif
 
 #ifndef YY_NO_INPUT
@@ -333,10 +561,10 @@
 #ifndef YY_DECL
 #define YY_DECL_IS_OURS 1
 
-extern int xlu__cfg_yylex \
-               (YYSTYPE * yylval_param,YYLTYPE * yylloc_param ,yyscan_t yyscanner);
+extern int yylex \
+               (YYSTYPE * yylval_param, YYLTYPE * yylloc_param , yyscan_t yyscanner);
 
-#define YY_DECL int xlu__cfg_yylex \
+#define YY_DECL int yylex \
                (YYSTYPE * yylval_param, YYLTYPE * yylloc_param , yyscan_t yyscanner)
 #endif /* !YY_DECL */
 
@@ -354,8 +582,153 @@
 #undef YY_DECL
 #endif
 
-#line 103 "libxlu_cfg_l.l"
+#ifndef xlu__cfg_yy_create_buffer_ALREADY_DEFINED
+#undef yy_create_buffer
+#endif
+#ifndef xlu__cfg_yy_delete_buffer_ALREADY_DEFINED
+#undef yy_delete_buffer
+#endif
+#ifndef xlu__cfg_yy_scan_buffer_ALREADY_DEFINED
+#undef yy_scan_buffer
+#endif
+#ifndef xlu__cfg_yy_scan_string_ALREADY_DEFINED
+#undef yy_scan_string
+#endif
+#ifndef xlu__cfg_yy_scan_bytes_ALREADY_DEFINED
+#undef yy_scan_bytes
+#endif
+#ifndef xlu__cfg_yy_init_buffer_ALREADY_DEFINED
+#undef yy_init_buffer
+#endif
+#ifndef xlu__cfg_yy_flush_buffer_ALREADY_DEFINED
+#undef yy_flush_buffer
+#endif
+#ifndef xlu__cfg_yy_load_buffer_state_ALREADY_DEFINED
+#undef yy_load_buffer_state
+#endif
+#ifndef xlu__cfg_yy_switch_to_buffer_ALREADY_DEFINED
+#undef yy_switch_to_buffer
+#endif
+#ifndef xlu__cfg_yypush_buffer_state_ALREADY_DEFINED
+#undef yypush_buffer_state
+#endif
+#ifndef xlu__cfg_yypop_buffer_state_ALREADY_DEFINED
+#undef yypop_buffer_state
+#endif
+#ifndef xlu__cfg_yyensure_buffer_stack_ALREADY_DEFINED
+#undef yyensure_buffer_stack
+#endif
+#ifndef xlu__cfg_yylex_ALREADY_DEFINED
+#undef yylex
+#endif
+#ifndef xlu__cfg_yyrestart_ALREADY_DEFINED
+#undef yyrestart
+#endif
+#ifndef xlu__cfg_yylex_init_ALREADY_DEFINED
+#undef yylex_init
+#endif
+#ifndef xlu__cfg_yylex_init_extra_ALREADY_DEFINED
+#undef yylex_init_extra
+#endif
+#ifndef xlu__cfg_yylex_destroy_ALREADY_DEFINED
+#undef yylex_destroy
+#endif
+#ifndef xlu__cfg_yyget_debug_ALREADY_DEFINED
+#undef yyget_debug
+#endif
+#ifndef xlu__cfg_yyset_debug_ALREADY_DEFINED
+#undef yyset_debug
+#endif
+#ifndef xlu__cfg_yyget_extra_ALREADY_DEFINED
+#undef yyget_extra
+#endif
+#ifndef xlu__cfg_yyset_extra_ALREADY_DEFINED
+#undef yyset_extra
+#endif
+#ifndef xlu__cfg_yyget_in_ALREADY_DEFINED
+#undef yyget_in
+#endif
+#ifndef xlu__cfg_yyset_in_ALREADY_DEFINED
+#undef yyset_in
+#endif
+#ifndef xlu__cfg_yyget_out_ALREADY_DEFINED
+#undef yyget_out
+#endif
+#ifndef xlu__cfg_yyset_out_ALREADY_DEFINED
+#undef yyset_out
+#endif
+#ifndef xlu__cfg_yyget_leng_ALREADY_DEFINED
+#undef yyget_leng
+#endif
+#ifndef xlu__cfg_yyget_text_ALREADY_DEFINED
+#undef yyget_text
+#endif
+#ifndef xlu__cfg_yyget_lineno_ALREADY_DEFINED
+#undef yyget_lineno
+#endif
+#ifndef xlu__cfg_yyset_lineno_ALREADY_DEFINED
+#undef yyset_lineno
+#endif
+#ifndef xlu__cfg_yyget_column_ALREADY_DEFINED
+#undef yyget_column
+#endif
+#ifndef xlu__cfg_yyset_column_ALREADY_DEFINED
+#undef yyset_column
+#endif
+#ifndef xlu__cfg_yywrap_ALREADY_DEFINED
+#undef yywrap
+#endif
+#ifndef xlu__cfg_yyget_lval_ALREADY_DEFINED
+#undef yyget_lval
+#endif
+#ifndef xlu__cfg_yyset_lval_ALREADY_DEFINED
+#undef yyset_lval
+#endif
+#ifndef xlu__cfg_yyget_lloc_ALREADY_DEFINED
+#undef yyget_lloc
+#endif
+#ifndef xlu__cfg_yyset_lloc_ALREADY_DEFINED
+#undef yyset_lloc
+#endif
+#ifndef xlu__cfg_yyalloc_ALREADY_DEFINED
+#undef yyalloc
+#endif
+#ifndef xlu__cfg_yyrealloc_ALREADY_DEFINED
+#undef yyrealloc
+#endif
+#ifndef xlu__cfg_yyfree_ALREADY_DEFINED
+#undef yyfree
+#endif
+#ifndef xlu__cfg_yytext_ALREADY_DEFINED
+#undef yytext
+#endif
+#ifndef xlu__cfg_yyleng_ALREADY_DEFINED
+#undef yyleng
+#endif
+#ifndef xlu__cfg_yyin_ALREADY_DEFINED
+#undef yyin
+#endif
+#ifndef xlu__cfg_yyout_ALREADY_DEFINED
+#undef yyout
+#endif
+#ifndef xlu__cfg_yy_flex_debug_ALREADY_DEFINED
+#undef yy_flex_debug
+#endif
+#ifndef xlu__cfg_yylineno_ALREADY_DEFINED
+#undef yylineno
+#endif
+#ifndef xlu__cfg_yytables_fload_ALREADY_DEFINED
+#undef yytables_fload
+#endif
+#ifndef xlu__cfg_yytables_destroy_ALREADY_DEFINED
+#undef yytables_destroy
+#endif
+#ifndef xlu__cfg_yyTABLES_NAME_ALREADY_DEFINED
+#undef yyTABLES_NAME
+#endif
+
+#line 104 "libxlu_cfg_l.l"
 
-#line 360 "libxlu_cfg_l.h"
+#line 733 "libxlu_cfg_l.h"
 #undef xlu__cfg_yyIN_HEADER
 #endif /* xlu__cfg_yyHEADER_H */
diff -aur ./tools/libxl/libxlu_cfg_y.c ./tools/libxl/libxlu_cfg_y.c
--- ./tools/libxl/libxlu_cfg_y.c	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/libxl/libxlu_cfg_y.c	2020-11-13 20:14:48.000000000 +0100
@@ -1,8 +1,8 @@
-/* A Bison parser, made by GNU Bison 3.0.2.  */
+/* A Bison parser, made by GNU Bison 3.0.4.  */
 
 /* Bison implementation for Yacc-like parsers in C
 
-   Copyright (C) 1984, 1989-1990, 2000-2013 Free Software Foundation, Inc.
+   Copyright (C) 1984, 1989-1990, 2000-2015 Free Software Foundation, Inc.
 
    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
@@ -44,7 +44,7 @@
 #define YYBISON 1
 
 /* Bison version.  */
-#define YYBISON_VERSION "3.0.2"
+#define YYBISON_VERSION "3.0.4"
 
 /* Skeleton name.  */
 #define YYSKELETON_NAME "yacc.c"
@@ -118,7 +118,7 @@
 
 /* Value type.  */
 #if ! defined YYSTYPE && ! defined YYSTYPE_IS_DECLARED
-typedef union YYSTYPE YYSTYPE;
+
 union YYSTYPE
 {
 #line 25 "libxlu_cfg_y.y" /* yacc.c:355  */
@@ -128,6 +128,8 @@
 
 #line 130 "libxlu_cfg_y.c" /* yacc.c:355  */
 };
+
+typedef union YYSTYPE YYSTYPE;
 # define YYSTYPE_IS_TRIVIAL 1
 # define YYSTYPE_IS_DECLARED 1
 #endif
@@ -154,7 +156,7 @@
 
 /* Copy the second part of user declarations.  */
 
-#line 158 "libxlu_cfg_y.c" /* yacc.c:358  */
+#line 160 "libxlu_cfg_y.c" /* yacc.c:358  */
 
 #ifdef short
 # undef short
@@ -1060,43 +1062,43 @@
           case 3: /* IDENT  */
 #line 40 "libxlu_cfg_y.y" /* yacc.c:1257  */
       { free(((*yyvaluep).string)); }
-#line 1064 "libxlu_cfg_y.c" /* yacc.c:1257  */
+#line 1066 "libxlu_cfg_y.c" /* yacc.c:1257  */
         break;
 
     case 4: /* STRING  */
 #line 40 "libxlu_cfg_y.y" /* yacc.c:1257  */
       { free(((*yyvaluep).string)); }
-#line 1070 "libxlu_cfg_y.c" /* yacc.c:1257  */
+#line 1072 "libxlu_cfg_y.c" /* yacc.c:1257  */
         break;
 
     case 5: /* NUMBER  */
 #line 40 "libxlu_cfg_y.y" /* yacc.c:1257  */
       { free(((*yyvaluep).string)); }
-#line 1076 "libxlu_cfg_y.c" /* yacc.c:1257  */
+#line 1078 "libxlu_cfg_y.c" /* yacc.c:1257  */
         break;
 
     case 18: /* value  */
 #line 43 "libxlu_cfg_y.y" /* yacc.c:1257  */
       { xlu__cfg_value_free(((*yyvaluep).value)); }
-#line 1082 "libxlu_cfg_y.c" /* yacc.c:1257  */
+#line 1084 "libxlu_cfg_y.c" /* yacc.c:1257  */
         break;
 
     case 19: /* atom  */
 #line 40 "libxlu_cfg_y.y" /* yacc.c:1257  */
       { free(((*yyvaluep).string)); }
-#line 1088 "libxlu_cfg_y.c" /* yacc.c:1257  */
+#line 1090 "libxlu_cfg_y.c" /* yacc.c:1257  */
         break;
 
     case 20: /* valuelist  */
 #line 43 "libxlu_cfg_y.y" /* yacc.c:1257  */
       { xlu__cfg_value_free(((*yyvaluep).value)); }
-#line 1094 "libxlu_cfg_y.c" /* yacc.c:1257  */
+#line 1096 "libxlu_cfg_y.c" /* yacc.c:1257  */
         break;
 
     case 21: /* values  */
 #line 43 "libxlu_cfg_y.y" /* yacc.c:1257  */
       { xlu__cfg_value_free(((*yyvaluep).value)); }
-#line 1100 "libxlu_cfg_y.c" /* yacc.c:1257  */
+#line 1102 "libxlu_cfg_y.c" /* yacc.c:1257  */
         break;
 
 
@@ -1390,65 +1392,65 @@
         case 9:
 #line 57 "libxlu_cfg_y.y" /* yacc.c:1646  */
     { xlu__cfg_set_store(ctx,(yyvsp[-2].string),(yyvsp[0].value),(yylsp[0]).first_line); }
-#line 1394 "libxlu_cfg_y.c" /* yacc.c:1646  */
+#line 1396 "libxlu_cfg_y.c" /* yacc.c:1646  */
     break;
 
   case 12:
 #line 62 "libxlu_cfg_y.y" /* yacc.c:1646  */
     { (yyval.value)= xlu__cfg_string_mk(ctx,(yyvsp[0].string),&(yylsp[0])); }
-#line 1400 "libxlu_cfg_y.c" /* yacc.c:1646  */
+#line 1402 "libxlu_cfg_y.c" /* yacc.c:1646  */
     break;
 
   case 13:
 #line 63 "libxlu_cfg_y.y" /* yacc.c:1646  */
     { (yyval.value)= (yyvsp[-1].value); }
-#line 1406 "libxlu_cfg_y.c" /* yacc.c:1646  */
+#line 1408 "libxlu_cfg_y.c" /* yacc.c:1646  */
     break;
 
   case 14:
 #line 65 "libxlu_cfg_y.y" /* yacc.c:1646  */
     { (yyval.string)= (yyvsp[0].string); }
-#line 1412 "libxlu_cfg_y.c" /* yacc.c:1646  */
+#line 1414 "libxlu_cfg_y.c" /* yacc.c:1646  */
     break;
 
   case 15:
 #line 66 "libxlu_cfg_y.y" /* yacc.c:1646  */
     { (yyval.string)= (yyvsp[0].string); }
-#line 1418 "libxlu_cfg_y.c" /* yacc.c:1646  */
+#line 1420 "libxlu_cfg_y.c" /* yacc.c:1646  */
     break;
 
   case 16:
 #line 68 "libxlu_cfg_y.y" /* yacc.c:1646  */
     { (yyval.value)= xlu__cfg_list_mk(ctx,NULL,&yylloc); }
-#line 1424 "libxlu_cfg_y.c" /* yacc.c:1646  */
+#line 1426 "libxlu_cfg_y.c" /* yacc.c:1646  */
     break;
 
   case 17:
 #line 69 "libxlu_cfg_y.y" /* yacc.c:1646  */
     { (yyval.value)= (yyvsp[0].value); }
-#line 1430 "libxlu_cfg_y.c" /* yacc.c:1646  */
+#line 1432 "libxlu_cfg_y.c" /* yacc.c:1646  */
     break;
 
   case 18:
 #line 70 "libxlu_cfg_y.y" /* yacc.c:1646  */
     { (yyval.value)= (yyvsp[-2].value); }
-#line 1436 "libxlu_cfg_y.c" /* yacc.c:1646  */
+#line 1438 "libxlu_cfg_y.c" /* yacc.c:1646  */
     break;
 
   case 19:
 #line 72 "libxlu_cfg_y.y" /* yacc.c:1646  */
     { (yyval.value)= xlu__cfg_list_mk(ctx,(yyvsp[-1].value),&(yylsp[-1])); }
-#line 1442 "libxlu_cfg_y.c" /* yacc.c:1646  */
+#line 1444 "libxlu_cfg_y.c" /* yacc.c:1646  */
     break;
 
   case 20:
 #line 73 "libxlu_cfg_y.y" /* yacc.c:1646  */
     { xlu__cfg_list_append(ctx,(yyvsp[-4].value),(yyvsp[-1].value)); (yyval.value)= (yyvsp[-4].value); }
-#line 1448 "libxlu_cfg_y.c" /* yacc.c:1646  */
+#line 1450 "libxlu_cfg_y.c" /* yacc.c:1646  */
     break;
 
 
-#line 1452 "libxlu_cfg_y.c" /* yacc.c:1646  */
+#line 1454 "libxlu_cfg_y.c" /* yacc.c:1646  */
       default: break;
     }
   /* User semantic actions sometimes alter yychar, and that requires
diff -aur ./tools/libxl/libxlu_cfg_y.h ./tools/libxl/libxlu_cfg_y.h
--- ./tools/libxl/libxlu_cfg_y.h	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/libxl/libxlu_cfg_y.h	2020-11-13 20:14:48.000000000 +0100
@@ -1,8 +1,8 @@
-/* A Bison parser, made by GNU Bison 3.0.2.  */
+/* A Bison parser, made by GNU Bison 3.0.4.  */
 
 /* Bison interface for Yacc-like parsers in C
 
-   Copyright (C) 1984, 1989-1990, 2000-2013 Free Software Foundation, Inc.
+   Copyright (C) 1984, 1989-1990, 2000-2015 Free Software Foundation, Inc.
 
    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
@@ -54,7 +54,7 @@
 
 /* Value type.  */
 #if ! defined YYSTYPE && ! defined YYSTYPE_IS_DECLARED
-typedef union YYSTYPE YYSTYPE;
+
 union YYSTYPE
 {
 #line 25 "libxlu_cfg_y.y" /* yacc.c:1909  */
@@ -64,6 +64,8 @@
 
 #line 66 "libxlu_cfg_y.h" /* yacc.c:1909  */
 };
+
+typedef union YYSTYPE YYSTYPE;
 # define YYSTYPE_IS_TRIVIAL 1
 # define YYSTYPE_IS_DECLARED 1
 #endif
Seulement dans ./tools/libxl: test_fdderegrace
Seulement dans ./tools/libxl: test_timedereg
Seulement dans ./tools/ocaml/xenstored: oxenstored.conf
Seulement dans ./tools/ocaml/xenstored: _paths.h
diff -aur ./tools/qemu-xen/po/bg.po ./tools/qemu-xen/po/bg.po
--- ./tools/qemu-xen/po/bg.po	2017-11-09 16:46:00.000000000 +0100
+++ ./tools/qemu-xen/po/bg.po	2021-04-07 11:46:58.000000000 +0200
@@ -7,7 +7,7 @@
 msgstr ""
 "Project-Id-Version: QEMU 2.6.50\n"
 "Report-Msgid-Bugs-To: qemu-devel@nongnu.org\n"
-"POT-Creation-Date: 2016-12-13 21:46+0000\n"
+"POT-Creation-Date: 2021-04-07 11:46+0200\n"
 "PO-Revision-Date: 2016-06-09 15:54+0300\n"
 "Last-Translator: Alexander Shopov <ash@kambanaria.org>\n"
 "Language-Team: Bulgarian <dict@ludost.net>\n"
@@ -17,74 +17,74 @@
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
 
-#: ui/gtk.c:275
+#: ui/gtk.c:288
 msgid " - Press Ctrl+Alt+G to release grab"
 msgstr "   Ctrl+Alt+G,    "
 
-#: ui/gtk.c:279
+#: ui/gtk.c:292
 msgid " [Paused]"
 msgstr " []"
 
-#: ui/gtk.c:1922
+#: ui/gtk.c:1988
 msgid "_Pause"
 msgstr "_"
 
-#: ui/gtk.c:1928
+#: ui/gtk.c:1994
 msgid "_Reset"
 msgstr "_"
 
-#: ui/gtk.c:1931
+#: ui/gtk.c:1997
 msgid "Power _Down"
 msgstr "_"
 
-#: ui/gtk.c:1937
+#: ui/gtk.c:2003
 msgid "_Quit"
 msgstr "_  "
 
-#: ui/gtk.c:2029
+#: ui/gtk.c:2095
 msgid "_Fullscreen"
 msgstr " _ "
 
-#: ui/gtk.c:2032
+#: ui/gtk.c:2098
 msgid "_Copy"
 msgstr "_"
 
-#: ui/gtk.c:2048
+#: ui/gtk.c:2114
 msgid "Zoom _In"
 msgstr "_"
 
-#: ui/gtk.c:2055
+#: ui/gtk.c:2123
 msgid "Zoom _Out"
 msgstr "_"
 
-#: ui/gtk.c:2062
+#: ui/gtk.c:2130
 msgid "Best _Fit"
 msgstr "_"
 
-#: ui/gtk.c:2069
+#: ui/gtk.c:2137
 msgid "Zoom To _Fit"
 msgstr "_"
 
-#: ui/gtk.c:2075
+#: ui/gtk.c:2143
 msgid "Grab On _Hover"
 msgstr "  _"
 
-#: ui/gtk.c:2078
+#: ui/gtk.c:2146
 msgid "_Grab Input"
 msgstr "  _"
 
-#: ui/gtk.c:2107
+#: ui/gtk.c:2175
 msgid "Show _Tabs"
 msgstr "_"
 
-#: ui/gtk.c:2110
+#: ui/gtk.c:2178
 msgid "Detach Tab"
 msgstr "  "
 
-#: ui/gtk.c:2122
+#: ui/gtk.c:2190
 msgid "_Machine"
 msgstr "_"
 
-#: ui/gtk.c:2127
+#: ui/gtk.c:2195
 msgid "_View"
 msgstr "_"
diff -aur ./tools/qemu-xen/po/de_DE.po ./tools/qemu-xen/po/de_DE.po
--- ./tools/qemu-xen/po/de_DE.po	2017-11-09 16:46:00.000000000 +0100
+++ ./tools/qemu-xen/po/de_DE.po	2021-04-07 11:46:58.000000000 +0200
@@ -6,7 +6,7 @@
 msgstr ""
 "Project-Id-Version: QEMU 1.4.50\n"
 "Report-Msgid-Bugs-To: qemu-devel@nongnu.org\n"
-"POT-Creation-Date: 2016-12-13 21:46+0000\n"
+"POT-Creation-Date: 2021-04-07 11:46+0200\n"
 "PO-Revision-Date: 2012-02-28 16:00+0100\n"
 "Last-Translator: Kevin Wolf <kwolf@redhat.com>\n"
 "Language-Team: Deutsch <de@li.org>\n"
@@ -16,74 +16,74 @@
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n!=1);\n"
 
-#: ui/gtk.c:275
+#: ui/gtk.c:288
 msgid " - Press Ctrl+Alt+G to release grab"
 msgstr " - Strg+Alt+G drcken, um Eingabegerte freizugeben"
 
-#: ui/gtk.c:279
+#: ui/gtk.c:292
 msgid " [Paused]"
 msgstr " [Angehalten]"
 
-#: ui/gtk.c:1922
+#: ui/gtk.c:1988
 msgid "_Pause"
 msgstr "_Angehalten"
 
-#: ui/gtk.c:1928
+#: ui/gtk.c:1994
 msgid "_Reset"
 msgstr "_Reset"
 
-#: ui/gtk.c:1931
+#: ui/gtk.c:1997
 msgid "Power _Down"
 msgstr "_Herunterfahren"
 
-#: ui/gtk.c:1937
+#: ui/gtk.c:2003
 msgid "_Quit"
 msgstr "_Beenden"
 
-#: ui/gtk.c:2029
+#: ui/gtk.c:2095
 msgid "_Fullscreen"
 msgstr "_Vollbild"
 
-#: ui/gtk.c:2032
+#: ui/gtk.c:2098
 msgid "_Copy"
 msgstr "_Kopieren"
 
-#: ui/gtk.c:2048
+#: ui/gtk.c:2114
 msgid "Zoom _In"
 msgstr "_Heranzoomen"
 
-#: ui/gtk.c:2055
+#: ui/gtk.c:2123
 msgid "Zoom _Out"
 msgstr "_Wegzoomen"
 
-#: ui/gtk.c:2062
+#: ui/gtk.c:2130
 msgid "Best _Fit"
 msgstr "_Einpassen"
 
-#: ui/gtk.c:2069
+#: ui/gtk.c:2137
 msgid "Zoom To _Fit"
 msgstr "Auf _Fenstergre skalieren"
 
-#: ui/gtk.c:2075
+#: ui/gtk.c:2143
 msgid "Grab On _Hover"
 msgstr "Tastatur _automatisch einfangen"
 
-#: ui/gtk.c:2078
+#: ui/gtk.c:2146
 msgid "_Grab Input"
 msgstr "_Eingabegerte einfangen"
 
-#: ui/gtk.c:2107
+#: ui/gtk.c:2175
 msgid "Show _Tabs"
 msgstr "Reiter anzeigen"
 
-#: ui/gtk.c:2110
+#: ui/gtk.c:2178
 msgid "Detach Tab"
 msgstr "Reiter abtrennen"
 
-#: ui/gtk.c:2122
+#: ui/gtk.c:2190
 msgid "_Machine"
 msgstr "_Maschine"
 
-#: ui/gtk.c:2127
+#: ui/gtk.c:2195
 msgid "_View"
 msgstr "_Ansicht"
diff -aur ./tools/qemu-xen/po/fr_FR.po ./tools/qemu-xen/po/fr_FR.po
--- ./tools/qemu-xen/po/fr_FR.po	2017-11-09 16:46:00.000000000 +0100
+++ ./tools/qemu-xen/po/fr_FR.po	2021-04-07 11:46:58.000000000 +0200
@@ -6,7 +6,7 @@
 msgstr ""
 "Project-Id-Version: QEMU 1.4.50\n"
 "Report-Msgid-Bugs-To: qemu-devel@nongnu.org\n"
-"POT-Creation-Date: 2016-12-13 21:46+0000\n"
+"POT-Creation-Date: 2021-04-07 11:46+0200\n"
 "PO-Revision-Date: 2014-07-28 23:25+0200\n"
 "Last-Translator: Aurelien Jarno <aurelien@aurel32.net>\n"
 "Language-Team: French <FR@li.org>\n"
@@ -17,74 +17,74 @@
 "Plural-Forms: nplurals=2; plural=n != 1;\n"
 "X-Generator: Lokalize 1.4\n"
 
-#: ui/gtk.c:275
+#: ui/gtk.c:288
 msgid " - Press Ctrl+Alt+G to release grab"
 msgstr "- Appuyer sur Ctrl+Alt+G pour arrter la capture"
 
-#: ui/gtk.c:279
+#: ui/gtk.c:292
 msgid " [Paused]"
 msgstr "[En pause]"
 
-#: ui/gtk.c:1922
+#: ui/gtk.c:1988
 msgid "_Pause"
 msgstr "_Pause"
 
-#: ui/gtk.c:1928
+#: ui/gtk.c:1994
 msgid "_Reset"
 msgstr "_Rinitialiser"
 
-#: ui/gtk.c:1931
+#: ui/gtk.c:1997
 msgid "Power _Down"
 msgstr "_teindre"
 
-#: ui/gtk.c:1937
+#: ui/gtk.c:2003
 msgid "_Quit"
 msgstr "_Quitter"
 
-#: ui/gtk.c:2029
+#: ui/gtk.c:2095
 msgid "_Fullscreen"
 msgstr "Mode _plein cran"
 
-#: ui/gtk.c:2032
+#: ui/gtk.c:2098
 msgid "_Copy"
 msgstr "_Copier"
 
-#: ui/gtk.c:2048
+#: ui/gtk.c:2114
 msgid "Zoom _In"
 msgstr "Zoom _avant"
 
-#: ui/gtk.c:2055
+#: ui/gtk.c:2123
 msgid "Zoom _Out"
 msgstr "_Zoom arrire"
 
-#: ui/gtk.c:2062
+#: ui/gtk.c:2130
 msgid "Best _Fit"
 msgstr "Zoom _idal"
 
-#: ui/gtk.c:2069
+#: ui/gtk.c:2137
 msgid "Zoom To _Fit"
 msgstr "Zoomer pour a_juster"
 
-#: ui/gtk.c:2075
+#: ui/gtk.c:2143
 msgid "Grab On _Hover"
 msgstr "Capturer en _survolant"
 
-#: ui/gtk.c:2078
+#: ui/gtk.c:2146
 msgid "_Grab Input"
 msgstr "_Capturer les entres"
 
-#: ui/gtk.c:2107
+#: ui/gtk.c:2175
 msgid "Show _Tabs"
 msgstr "Montrer les _onglets"
 
-#: ui/gtk.c:2110
+#: ui/gtk.c:2178
 msgid "Detach Tab"
 msgstr "_Dtacher l'onglet"
 
-#: ui/gtk.c:2122
+#: ui/gtk.c:2190
 msgid "_Machine"
 msgstr "_Machine"
 
-#: ui/gtk.c:2127
+#: ui/gtk.c:2195
 msgid "_View"
 msgstr "_Vue"
diff -aur ./tools/qemu-xen/po/hu.po ./tools/qemu-xen/po/hu.po
--- ./tools/qemu-xen/po/hu.po	2017-11-09 16:46:00.000000000 +0100
+++ ./tools/qemu-xen/po/hu.po	2021-04-07 11:46:58.000000000 +0200
@@ -6,7 +6,7 @@
 msgstr ""
 "Project-Id-Version: QEMU 1.4.50\n"
 "Report-Msgid-Bugs-To: qemu-devel@nongnu.org\n"
-"POT-Creation-Date: 2016-12-13 21:46+0000\n"
+"POT-Creation-Date: 2021-04-07 11:46+0200\n"
 "PO-Revision-Date: 2013-05-06 20:42+0200\n"
 "Last-Translator: kos Kovcs <akoskovacs@gmx.com>\n"
 "Language-Team: Hungarian <hu@li.org>\n"
@@ -15,77 +15,77 @@
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 
-#: ui/gtk.c:275
+#: ui/gtk.c:288
 msgid " - Press Ctrl+Alt+G to release grab"
 msgstr " - Nyomj Ctrl+Alt+G-t a bemeneti eszkzk elengedshez"
 
-#: ui/gtk.c:279
+#: ui/gtk.c:292
 msgid " [Paused]"
 msgstr " [Meglltva]"
 
-#: ui/gtk.c:1922
+#: ui/gtk.c:1988
 msgid "_Pause"
 msgstr "_Megllts"
 
-#: ui/gtk.c:1928
+#: ui/gtk.c:1994
 msgid "_Reset"
 msgstr "j_raindts"
 
-#: ui/gtk.c:1931
+#: ui/gtk.c:1997
 msgid "Power _Down"
 msgstr "_Lellts"
 
-#: ui/gtk.c:1937
+#: ui/gtk.c:2003
 msgid "_Quit"
 msgstr ""
 
-#: ui/gtk.c:2029
+#: ui/gtk.c:2095
 msgid "_Fullscreen"
 msgstr ""
 
-#: ui/gtk.c:2032
+#: ui/gtk.c:2098
 msgid "_Copy"
 msgstr ""
 
-#: ui/gtk.c:2048
+#: ui/gtk.c:2114
 #, fuzzy
 msgid "Zoom _In"
 msgstr "Ablakmrethez _igazts"
 
-#: ui/gtk.c:2055
+#: ui/gtk.c:2123
 #, fuzzy
 msgid "Zoom _Out"
 msgstr "Ablakmrethez _igazts"
 
-#: ui/gtk.c:2062
+#: ui/gtk.c:2130
 msgid "Best _Fit"
 msgstr ""
 
-#: ui/gtk.c:2069
+#: ui/gtk.c:2137
 msgid "Zoom To _Fit"
 msgstr "Ablakmrethez _igazts"
 
-#: ui/gtk.c:2075
+#: ui/gtk.c:2143
 msgid "Grab On _Hover"
 msgstr "Automatikus _elfogs"
 
-#: ui/gtk.c:2078
+#: ui/gtk.c:2146
 msgid "_Grab Input"
 msgstr "_Bemeneti eszkzk megragadsa"
 
-#: ui/gtk.c:2107
+#: ui/gtk.c:2175
 msgid "Show _Tabs"
 msgstr "_Flek megjelentse"
 
-#: ui/gtk.c:2110
+#: ui/gtk.c:2178
 msgid "Detach Tab"
 msgstr ""
 
-#: ui/gtk.c:2122
+#: ui/gtk.c:2190
 msgid "_Machine"
 msgstr "_Gp"
 
-#: ui/gtk.c:2127
+#: ui/gtk.c:2195
 msgid "_View"
 msgstr "_Nzet"
 
diff -aur ./tools/qemu-xen/po/it.po ./tools/qemu-xen/po/it.po
--- ./tools/qemu-xen/po/it.po	2017-11-09 16:46:00.000000000 +0100
+++ ./tools/qemu-xen/po/it.po	2021-04-07 11:46:58.000000000 +0200
@@ -6,7 +6,7 @@
 msgstr ""
 "Project-Id-Version: QEMU 1.4.50\n"
 "Report-Msgid-Bugs-To: qemu-devel@nongnu.org\n"
-"POT-Creation-Date: 2016-12-13 21:46+0000\n"
+"POT-Creation-Date: 2021-04-07 11:46+0200\n"
 "PO-Revision-Date: 2014-07-29 08:25+0200\n"
 "Last-Translator: Paolo Bonzini <pbonzini@redhat.com>\n"
 "Language-Team: Italian <it@li.org>\n"
@@ -16,74 +16,74 @@
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=n != 1;\n"
 
-#: ui/gtk.c:275
+#: ui/gtk.c:288
 msgid " - Press Ctrl+Alt+G to release grab"
 msgstr " - Premere Ctrl+Alt+G per rilasciare l'input"
 
-#: ui/gtk.c:279
+#: ui/gtk.c:292
 msgid " [Paused]"
 msgstr " [Pausa]"
 
-#: ui/gtk.c:1922
+#: ui/gtk.c:1988
 msgid "_Pause"
 msgstr "_Pausa"
 
-#: ui/gtk.c:1928
+#: ui/gtk.c:1994
 msgid "_Reset"
 msgstr "_Reset"
 
-#: ui/gtk.c:1931
+#: ui/gtk.c:1997
 msgid "Power _Down"
 msgstr "_Spegni"
 
-#: ui/gtk.c:1937
+#: ui/gtk.c:2003
 msgid "_Quit"
 msgstr "_Esci"
 
-#: ui/gtk.c:2029
+#: ui/gtk.c:2095
 msgid "_Fullscreen"
 msgstr "A t_utto schermo"
 
-#: ui/gtk.c:2032
+#: ui/gtk.c:2098
 msgid "_Copy"
 msgstr "_Copia"
 
-#: ui/gtk.c:2048
+#: ui/gtk.c:2114
 msgid "Zoom _In"
 msgstr "_Aumenta zoom"
 
-#: ui/gtk.c:2055
+#: ui/gtk.c:2123
 msgid "Zoom _Out"
 msgstr "_Riduci zoom"
 
-#: ui/gtk.c:2062
+#: ui/gtk.c:2130
 msgid "Best _Fit"
 msgstr "A_nnulla zoom"
 
-#: ui/gtk.c:2069
+#: ui/gtk.c:2137
 msgid "Zoom To _Fit"
 msgstr "Adatta alla _finestra"
 
-#: ui/gtk.c:2075
+#: ui/gtk.c:2143
 msgid "Grab On _Hover"
 msgstr "Cattura _automatica input"
 
-#: ui/gtk.c:2078
+#: ui/gtk.c:2146
 msgid "_Grab Input"
 msgstr "_Cattura input"
 
-#: ui/gtk.c:2107
+#: ui/gtk.c:2175
 msgid "Show _Tabs"
 msgstr "Mostra _tab"
 
-#: ui/gtk.c:2110
+#: ui/gtk.c:2178
 msgid "Detach Tab"
 msgstr "_Sposta in una nuova finestra"
 
-#: ui/gtk.c:2122
+#: ui/gtk.c:2190
 msgid "_Machine"
 msgstr "_Macchina virtuale"
 
-#: ui/gtk.c:2127
+#: ui/gtk.c:2195
 msgid "_View"
 msgstr "_Visualizza"
diff -aur ./tools/qemu-xen/po/messages.po ./tools/qemu-xen/po/messages.po
--- ./tools/qemu-xen/po/messages.po	2017-11-09 16:46:00.000000000 +0100
+++ ./tools/qemu-xen/po/messages.po	2021-04-07 11:46:58.000000000 +0200
@@ -5,9 +5,9 @@
 #, fuzzy
 msgid ""
 msgstr ""
-"Project-Id-Version: QEMU 2.7.93\n"
+"Project-Id-Version: QEMU 2.10.1\n"
 "Report-Msgid-Bugs-To: qemu-devel@nongnu.org\n"
-"POT-Creation-Date: 2016-12-13 21:46+0000\n"
+"POT-Creation-Date: 2021-04-07 11:46+0200\n"
 "PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
 "Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
 "Language-Team: LANGUAGE <LL@li.org>\n"
@@ -16,74 +16,74 @@
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 
-#: ui/gtk.c:275
+#: ui/gtk.c:288
 msgid " - Press Ctrl+Alt+G to release grab"
 msgstr ""
 
-#: ui/gtk.c:279
+#: ui/gtk.c:292
 msgid " [Paused]"
 msgstr ""
 
-#: ui/gtk.c:1922
+#: ui/gtk.c:1988
 msgid "_Pause"
 msgstr ""
 
-#: ui/gtk.c:1928
+#: ui/gtk.c:1994
 msgid "_Reset"
 msgstr ""
 
-#: ui/gtk.c:1931
+#: ui/gtk.c:1997
 msgid "Power _Down"
 msgstr ""
 
-#: ui/gtk.c:1937
+#: ui/gtk.c:2003
 msgid "_Quit"
 msgstr ""
 
-#: ui/gtk.c:2029
+#: ui/gtk.c:2095
 msgid "_Fullscreen"
 msgstr ""
 
-#: ui/gtk.c:2032
+#: ui/gtk.c:2098
 msgid "_Copy"
 msgstr ""
 
-#: ui/gtk.c:2048
+#: ui/gtk.c:2114
 msgid "Zoom _In"
 msgstr ""
 
-#: ui/gtk.c:2055
+#: ui/gtk.c:2123
 msgid "Zoom _Out"
 msgstr ""
 
-#: ui/gtk.c:2062
+#: ui/gtk.c:2130
 msgid "Best _Fit"
 msgstr ""
 
-#: ui/gtk.c:2069
+#: ui/gtk.c:2137
 msgid "Zoom To _Fit"
 msgstr ""
 
-#: ui/gtk.c:2075
+#: ui/gtk.c:2143
 msgid "Grab On _Hover"
 msgstr ""
 
-#: ui/gtk.c:2078
+#: ui/gtk.c:2146
 msgid "_Grab Input"
 msgstr ""
 
-#: ui/gtk.c:2107
+#: ui/gtk.c:2175
 msgid "Show _Tabs"
 msgstr ""
 
-#: ui/gtk.c:2110
+#: ui/gtk.c:2178
 msgid "Detach Tab"
 msgstr ""
 
-#: ui/gtk.c:2122
+#: ui/gtk.c:2190
 msgid "_Machine"
 msgstr ""
 
-#: ui/gtk.c:2127
+#: ui/gtk.c:2195
 msgid "_View"
 msgstr ""
diff -aur ./tools/qemu-xen/po/tr.po ./tools/qemu-xen/po/tr.po
--- ./tools/qemu-xen/po/tr.po	2017-11-09 16:46:00.000000000 +0100
+++ ./tools/qemu-xen/po/tr.po	2021-04-07 11:46:58.000000000 +0200
@@ -6,7 +6,7 @@
 msgstr ""
 "Project-Id-Version: QEMU 1.4.50\n"
 "Report-Msgid-Bugs-To: qemu-devel@nongnu.org\n"
-"POT-Creation-Date: 2016-12-13 21:46+0000\n"
+"POT-Creation-Date: 2021-04-07 11:46+0200\n"
 "PO-Revision-Date: 2013-04-22 18:35+0300\n"
 "Last-Translator: Ozan alayan <ozancag@gmail.com>\n"
 "Language-Team: Trke <>\n"
@@ -17,76 +17,76 @@
 "Plural-Forms: nplurals=1; plural=0;\n"
 "X-Generator: Gtranslator 2.91.6\n"
 
-#: ui/gtk.c:275
+#: ui/gtk.c:288
 msgid " - Press Ctrl+Alt+G to release grab"
 msgstr " - Yakalamay durdurmak iin Ctrl+Alt+G tularna basn"
 
-#: ui/gtk.c:279
+#: ui/gtk.c:292
 msgid " [Paused]"
 msgstr " [Duraklatld]"
 
-#: ui/gtk.c:1922
+#: ui/gtk.c:1988
 msgid "_Pause"
 msgstr "_Duraklat"
 
-#: ui/gtk.c:1928
+#: ui/gtk.c:1994
 msgid "_Reset"
 msgstr "_Sfrla"
 
-#: ui/gtk.c:1931
+#: ui/gtk.c:1997
 msgid "Power _Down"
 msgstr "_Kapat"
 
-#: ui/gtk.c:1937
+#: ui/gtk.c:2003
 msgid "_Quit"
 msgstr ""
 
-#: ui/gtk.c:2029
+#: ui/gtk.c:2095
 msgid "_Fullscreen"
 msgstr ""
 
-#: ui/gtk.c:2032
+#: ui/gtk.c:2098
 msgid "_Copy"
 msgstr ""
 
-#: ui/gtk.c:2048
+#: ui/gtk.c:2114
 #, fuzzy
 msgid "Zoom _In"
 msgstr "Yaknla ve S_dr"
 
-#: ui/gtk.c:2055
+#: ui/gtk.c:2123
 #, fuzzy
 msgid "Zoom _Out"
 msgstr "Yaknla ve S_dr"
 
-#: ui/gtk.c:2062
+#: ui/gtk.c:2130
 msgid "Best _Fit"
 msgstr ""
 
-#: ui/gtk.c:2069
+#: ui/gtk.c:2137
 msgid "Zoom To _Fit"
 msgstr "Yaknla ve S_dr"
 
-#: ui/gtk.c:2075
+#: ui/gtk.c:2143
 msgid "Grab On _Hover"
 msgstr "_zerindeyken Yakala"
 
-#: ui/gtk.c:2078
+#: ui/gtk.c:2146
 msgid "_Grab Input"
 msgstr "Girdiyi _Yakala"
 
-#: ui/gtk.c:2107
+#: ui/gtk.c:2175
 msgid "Show _Tabs"
 msgstr "Se_kmeleri Gster"
 
-#: ui/gtk.c:2110
+#: ui/gtk.c:2178
 msgid "Detach Tab"
 msgstr ""
 
-#: ui/gtk.c:2122
+#: ui/gtk.c:2190
 msgid "_Machine"
 msgstr "_Makine"
 
-#: ui/gtk.c:2127
+#: ui/gtk.c:2195
 msgid "_View"
 msgstr "_Grntle"
diff -aur ./tools/qemu-xen/po/zh_CN.po ./tools/qemu-xen/po/zh_CN.po
--- ./tools/qemu-xen/po/zh_CN.po	2017-11-09 16:46:00.000000000 +0100
+++ ./tools/qemu-xen/po/zh_CN.po	2021-04-07 11:46:58.000000000 +0200
@@ -6,7 +6,7 @@
 msgstr ""
 "Project-Id-Version: QEMU 2.2\n"
 "Report-Msgid-Bugs-To: qemu-devel@nongnu.org\n"
-"POT-Creation-Date: 2016-12-13 21:46+0000\n"
+"POT-Creation-Date: 2021-04-07 11:46+0200\n"
 "PO-Revision-Date: 2014-07-31 10:00+0800\n"
 "Last-Translator: Fam Zheng <famz@redhat.com>\n"
 "Language-Team: Chinese <zh@li.org>\n"
@@ -17,74 +17,74 @@
 "Plural-Forms: nplurals=2; plural=n != 1;\n"
 "X-Generator: Lokalize 1.4\n"
 
-#: ui/gtk.c:275
+#: ui/gtk.c:288
 msgid " - Press Ctrl+Alt+G to release grab"
 msgstr " -  Ctrl+Alt+G "
 
-#: ui/gtk.c:279
+#: ui/gtk.c:292
 msgid " [Paused]"
 msgstr "[]"
 
-#: ui/gtk.c:1922
+#: ui/gtk.c:1988
 msgid "_Pause"
 msgstr "(_P)"
 
-#: ui/gtk.c:1928
+#: ui/gtk.c:1994
 msgid "_Reset"
 msgstr "(_R)"
 
-#: ui/gtk.c:1931
+#: ui/gtk.c:1997
 msgid "Power _Down"
 msgstr "(_D)"
 
-#: ui/gtk.c:1937
+#: ui/gtk.c:2003
 msgid "_Quit"
 msgstr "(_Q)"
 
-#: ui/gtk.c:2029
+#: ui/gtk.c:2095
 msgid "_Fullscreen"
 msgstr "(_F)"
 
-#: ui/gtk.c:2032
+#: ui/gtk.c:2098
 msgid "_Copy"
 msgstr "(_C)"
 
-#: ui/gtk.c:2048
+#: ui/gtk.c:2114
 msgid "Zoom _In"
 msgstr "(_I)"
 
-#: ui/gtk.c:2055
+#: ui/gtk.c:2123
 msgid "Zoom _Out"
 msgstr "(_O)"
 
-#: ui/gtk.c:2062
+#: ui/gtk.c:2130
 msgid "Best _Fit"
 msgstr "(_F)"
 
-#: ui/gtk.c:2069
+#: ui/gtk.c:2137
 msgid "Zoom To _Fit"
 msgstr "(_F)"
 
-#: ui/gtk.c:2075
+#: ui/gtk.c:2143
 msgid "Grab On _Hover"
 msgstr "(_H)"
 
-#: ui/gtk.c:2078
+#: ui/gtk.c:2146
 msgid "_Grab Input"
 msgstr "(_G)"
 
-#: ui/gtk.c:2107
+#: ui/gtk.c:2175
 msgid "Show _Tabs"
 msgstr "(_T)"
 
-#: ui/gtk.c:2110
+#: ui/gtk.c:2178
 msgid "Detach Tab"
 msgstr ""
 
-#: ui/gtk.c:2122
+#: ui/gtk.c:2190
 msgid "_Machine"
 msgstr "(_M)"
 
-#: ui/gtk.c:2127
+#: ui/gtk.c:2195
 msgid "_View"
 msgstr "(_V)"
Seulement dans ./tools/qemu-xen/scripts/tracetool/backend: __init__.pyc
Seulement dans ./tools/qemu-xen/scripts/tracetool/backend: log.pyc
Seulement dans ./tools/qemu-xen/scripts/tracetool/format: __init__.pyc
Seulement dans ./tools/qemu-xen/scripts/tracetool: __init__.pyc
Seulement dans ./tools/qemu-xen/scripts/tracetool: transform.pyc
diff -aur ./tools/qemu-xen/util/memfd.c ./tools/qemu-xen/util/memfd.c
--- ./tools/qemu-xen/util/memfd.c	2017-11-09 16:46:00.000000000 +0100
+++ ./tools/qemu-xen/util/memfd.c	2021-04-07 11:44:22.000000000 +0200
@@ -37,7 +37,7 @@
 #include <sys/syscall.h>
 #include <asm/unistd.h>
 
-static int memfd_create(const char *name, unsigned int flags)
+int memfd_create(const char *name, unsigned int flags)
 {
 #ifdef __NR_memfd_create
     return syscall(__NR_memfd_create, name, flags);
Seulement dans ./tools: qemu-xen-build
Seulement dans ./tools: qemu-xen-dir
Seulement dans ./tools: qemu-xen-traditional-dir
diff -aur ./tools/tests/xenstore/xs-test.c ./tools/tests/xenstore/xs-test.c
--- ./tools/tests/xenstore/xs-test.c	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/tests/xenstore/xs-test.c	2020-11-13 20:14:48.000000000 +0100
@@ -445,7 +445,7 @@
 
 int main(int argc, char *argv[])
 {
-    int opt, t, iters = 1, ret = 0, randtime = 0;
+    int opt, t, iters = 1, ret = 0, randtime = 0, return_asprintf = 0;
     char *test = NULL;
     bool list = false;
     time_t stop;
@@ -482,11 +482,11 @@
         return 0;
     }
 
-    asprintf(&path, "%s/%u", TEST_PATH, getpid());
+    return_asprintf = asprintf(&path, "%s/%u", TEST_PATH, getpid());
     for ( t = 0; t < WRITE_BUFFERS_N; t++ )
     {
         memset(write_buffers[t], 'a' + t, WRITE_BUFFERS_SIZE);
-        asprintf(&paths[t], "%s/%c", path, 'a' + t);
+        return_asprintf = asprintf(&paths[t], "%s/%c", path, 'a' + t);
     }
 
     xsh = xs_open(0);
Seulement dans ./tools/xenstore: xenstored_probes.d
diff -aur ./tools/xl/xl.c ./tools/xl/xl.c
--- ./tools/xl/xl.c	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/xl/xl.c	2020-11-13 20:14:48.000000000 +0100
@@ -28,6 +28,7 @@
 #include <libxl_utils.h>
 #include <libxlutil.h>
 #include "xl.h"
+//#include <execinfo.h>
 
 xentoollog_logger_stdiostream *logger;
 int dryrun_only;
@@ -51,6 +52,7 @@
 xentoollog_level minmsglevel = minmsglevel_default;
 
 int logfile = 2;
+int is_vtf_cmd = 0;
 
 /* every libxl action in xl uses this same libxl context */
 libxl_ctx *ctx;
@@ -195,6 +197,10 @@
         max_grant_frames = l;
     else {
         libxl_physinfo_init(&physinfo);
+        if(is_vtf_cmd){
+            physinfo.domain_unpriv = LIBXL_DOMAIN_UNPRIV_DOMU;
+            //printf("%d\n", (int)physinfo.domain_unpriv);
+        }
         max_grant_frames = (libxl_get_physinfo(ctx, &physinfo) != 0 ||
                             !(physinfo.max_possible_mfn >> 32))
                            ? 32 : 64;
@@ -366,6 +372,10 @@
     if (ret)
         fprintf(stderr, "Failed to read config file: %s: %s\n",
                 XL_GLOBAL_CONFIG, strerror(errno));
+
+    if(!strcmp(cmd, "vtf"))
+        is_vtf_cmd = 1;
+        
     parse_global_config(XL_GLOBAL_CONFIG, config_data, config_len);
     free(config_data);
 
@@ -389,6 +399,7 @@
         fprintf(stderr, "command not implemented\n");
         ret = EXIT_FAILURE;
     }
+    
 
  xit:
     return ret;
@@ -415,6 +426,28 @@
     int i;
     struct cmd_spec *cmd;
 
+
+   /* void *array[10];
+  size_t size;
+  char **strings, *pText, *pPosition;
+  int find=0;
+
+  size = backtrace (array, 10);
+  strings = backtrace_symbols (array, size);
+
+  printf ("Obtained %zd stack frames.\n", size);
+
+  for (i = 0; i < size && find==0; i++)
+  {
+     pText=strings[i];
+     if((pPosition=strstr(pText, "dummy"))!=NULL)
+	  find=1;
+     //printf ("%s\n", strings[i]);
+  }
+  printf("%s - %d - %d\n", pPosition, find, (int)i);
+  free (strings);*/
+
+
     if (!command || !strcmp(command, "help")) {
         printf("Usage xl [-vfN] <subcommand> [args]\n\n");
         printf("xl full list of subcommands:\n\n");
diff -aur ./tools/xl/xl_cmdtable.c ./tools/xl/xl_cmdtable.c
--- ./tools/xl/xl_cmdtable.c	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/xl/xl_cmdtable.c	2020-11-13 20:14:48.000000000 +0100
@@ -47,6 +47,39 @@
       "-f FILE, --defconfig=FILE\n                     Use the given configuration file.\n"
       "-d                      Enable debug messages.\n"
     },
+    { "vtf",
+      &main_vtf, 0, 0,
+      "Informations about VTF (Virtual Technology Extensions)",
+      "[options] [VMX] [process_pid]",
+      "-l, --list               List VMX supported by the vtf library\n"
+      "-e, --enable             Enable a vtf for this domain\n"
+      "-d, --disable            Disable a vtf for this domain\n"
+      "-h  --help               Print this help."
+    },
+    { "enable-logdirty",
+      &main_enable_logdirty, 1, 1,
+      "Enable log dirty mode for domain <domid>",
+      "[options] [Domain]",
+      "-h                      Print this help.\n"
+    },
+    { "collect-dirty-logs",
+      &main_collect_dirty_logs, 1, 1,
+      "Collect dirty pages from pml buffer for domain <domid>",
+      "[options] [Domain]",
+      "-h                      Print this help.\n"
+    },
+    { "clean-dirty-bitmap",
+      &main_clean_dirty_bitmap, 1, 1,
+      "Clean the dirty bitmap of domain <domid>",
+      "[options] [Domain]",
+      "-h                      Print this help.\n"
+    },
+    { "disable-logdirty",
+      &main_disable_logdirty, 1, 1,
+      "Disable log dirty mode for domain <domid>",
+      "[options] [Domain]",
+      "-h                      Print this help.\n"
+    },
     { "list",
       &main_list, 0, 0,
       "List information about all/some domains",
diff -aur ./tools/xl/xl.h ./tools/xl/xl.h
--- ./tools/xl/xl.h	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/xl/xl.h	2020-11-13 20:14:48.000000000 +0100
@@ -136,6 +136,11 @@
 int main_destroy(int argc, char **argv);
 int main_shutdown(int argc, char **argv);
 int main_reboot(int argc, char **argv);
+int main_vtf(int argc, char **argv);
+int main_collect_dirty_logs(int argc, char **argv);
+int main_clean_dirty_bitmap(int argc, char **argv);
+int main_enable_logdirty(int argc, char **argv);
+int main_disable_logdirty(int argc, char **argv);
 int main_list(int argc, char **argv);
 int main_vm_list(int argc, char **argv);
 int main_create(int argc, char **argv);
diff -aur ./tools/xl/xl_mem.c ./tools/xl/xl_mem.c
--- ./tools/xl/xl_mem.c	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/xl/xl_mem.c	2020-11-13 20:14:48.000000000 +0100
@@ -158,6 +158,18 @@
     return EXIT_SUCCESS;
 }
 
+int main_collect_dirty_logs(int argc, char **argv)
+{
+    uint32_t domid = atoi(argv[1]);
+    return libxl_collect_dirty_logs(ctx, domid);
+}
+
+int main_clean_dirty_bitmap(int argc, char **argv)
+{
+    uint32_t domid = atoi(argv[1]);
+    return libxl_clean_dirty_bitmap(ctx, domid);
+}
+
 /*
  * Local variables:
  * mode: C
diff -aur ./tools/xl/xl_vcpu.c ./tools/xl/xl_vcpu.c
--- ./tools/xl/xl_vcpu.c	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/xl/xl_vcpu.c	2020-11-13 20:14:48.000000000 +0100
@@ -11,12 +11,15 @@
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU Lesser General Public License for more details.
  */
-
+ 
 #include <stdlib.h>
 
 #include <libxl.h>
 #include <libxl_utils.h>
 #include <libxlutil.h>
+#include <sched.h>
+#include <unistd.h>
+#include <sys/resource.h>
 
 #include "xl.h"
 #include "xl_utils.h"
@@ -328,6 +331,54 @@
     return EXIT_SUCCESS;
 }
 
+int main_vtf(int argc, char **argv)
+{
+    #define LIST 1
+    #define ENABLE 2
+    #define DISABLE 3
+
+    int opt, arg=0, pid_idx=0;
+    uint32_t pid_list[25];
+    char *hw = NULL;
+    static struct option opts[] = {
+        {"list", 0, 0, 'l'},
+        {"enable", 1, 0, 'e'},
+        {"disable", 1, 0, 'd'},
+        COMMON_LONG_OPTS
+    };
+
+    SWITCH_FOREACH_OPT(opt, "led", opts, "vtf", 0) {
+        case 'l':
+            arg = LIST;
+            break;
+        case 'e':
+            arg = ENABLE;
+            hw = optarg;
+            break;
+        case 'd':
+            arg = DISABLE;
+            hw = optarg;
+            break;
+        /*default:
+            help("vtf");*/
+    }
+    
+    hw = argv[optind];
+    argc--;
+    
+    if( argc > 3 && !strcmp(argv[++optind], "-p") )
+    {
+        while(optind < argc)
+        {
+            pid_list[pid_idx++] = atoi(argv[++optind]);
+            printf("pid_list[%d] : %d\n", pid_idx-1, pid_list[pid_idx-1]);
+        }
+        pid_list[pid_idx] = (int)(uintptr_t)NULL;
+    }
+    
+    return libxl_vtf(ctx, arg, hw, pid_list);
+}
+
 /*
  * Local variables:
  * mode: C
diff -aur ./tools/xl/xl_vmcontrol.c ./tools/xl/xl_vmcontrol.c
--- ./tools/xl/xl_vmcontrol.c	2017-12-13 12:37:59.000000000 +0100
+++ ./tools/xl/xl_vmcontrol.c	2020-11-13 20:14:48.000000000 +0100
@@ -1214,6 +1214,18 @@
     return 0;
 }
 
+int main_enable_logdirty(int argc, char **argv)
+{
+    uint32_t domid = atoi(argv[1]);
+    return libxl_domain_enable_logdirty(ctx, domid);
+}
+
+int main_disable_logdirty(int argc, char **argv)
+{
+    uint32_t domid = atoi(argv[1]);
+    return libxl_domain_disable_logdirty(ctx, domid);
+}
+
 /*
  * Local variables:
  * mode: C
Seulement dans ./: tools_VM
Seulement dans ./: .vscode
diff -aur ./xen/arch/arm/hvm.c ./xen/arch/arm/hvm.c
--- ./xen/arch/arm/hvm.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/arch/arm/hvm.c	2020-11-13 20:14:48.000000000 +0100
@@ -30,13 +30,22 @@
 #include <public/hvm/hvm_op.h>
 
 #include <asm/hypercall.h>
-
+ 
 long do_hvm_op(unsigned long op, XEN_GUEST_HANDLE_PARAM(void) arg)
 {
     long rc = 0;
 
     switch ( op )
     {
+    /*case HVMOP_vtf_context_switch:
+    {
+        struct xen_hvm_param vtf;
+
+        if ( copy_from_guest(&vtf, arg, 1) )
+            return -EFAULT;
+        
+        printk("pids received prev : , next : ", vtf.index, vtf.value);
+    }*/
     case HVMOP_set_param:
     case HVMOP_get_param:
     {
Seulement dans ./xen/arch/x86/boot: .head.o.d2
diff -aur ./xen/arch/x86/domain.c ./xen/arch/x86/domain.c
--- ./xen/arch/x86/domain.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/arch/x86/domain.c	2020-11-13 20:14:48.000000000 +0100
@@ -379,6 +379,9 @@
 {
     xfree(v->arch.vm_event);
     v->arch.vm_event = NULL;
+    
+    /*if ( v->vtf_info.pml )
+        free_xenheap_pages(v->vtf_info.pml, v->vtf_info.pml_page_order);*/
 
     vcpu_destroy_fpu(v);
 
@@ -593,6 +596,8 @@
     free_perdomain_mappings(d);
 
     free_xenheap_page(d->shared_info);
+    if ( d->vtf_info.pml )
+        free_xenheap_pages(d->vtf_info.pml, d->vtf_info.pml_page_order);
     cleanup_domain_irq_mapping(d);
 
     psr_domain_free(d);
diff -aur ./xen/arch/x86/domctl.c ./xen/arch/x86/domctl.c
--- ./xen/arch/x86/domctl.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/arch/x86/domctl.c	2020-11-13 20:14:48.000000000 +0100
@@ -349,7 +349,7 @@
 
 #define MAX_IOPORTS 0x10000
 
-long arch_do_domctl(
+long arch_do_domctl( 
     struct xen_domctl *domctl, struct domain *d,
     XEN_GUEST_HANDLE_PARAM(xen_domctl_t) u_domctl)
 {
@@ -358,15 +358,23 @@
     long ret = 0;
     bool copyback = false;
     unsigned long i;
-
+ 
     switch ( domctl->cmd )
     {
-
+            
+    case XEN_DOMCTL_vtf:
     case XEN_DOMCTL_shadow_op:
         ret = paging_domctl(d, &domctl->u.shadow_op, u_domctl, 0);
         if ( ret == -ERESTART )
             return hypercall_create_continuation(__HYPERVISOR_arch_1,
-                                                 "h", u_domctl);
+                                                "h", u_domctl);
+        /*if ( ret == -ERESTART ){
+            printk("%ld\n", ret);
+            if(!currd->is_vtf)
+                return hypercall_create_continuation(__HYPERVISOR_arch_1,
+                                                    "h", u_domctl);
+        }*/
+        
         copyback = true;
         break;
 
Seulement dans ./xen/arch/x86/efi: boot.c
Seulement dans ./xen/arch/x86/efi: .boot.o.d2
Seulement dans ./xen/arch/x86/efi: compat.c
Seulement dans ./xen/arch/x86/efi: .compat.o.d2
Seulement dans ./xen/arch/x86/efi: efi.h
Seulement dans ./xen/arch/x86/efi: .relocs-dummy.o.d2
Seulement dans ./xen/arch/x86/efi: runtime.c
Seulement dans ./xen/arch/x86/efi: .runtime.o.d2
diff -aur ./xen/arch/x86/hvm/hvm.c ./xen/arch/x86/hvm/hvm.c
--- ./xen/arch/x86/hvm/hvm.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/arch/x86/hvm/hvm.c	2021-05-31 13:04:33.000000000 +0200
@@ -73,6 +73,8 @@
 #include <public/arch-x86/cpuid.h>
 #include <asm/cpuid.h>
 
+#define SPP_MAX 50
+
 bool_t __read_mostly hvm_enabled;
 
 #ifdef DBG_LEVEL_0
@@ -109,6 +111,14 @@
 static bool_t __initdata opt_altp2m_enabled = 0;
 boolean_param("altp2m", opt_altp2m_enabled);
 
+
+gfn_t spp_gfn;
+ 
+void register_gfn(gfn_t gfn){
+    spp_gfn = gfn;
+}
+
+
 static int cpu_callback(
     struct notifier_block *nfb, unsigned long action, void *hcpu)
 {
@@ -1823,6 +1833,11 @@
         case p2m_access_rwx:
             violation = 0;
             break;
+        case p2m_access_spp:
+            printk("SPP: spp write protect: %lx\n", gpa);
+            violation = npfec.write_access;
+            rc = HVM_SPP_WRITE_PROTECTED;
+            goto out_put_gfn;
         }
 
         if ( violation )
@@ -4786,6 +4801,75 @@
     case HVMOP_altp2m:
         rc = do_altp2m_op(arg);
         break;
+    
+    case HVMOP_set_subpage: {
+        xen_hvm_subpage_t subpage;
+        struct domain *d;
+        if ( copy_from_guest(&subpage, arg, 1 ) )
+            return -EFAULT;
+        d = rcu_lock_domain_by_any_id(subpage.domid);
+        if ( d == NULL )
+            return -ESRCH;
+        if (subpage.dest_gfn == 0) {
+            printk("subpage = 0\n");
+            return -ESRCH;
+        }
+        switch (subpage.op)
+        {
+        case 0:     /* Set Subpage */
+            printk("SET subpage %lx\n", subpage.dest_gfn);
+            rc = p2m_set_subpage(d, (_gfn)(subpage.dest_gfn), subpage.subpage);
+            flush_tlb_all();
+            break;
+        case 1:     /* Unset subpage */
+            printk("UNSET subpage %lx\n", subpage.dest_gfn);
+            rc = p2m_unset_subpage(d, (_gfn)(subpage.dest_gfn), subpage.subpage);
+            flush_tlb_all();
+            break;            
+        case 2:     /* Release PFN */
+            printk("RELASE gfn %lx\n", subpage.dest_gfn);
+            rc = p2m_release_subpage(d, (_gfn)(subpage.dest_gfn));
+            flush_tlb_all();
+            break;
+        case 3:     /* Copy PNF */
+            printk("COPY gfn from %lx to %lx\n", subpage.src_gfn,subpage.dest_gfn);
+            rc = p2m_copy_subpage(d, (_gfn)(subpage.dest_gfn), (_gfn)(subpage.src_gfn));
+            flush_tlb_all();
+            break;
+        default: /* Single Step */              
+        /****    SPP_DEPRACATED
+            rc = p2m_reset_subpage(d, spp_gfn);
+            struct cpu_user_regs *regs = guest_cpu_user_regs();
+            regs->eflags &= ~(X86_EFLAGS_TF);
+            flush_tlb_all();
+        ***/
+            break;
+        }
+        rcu_unlock_domain(d);
+        break;
+     }
+    case HVMOP_release_subpage: {
+        
+        uint64_t tab_gfn[SPP_MAX];
+
+        struct domain *d;
+         if ( copy_from_guest(&tab_gfn, arg, 1 ) )
+             return -EFAULT;
+
+        d = rcu_lock_domain_by_any_id(DOMID_SELF);
+        if ( d == NULL )
+            return -ESRCH;
+
+        int i = 0;
+        while(tab_gfn[i] != 0){
+            printk("release gfn %lx\n", tab_gfn[i]);                
+            rc = p2m_release_subpage(d, tab_gfn[i]);
+            i++;
+        }
+
+        rcu_unlock_domain(d);
+        break; 
+    }
 
     default:
     {
Seulement dans ./xen/arch/x86/hvm/vmx: hashtab.c
diff -aur ./xen/arch/x86/hvm/vmx/vmcs.c ./xen/arch/x86/hvm/vmx/vmcs.c
--- ./xen/arch/x86/hvm/vmx/vmcs.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/arch/x86/hvm/vmx/vmcs.c	2021-04-16 10:22:51.000000000 +0200
@@ -40,6 +40,7 @@
 #include <asm/shadow.h>
 #include <asm/tboot.h>
 #include <asm/apic.h>
+#define SIZE 25
 
 static bool_t __read_mostly opt_vpid_enabled = 1;
 boolean_param("vpid", opt_vpid_enabled);
@@ -50,6 +51,9 @@
 static bool_t __read_mostly opt_apicv_enabled = 1;
 boolean_param("apicv", opt_apicv_enabled);
 
+static bool_t __read_mostly opt_spp_enabled = 1;
+boolean_param("spp_enable", opt_spp_enabled);
+
 /*
  * These two parameters are used to config the controls for Pause-Loop Exiting:
  * ple_gap:    upper bound on the amount of time between two successive
@@ -143,12 +147,20 @@
     P(cpu_has_vmx_virt_exceptions, "Virtualisation Exceptions");
     P(cpu_has_vmx_pml, "Page Modification Logging");
     P(cpu_has_vmx_tsc_scaling, "TSC Scaling");
+    P(cpu_has_vmx_ept_spp, "EPT Sub-page Write Protection");
 #undef P
 
     if ( !printed )
         printk(" - none\n");
 }
 
+void get_vtf_cpuinfo(struct xen_sysctl_vtf_getcpuinfo *info){
+    if(cpu_has_vmx_pml) 
+        info->pml = 1;
+    if(cpu_has_vmx_ept) 
+        info->ept = 1;
+}
+
 static u32 adjust_vmx_controls(
     const char *name, u32 ctl_min, u32 ctl_opt, u32 msr, bool_t *mismatch)
 {
@@ -248,6 +260,8 @@
             opt |= SECONDARY_EXEC_UNRESTRICTED_GUEST;
         if ( opt_pml_enabled )
             opt |= SECONDARY_EXEC_ENABLE_PML;
+        if ( opt_spp_enabled )
+            opt |= SECONDARY_EXEC_ENABLE_SPP;
 
         /*
          * "APIC Register Virtualization" and "Virtual Interrupt Delivery"
@@ -341,6 +355,14 @@
         _vmx_secondary_exec_control &= ~ SECONDARY_EXEC_PAUSE_LOOP_EXITING;
     }
 
+    /* SPP cannot be supported if EPT is not used */
+    if ( !(_vmx_secondary_exec_control & SECONDARY_EXEC_ENABLE_EPT) )
+        _vmx_secondary_exec_control &= ~SECONDARY_EXEC_ENABLE_SPP;
+
+    /* Turn off opt_spp_enabled if SPP feature is not present */
+    if ( !(_vmx_secondary_exec_control & SECONDARY_EXEC_ENABLE_SPP) )
+        opt_spp_enabled = 0;
+
     min = VM_EXIT_ACK_INTR_ON_EXIT;
     opt = VM_EXIT_SAVE_GUEST_PAT | VM_EXIT_LOAD_HOST_PAT |
           VM_EXIT_CLEAR_BNDCFGS;
@@ -1249,6 +1271,13 @@
 
         ept->mfn = pagetable_get_pfn(p2m_get_pagetable(p2m));
         __vmwrite(EPT_POINTER, ept->eptp);
+
+        if (cpu_has_vmx_ept_spp) {
+            printk("--- COUCOCU: EPT and SPP enable ---\n");
+            struct spp_data *spp = &p2m->spptp;
+            spp->mfn = pagetable_get_pfn(p2m_get_spp_pagetable(p2m));
+            __vmwrite(SPPT_POINT, spp->sppt_point);
+        }
     }
 
     if ( paging_mode_hap(d) )
@@ -1428,17 +1457,18 @@
 
 int vmx_vcpu_enable_pml(struct vcpu *v)
 {
-    if ( vmx_vcpu_pml_enabled(v) )
+    if ( !v->domain->is_vtf && vmx_vcpu_pml_enabled(v) )
         return 0;
 
     v->arch.hvm_vmx.pml_pg = v->domain->arch.paging.alloc_page(v->domain);
+
     if ( !v->arch.hvm_vmx.pml_pg )
         return -ENOMEM;
 
     vmx_vmcs_enter(v);
 
     __vmwrite(PML_ADDRESS, page_to_mfn(v->arch.hvm_vmx.pml_pg) << PAGE_SHIFT);
-    __vmwrite(GUEST_PML_INDEX, NR_PML_ENTRIES - 1);
+    __vmwrite(GUEST_PML_INDEX, NR_PML_ENTRIES - 1); //printk("enabled!\n");
 
     v->arch.hvm_vmx.secondary_exec_control |= SECONDARY_EXEC_ENABLE_PML;
 
@@ -1473,7 +1503,9 @@
 void vmx_vcpu_flush_pml_buffer(struct vcpu *v)
 {
     uint64_t *pml_buf;
-    unsigned long pml_idx;
+    unsigned long pml_idx, index;
+    unsigned long *shared_pml;
+    struct vcpu *v0;
 
     ASSERT((v == current) || (!vcpu_runnable(v) && !v->is_running));
     ASSERT(vmx_vcpu_pml_enabled(v));
@@ -1481,13 +1513,11 @@
     vmx_vmcs_enter(v);
 
     __vmread(GUEST_PML_INDEX, &pml_idx);
-
-    /* Do nothing if PML buffer is empty. */
-    if ( pml_idx == (NR_PML_ENTRIES - 1) )
+    
+    if ( pml_idx == (NR_PML_ENTRIES - 1))
         goto out;
 
     pml_buf = __map_domain_page(v->arch.hvm_vmx.pml_pg);
-
     /*
      * PML index can be either 2^16-1 (buffer is full), or 0 ~ NR_PML_ENTRIES-1
      * (buffer is not full), and in latter case PML index always points to next
@@ -1497,9 +1527,11 @@
         pml_idx = 0;
     else
         pml_idx++;
+    
+    v0 = v->domain->vcpu[0];
 
     for ( ; pml_idx < NR_PML_ENTRIES; pml_idx++ )
-    {
+    {                
         unsigned long gfn = pml_buf[pml_idx] >> PAGE_SHIFT;
 
         /*
@@ -1514,8 +1546,30 @@
 
         /* HVM guest: pfn == gfn */
         paging_mark_pfn_dirty(v->domain, _pfn(gfn));
-    }
 
+        if(v->domain->is_vtf)//else don't execute this as it needs for the VM's module to be loaded. Otherwise operations like live migration won't be possible
+        {
+            /* Save GFNs to the shared memory. */
+            spin_lock(&v->domain->vtf_pml_lock);
+
+            //shared_pml[0] stores the index of shared_pml array and shared_pml[1] tells us weither we shall log or not (meaning weither the tracked app is scheduled or not). 
+            shared_pml = v->domain->vtf_info.pml; 
+            
+            index = v->vcpu_id*(v->domain->vtf_info.nr_pml_entries/v->domain->max_vcpus); 
+
+            if (shared_pml && shared_pml[index + 1] != 0 && shared_pml[index] < 50){//v->domain->vtf_info.nr_pml_entries
+                shared_pml[++shared_pml[index] + index] = gfn; 
+                printk("domain%d - vcpu%d [%ld] : %ld - [%ld] : %ld \n", v->domain->domain_id, v->vcpu_id, index, shared_pml[index], (shared_pml[index] + index), shared_pml[shared_pml[index] + index]);
+            }
+
+            // Do nothing if PML buffer is empty. or if the shm has not been reset to 0 by the user
+            if (shared_pml[index] >= 50)
+                send_guest_vcpu_virq(v0, VIRQ_VTF_PML);
+
+            spin_unlock(&v->domain->vtf_pml_lock);
+        }
+    }
+    
     unmap_domain_page(pml_buf);
 
     /* Reset PML index */
@@ -1959,6 +2013,226 @@
 }
 
 /*
+ * For the hashtab
+ */
+
+    /*if(v->domain->is_vtf && v->domain->vtf_pids != NULL)
+    {
+        dt->idx = NR_PML_ENTRIES - 1;
+        dt->pg = v->arch.hvm_vmx.pml_pg;
+        ht = vtf_hashmap_init();
+
+        do{
+            hashtab_insert(ht, (void *)(uintptr_t)v->domain->vtf_pids[i++], dt);
+            if(v->domain->vtf_pids[i]) printk("v->domain->vtf_pids[%d] : %d\n", i, v->domain->vtf_pids[i]);
+        }while(i < SIZE && v->domain->vtf_pids[i]);
+
+        dt->idx = 67;
+        hashtab_insert(ht, (void *)(uintptr_t)1994, dt);
+
+        printk("nb of elements inserted : %d\n", i);
+
+        dt_search = hashtab_search(ht, (void *)(uintptr_t)1994); 
+        printk("idx : %d, -- addr : %px\n", dt_search->idx, &dt_search->pg);
+    }*/
+
+/*struct hashtab *hashtab_create(u32 (*hash_value)(struct hashtab *h,
+						 const void *key),
+            int (*keycmp)(struct hashtab *h, const void *key1,
+			  const void *key2), u32 size)
+{
+    struct hashtab *p = xzalloc(struct hashtab);
+
+    if ( p == NULL )
+        return p;
+
+    p->size = size;
+    p->hash_value = hash_value;
+    p->keycmp = keycmp;
+    p->htable = xzalloc_array(struct hashtab_node *, size);
+    if ( p->htable == NULL )
+    {
+        xfree(p);
+        return NULL;
+    }
+    
+    return p;
+}
+
+int hashtab_insert(struct hashtab *h, void *key, void *datum)
+{
+    u32 hvalue; 
+    struct hashtab_node *prev, *cur, *newnode;
+
+    if ( !h || h->nel == HASHTAB_MAX_NODES )
+        return -EINVAL;
+
+    hvalue = h->hash_value(h, key);
+    prev = NULL;
+    cur = h->htable[hvalue];
+    while ( cur && h->keycmp(h, key, cur->key) > 0 )
+    {
+        prev = cur;
+        cur = cur->next;
+    }
+
+    if ( cur && (h->keycmp(h, key, cur->key) == 0) )
+        return -EEXIST;
+
+    newnode = xzalloc(struct hashtab_node);
+    if ( newnode == NULL )
+        return -ENOMEM;
+    newnode->key = key;
+    newnode->datum = datum;
+    if ( prev )
+    {
+        newnode->next = prev->next;
+        prev->next = newnode;
+    }
+    else
+    {
+        newnode->next = h->htable[hvalue];
+        h->htable[hvalue] = newnode;
+    }
+
+    h->nel++; 
+    return 0;
+}
+
+void *hashtab_search(struct hashtab *h, const void *key)
+{
+    u32 hvalue;
+    struct hashtab_node *cur;
+    
+
+    if ( !h )
+        return NULL;
+    
+    hvalue = h->hash_value(h, key);
+    cur = h->htable[hvalue];
+    while ( cur != NULL && h->keycmp(h, key, cur->key) == 0 )
+        cur = cur->next;
+    
+    if ( cur == NULL || (h->keycmp(h, key, cur->key) == 0) )
+        return NULL;
+    
+    return cur->datum;
+}
+
+void hashtab_destroy(struct hashtab *h)
+{
+    u32 i;
+    struct hashtab_node *cur, *temp;
+
+    if ( !h )
+        return;
+
+    for ( i = 0; i < h->size; i++ )
+    {
+        cur = h->htable[i];
+        while ( cur != NULL )
+        {
+            temp = cur;
+            cur = cur->next;
+            xfree(temp);
+        }
+        h->htable[i] = NULL;
+    }
+
+    xfree(h->htable);
+    h->htable = NULL;
+
+    xfree(h);
+}
+
+int hashtab_map(struct hashtab *h,
+        int (*apply)(void *k, void *d, void *args),
+        void *args)
+{
+    u32 i;
+    int ret;
+    struct hashtab_node *cur;
+
+    if ( !h )
+        return 0;
+
+    for ( i = 0; i < h->size; i++ )
+    {
+        cur = h->htable[i];
+        while ( cur != NULL )
+        {
+            ret = apply(cur->key, cur->datum, args);
+            if ( ret )
+                return ret;
+            cur = cur->next;
+        }
+    }
+    return 0;
+}
+
+
+void hashtab_stat(struct hashtab *h, struct hashtab_info *info)
+{
+    u32 i, chain_len, slots_used, max_chain_len;
+    struct hashtab_node *cur;
+
+    slots_used = 0;
+    max_chain_len = 0;
+    for ( slots_used = max_chain_len = i = 0; i < h->size; i++ )
+    {
+        cur = h->htable[i];
+        if ( cur )
+        {
+            slots_used++;
+            chain_len = 0;
+            while ( cur )
+            {
+                chain_len++;
+                cur = cur->next;
+            }
+
+            if ( chain_len > max_chain_len )
+                max_chain_len = chain_len;
+        }
+    }
+
+    info->slots_used = slots_used;
+    info->max_chain_len = max_chain_len;
+}
+
+unsigned int vtf_hash(struct hashtab *h, const void *key)
+{
+    unsigned int size = h->size, keyp = (unsigned int)(uintptr_t)key;
+
+    return keyp%size;
+}
+
+int vtf_cmp(struct hashtab *h, const void *key1, const void *key2)
+{
+    int keyp1, keyp2;
+
+    keyp1 = (unsigned int)(uintptr_t)key1; 
+    keyp2 = (unsigned int)(uintptr_t)key2;
+
+    return (key1 == key2);
+}
+
+struct hashtab *vtf_hashmap_init(void)
+{
+    return hashtab_create(vtf_hash, vtf_cmp, SIZE);
+}
+
+struct data *new_data(uint32_t idx, struct page_info *pg)
+{
+    struct data *dt = xzalloc(struct data);
+    dt->idx = idx;
+    dt->pg = pg;
+    return dt; 
+}*/
+/*
+ */
+
+/*
  * Local variables:
  * mode: C
  * c-file-style: "BSD"
diff -aur ./xen/arch/x86/hvm/vmx/vmx.c ./xen/arch/x86/hvm/vmx/vmx.c
--- ./xen/arch/x86/hvm/vmx/vmx.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/arch/x86/hvm/vmx/vmx.c	2021-04-20 14:21:46.000000000 +0200
@@ -93,11 +93,13 @@
 
 uint8_t __read_mostly posted_intr_vector;
 static uint8_t __read_mostly pi_wakeup_vector;
+unsigned long pml_exits;
 
 void vmx_pi_per_cpu_init(unsigned int cpu)
 {
     INIT_LIST_HEAD(&per_cpu(vmx_pi_blocking, cpu).list);
     spin_lock_init(&per_cpu(vmx_pi_blocking, cpu).lock);
+    pml_exits = 0;
 }
 
 static void vmx_vcpu_block(struct vcpu *v)
@@ -2517,6 +2519,10 @@
         vmx_function_table.get_guest_bndcfgs = vmx_get_guest_bndcfgs;
     }
 
+        vmx_function_table.hap_capabilities &= ~HVM_HAP_SUPERPAGE_2MB;
+        vmx_function_table.hap_capabilities &= ~HVM_HAP_SUPERPAGE_1GB;
+
+
     setup_vmcs_dump();
 
     lbr_tsx_fixup_check();
@@ -3215,7 +3221,29 @@
     else
         wbinvd();
 }
+/*** SPP_DEPRACATED
+static void spp_handle(struct p2m_domain *p2m, paddr_t gpa)
+{
+   uint64_t bitmap;
+    
+    if (p2m->spp_get_entry(p2m, gaddr_to_gfn(gpa), &bitmap)){
+
+        if (p2m->spp_access_check(bitmap, gpa) == ACCESS_GRANTED) {
+        /* granted acces behavior 
+        /* hardware signel step 
+        printk("ACCESS_GRANTED\n");
+        struct cpu_user_regs *regs = guest_cpu_user_regs();
+        regs->eflags |= X86_EFLAGS_TF;
+        p2m->spp_release(p2m, gaddr_to_gfn(gpa));
+        register_gfn(gaddr_to_gfn(gpa));
 
+        }else{
+            printk("ACCESS_DENIED %llx\n", gpa);
+            hvm_inject_hw_exception(TRAP_gp_fault, 0);
+        }
+    }
+}
+***/
 static void ept_handle_violation(ept_qual_t q, paddr_t gpa)
 {
     unsigned long gla, gfn = gpa >> PAGE_SHIFT;
@@ -3277,6 +3305,14 @@
         break;
     case 1:         // This violation is handled completly
         return;
+    case HVM_SPP_WRITE_PROTECTED: {
+        struct p2m_domain *p = p2m_get_hostp2m(d);
+    /*** SPP_DEPRACATED
+        spp_handle(p, gpa);
+    ***/
+        update_guest_eip();
+        return;
+    }
     case -1:        // This vioaltion should be injected to L1 VMM
         vcpu_nestedhvm(current).nv_vmexit_pending = 1;
         return;
@@ -3509,11 +3545,34 @@
     return vlapic_apicv_write(current, exit_qualification & 0xfff);
 }
 
+static int vmx_handle_spp(spp_qual_t q, paddr_t gpa)
+{
+    if ( q.sppt_miss_type )
+    {
+        /*
+         * SPPT Miss :
+         * Subpage Protection Table not present
+         */
+        printk("SPP miss occured at gpa:%lx\n", gpa);
+
+        return true;
+    }
+
+    /*
+     * SPPT Misconfig
+     * This is probably possible that your sppt table
+     * set as a incorrect format
+     */
+    WARN_ON(1);
+    return false;
+}
+
 void vmx_vmexit_handler(struct cpu_user_regs *regs)
 {
-    unsigned long exit_qualification, exit_reason, idtv_info, intr_info = 0;
-    unsigned int vector = 0, mode;
+    unsigned long exit_qualification, exit_reason, idtv_info, intr_info = 0;//, sleep=0;
+    unsigned int vector = 0, mode; //, diff_t;
     struct vcpu *v = current;
+    //s_time_t start_t=get_s_time(), end_t;
 
     __vmread(GUEST_RIP,    &regs->rip);
     __vmread(GUEST_RSP,    &regs->rsp);
@@ -4097,7 +4156,14 @@
         break;
 
     case EXIT_REASON_PML_FULL:
+        pml_exits = pml_exits+1; 
         vmx_vcpu_flush_pml_buffer(v);
+        /*do{
+            sleep++;
+            end_t = get_s_time();
+            diff_t = end_t - start_t;
+        }while(diff_t < 4000000);*/
+        printk("##pml_exit = %lu\n", pml_exits);
         break;
 
     case EXIT_REASON_XSAVES:
@@ -4112,6 +4178,15 @@
     case EXIT_REASON_ACCESS_LDTR_OR_TR:
         vmx_handle_descriptor_access(exit_reason);
         break;
+    case EXIT_REASON_SPP:
+    {
+        paddr_t gpa;
+
+        __vmread(GUEST_PHYSICAL_ADDRESS, &gpa);
+        __vmread(EXIT_QUALIFICATION, &exit_qualification);
+        vmx_handle_spp(exit_qualification, gpa);
+        break;
+    }
 
     case EXIT_REASON_VMX_PREEMPTION_TIMER_EXPIRED:
     case EXIT_REASON_INVPCID:
diff -aur ./xen/arch/x86/mm/hap/hap.c ./xen/arch/x86/mm/hap/hap.c
--- ./xen/arch/x86/mm/hap/hap.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/arch/x86/mm/hap/hap.c	2021-05-07 16:36:46.000000000 +0200
@@ -446,6 +446,7 @@
 /* return 0 for success, -errno for failure */
 int hap_enable(struct domain *d, u32 mode)
 {
+    printk("hap_enable");
     unsigned int old_pages;
     unsigned int i;
     int rv = 0;
diff -aur ./xen/arch/x86/mm/mem_access.c ./xen/arch/x86/mm/mem_access.c
--- ./xen/arch/x86/mm/mem_access.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/arch/x86/mm/mem_access.c	2021-05-31 13:10:36.000000000 +0200
@@ -30,8 +30,33 @@
 #include <asm/altp2m.h>
 #include <asm/vm_event.h>
 
+#include <xen/domain_page.h>
+#include <xen/sched.h>
+#include <asm/current.h>
+#include <asm/paging.h>
+#include <asm/types.h>
+#include <asm/domain.h>
+#include <asm/p2m.h>
+#include <asm/hvm/vmx/vmx.h>
+#include <asm/hvm/vmx/vmcs.h>
+#include <asm/hvm/nestedhvm.h>
+#include <xen/iommu.h>
+#include <asm/mtrr.h>
+#include <asm/hvm/cacheattr.h>
+#include <xen/keyhandler.h>
+#include <xen/softirq.h>
+ 
+
 #include "mm-locks.h"
 
+#define is_sppt_present(spp_entry)      ((spp_entry)->spp & 0x1)
+#define is_spp_bitmap_present(bitmap)   (bitmap & 0x8000000000000000)
+#define invalidate_bitmap(bitmap)       (bitmap &= 0)
+#define LEAF                            0
+#define validate_bitmap(bitmap)         (bitmap |= 0x8000000000000000)
+#define WRITABLE_BITMAP                 0xD555555555555555
+#define RELEASE                         12
+
 /*
  * Get access type for a gfn.
  * If gfn == INVALID_GFN, gets the default access type.
@@ -465,6 +490,421 @@
     return _p2m_get_mem_access(p2m, gfn, access);
 }
 
+int p2m_set_mem_spp_wp(struct domain *d, gfn_t gfn)
+{
+    struct p2m_domain *p2m = p2m_get_hostp2m(d);
+    mfn_t mfn;
+    p2m_access_t old_a;
+    int rc = -1;
+    p2m_type_t t;
+    spp_entry_t* table;
+    unsigned long gfn_l = gfn_x(gfn);
+    p2m_lock(p2m);
+    mfn = p2m->get_entry(p2m, gfn_l, &t, &old_a, 0, NULL, NULL);
+    if( mfn_eq(mfn, INVALID_MFN) )
+    {
+        printk("invalid mfn %ld\n", mfn);
+        rc = -1;
+        goto unlock_exit;
+    }
+    if ( p2m->update_ept_spp_wp ) {
+        printk("SET: update ept\n");
+        rc = p2m->update_ept_spp_wp(p2m, gfn_l, 1, 0, 1);
+    }
+
+unlock_exit:
+    p2m_unlock(p2m);
+    return rc;
+}
+
+int p2m_release_mem_spp_wp(struct domain *d, gfn_t gfn)
+{
+    struct p2m_domain *p2m = p2m_get_hostp2m(d);
+    mfn_t mfn;
+    p2m_access_t old_a;
+    int rc = -1;
+    p2m_type_t t;
+//    spp_entry_t* table;
+    unsigned long gfn_l = gfn_x(gfn);
+    p2m_lock(p2m);
+    mfn = p2m->get_entry(p2m, gfn_l, &t, &old_a, 0, NULL, NULL);
+    if( mfn_eq(mfn, INVALID_MFN) )
+    {
+        printk("invalid mfn %ld\n", mfn);
+        rc = -1;
+        goto unlock_exit;
+    }
+    if ( p2m->update_ept_spp_wp ) {
+        printk("RELEASE: update ept\n");
+        rc = p2m->update_ept_spp_wp(p2m, gfn_l, 0, 1, 1);
+    }
+/***    
+    table = map_domain_page(_mfn(pagetable_get_pfn(p2m_get_spp_pagetable(p2m))));
+    printk("spp_pagetable %lx\n", _mfn(pagetable_get_pfn(p2m_get_spp_pagetable(p2m))));
+    int r = free_spp_page(p2m, &table,3,&gfn);
+    printk("*****p2m_set_mem_spp_wp_and_free***(%d)***\n", r);
+    unmap_domain_page(table);
+***/
+unlock_exit:
+    p2m_unlock(p2m);
+    return rc;
+}
+
+
+int p2m_unset_mem_spp_wp(struct domain *d, gfn_t gfn)
+{
+    struct p2m_domain *p2m = p2m_get_hostp2m(d);
+    mfn_t mfn;
+    p2m_access_t old_a;
+    int rc = -1;
+    p2m_type_t t;
+    spp_entry_t* table;
+    unsigned long gfn_l = gfn_x(gfn);
+    p2m_lock(p2m);
+    mfn = p2m->get_entry(p2m, gfn_l, &t, &old_a, 0, NULL, NULL);
+    if( mfn_eq(mfn, INVALID_MFN) )
+    {
+        printk("invalid mfn %ld\n", mfn);
+        rc = -1;
+        goto unlock_exit;
+    }
+    if ( p2m->update_ept_spp_wp ) {
+        printk("UNSET: ept read\n");
+        rc = p2m->update_ept_spp_wp(p2m, gfn_l, 0, 0, 0);
+    }
+
+unlock_exit:
+    p2m_unlock(p2m);
+    return rc;
+}
+
+
+static u64 format_spp_spte(u32 spp_wp_bitmap)
+{
+       u64 new_spte = 0;
+       int i = 0;
+
+       /*
+        * One 4K page contains 32 sub-pages, in SPP table L4E, old bits
+        * are reserved, so we need to transfer u32 subpage write
+        * protect bitmap to u64 SPP L4E format.
+        */
+       while ( i < 32 ) {
+               if ( spp_wp_bitmap & (1ULL << i) )
+                       new_spte |= 1ULL << (i * 2);
+
+               i++;
+       }
+
+       return new_spte;
+}
+
+
+bool are_all_bitmap_empty(spp_entry_t* table){
+
+    __u64* tbitmap = (__u64*)map_domain_page(_mfn(table->mfn));
+
+    bool p = true;
+    int i = 0;
+    for(i = 0; i < EPT_PAGETABLE_ENTRIES; i++){
+        if (tbitmap[i] != 0) p = false;
+    }
+    unmap_domain_page(tbitmap);
+    return p;
+}
+
+bool is_empty_li(spp_entry_t* spp_entry){
+    unsigned int  p;
+    int i = 0;
+    while ( i < EPT_PAGETABLE_ENTRIES){
+        if (is_sppt_present(&spp_entry[i])) return false;      
+        i++;
+    }
+    return true;
+}
+
+int check(spp_entry_t *spp_entry, spp_entry_t **table, int level, unsigned long *gfn_remainder){
+
+    spp_entry_t e;
+    int i;
+    e.spp = read_atomic(&(spp_entry->spp));
+    
+
+    if ( !is_sppt_present(&e) )
+    {
+        printk("heck : spp_next_level: spp not present lvl %d\n", level);
+        unmap_domain_page(*table);
+        return 0;
+        
+    }   
+
+
+    unmap_domain_page(*table);
+    *table = map_domain_page(_mfn(e.mfn));
+    *gfn_remainder &= (1UL << level * 9) - 1;
+    return 1;
+}
+
+
+
+/*** free_spp_page
+ * 1 - Leaf:    invalidation de la bitmap
+ *              check du reste de la table
+ *              si vide return 1
+ *              sinon 0
+ * 2 - Middle:  free_spp_page(LVL-1)
+ *              1 - invalidation de l'entre
+ *                  check du reste de la table
+ *                  si vide return 1
+ *                  sinon 0
+ *              2 - return 0
+ * ***/
+int free_spp_page(struct p2m_domain *p2m, spp_entry_t **table, int level, unsigned long *gfn_remainder){
+  
+    int empty;
+    spp_entry_t *spp_entry;
+    __u64 *bitmap;
+    __u32 shift, index;
+    int s;
+    
+
+    if(level == LEAF){
+        printk("LEAF\n");
+        empty = 1;        
+        bitmap = (__u64 *) (*table + *gfn_remainder);
+        write_atomic(bitmap, (__u64) 0);
+
+        if (are_all_bitmap_empty(*table)){
+            printk("all_bitmap_are_empty \n");
+        }else
+            empty = 0;
+        return empty;
+    } else {        
+        //On dtermine l'entre courante sur la page
+        shift = level * 9;
+        index = *gfn_remainder >> shift;
+        spp_entry = (*table) + index;
+
+        s = check(spp_entry,table,level,gfn_remainder);
+        if(!s)
+            return 1;
+
+        //on vrifie si les entres du niveau Li-1 suivant sont libres
+        
+    
+        if (free_spp_page(p2m,table,level -1 , gfn_remainder)){
+            //si oui on invalide l'entre
+            printk("les entres du niveau %d sont libres\n", level - 1);
+            spp_entry->spp = 0;
+            //on verifie si les autres entres de ce niveau sont libres
+            if (is_empty_li(*table)){
+                empty = 1;
+            }
+            else {
+                return 0;
+            }
+        }else {
+            return 0;
+        }
+    }
+    
+    p2m_tlb_flush_sync(p2m);
+    //on supprime la page en mmoire
+    p2m_free_ptp(p2m, mfn_to_page((*table)->mfn));
+    return empty;
+}
+
+
+int p2m_set_spp_page_st(struct domain *d, gfn_t gfn, uint32_t subpage, int ignore)
+{
+    struct p2m_domain *p2m = p2m_get_hostp2m(d);
+    unsigned long gfn_l = gfn_x(gfn);
+    int ret = -1;
+    __u64 old, new;
+    __u32 sub = 0;
+    
+    sub = ~(1 << subpage);
+
+    p2m_lock(p2m);
+    new = format_spp_spte(sub);
+    if (!ignore) {
+        if (p2m->spp_get_entry) {
+            /* bitmap already exist */
+            if (p2m->spp_get_entry(p2m, gfn_l, &old)) new = new & old;            
+      }
+    }
+    if ( p2m->spp_set_entry ) {
+        printk("SET: gfn %lx, bitmap %lx\n", gfn, new);
+        ret = p2m->spp_set_entry(p2m, gfn_l, new);
+	}
+ 
+    p2m_unlock(p2m);
+ 
+    return ret;
+}
+ 
+int p2m_unset_spp_page_st(struct domain *d, gfn_t gfn, uint32_t subpage, int ignore)
+{
+    struct p2m_domain *p2m = p2m_get_hostp2m(d);
+    unsigned long gfn_l = gfn_x(gfn);
+    int ret = -1;
+    __u64 old, new;
+    __u32 sub = 0;
+    
+    sub = 1 << subpage;
+
+    p2m_lock(p2m);
+    new = format_spp_spte(sub);
+    if (p2m->spp_get_entry) {
+        /* bitmap already exist */
+        if (p2m->spp_get_entry(p2m, gfn_l, &old)) {
+            printk("bitmap exist\n");
+            new = new | old;
+        } else {
+            printk("bitmap not exist\n");
+            goto out;
+        }
+    }
+
+    if (new == WRITABLE_BITMAP) {
+        ret = RELEASE;
+        goto out;
+    }
+    if ( p2m->spp_set_entry ) {
+        p2m->spp_set_entry(p2m, gfn_l, new)
+	}
+out:
+    p2m_unlock(p2m);
+    return ret;
+}
+ 
+int p2m_copy_spp_page_st(struct domain *d, gfn_t dest, gfn_t src)
+{
+    struct p2m_domain *p2m = p2m_get_hostp2m(d);
+    unsigned long src_l = gfn_x(src);
+    unsigned long dest_l = gfn_x(dest);
+
+    int ret = 0;
+    __u64 old;
+
+    p2m_type_t t;
+    p2m_access_t a;
+
+    p2m_lock(p2m);
+
+    if (p2m->get_entry_spp(p2m, src, &t, &a, 0, NULL, NULL)) {
+        if (p2m->spp_get_entry){
+            /* bitmap already exist */
+            if (p2m->spp_get_entry(p2m, src_l, &old)) {
+                if ( p2m->spp_set_entry ) {
+                    printk("COPY: dest %lx, src %lx, bitmap %lx\n", dest_l, src_l, old);
+                    p2m->spp_set_entry(p2m, dest_l, old);
+	            }
+            }
+            else {
+                printk("COPY: bitmap doesn't exist\n");
+                ret = -1;
+            }         
+        }
+    }
+    else {
+        ret = 1;
+    }
+    p2m_unlock(p2m);
+
+    return ret;
+}
+
+int p2m_reset_subpage(struct domain *d, gfn_t gfn)
+{
+    int ret;
+
+    ret = p2m_set_mem_spp_wp(d, gfn);
+    if ( ret < 0 )
+     {
+        printk("SPP: Set subpage ept wp failed!! %x\n", ret);
+        return ret;
+    }
+    
+    return ret;
+}
+
+int p2m_release_subpage(struct domain *d, gfn_t gfn)
+{
+    int ret;
+    
+    ret = p2m_release_mem_spp_wp(d, gfn);
+    if ( ret < 0 )
+     {
+        printk("SPP: Set subpage ept wp failed!! %x\n", ret);
+        return ret;
+    }
+    return ret;
+    
+}
+
+int p2m_set_subpage(struct domain *d, gfn_t gfn, uint32_t subpage)
+{
+    int ret;
+    ret = p2m_set_mem_spp_wp(d, gfn);
+    if ( ret < 0 )
+    {
+        printk("SET: ept wp failed!! %x\n", ret);
+        return ret;
+    }
+    printk("SET: ignore = %d\n", ret);
+    ret = p2m_set_spp_page_st(d, gfn, subpage, ret);
+    if ( ret < 0 )
+        printk("SET: Set subpage table failed!! %x\n", ret);
+    
+    return ret;
+}
+
+int p2m_unset_subpage(struct domain *d, gfn_t gfn, uint32_t subpage)
+{
+    int ret;
+    ret = p2m_unset_mem_spp_wp(d, gfn);
+    if ( ret < 0 )
+    {
+        printk("SPP: Unset subpage ept wp failed!! %x\n", ret);
+        return ret;
+    }
+
+    if (ret) {
+        printk("UNSET: useless %x\n", ret);
+    } else {
+        ret = p2m_unset_spp_page_st(d, gfn, subpage, ret);
+        if (ret < 0)
+            printk("UNSET: failed %x\n", ret);
+        else
+            if (ret == RELEASE) {
+                printk("UNSET: now useless %x\n", ret);
+                ret = p2m_release_mem_spp_wp(d, gfn);
+                if ( ret < 0 )
+                    printk("UNSET: ept wp failed!! %x\n", ret);
+            }
+            printk("UNSET: subpage table done %x\n", ret);
+    }
+    return ret;
+}
+ 
+ 
+int p2m_copy_subpage(struct domain *d, gfn_t dest, gfn_t src)
+{
+    int ret;
+ 
+    
+    ret = p2m_set_mem_spp_wp(d, dest);
+    if ( ret < 0 )
+    {
+        printk("COPY: ept wp failed!! %x\n", ret);
+        return ret;
+    }
+    ret = p2m_copy_spp_page_st(d, dest, src);
+    if (ret < 0) printk("SPP: copy subpage %x\n", ret);
+    return ret;
+}
+
 /*
  * Local variables:
  * mode: C
diff -aur ./xen/arch/x86/mm/p2m.c ./xen/arch/x86/mm/p2m.c
--- ./xen/arch/x86/mm/p2m.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/arch/x86/mm/p2m.c	2021-05-07 12:43:27.000000000 +0200
@@ -615,7 +615,9 @@
  */
 int p2m_alloc_table(struct p2m_domain *p2m)
 {
-    mfn_t top_mfn;
+    mfn_t top_mfn, p2m_spp;
+    __u64* tbitmap;
+    int i;
     struct domain *d = p2m->domain;
     int rc = 0;
 
@@ -637,16 +639,30 @@
     }
 
     P2M_PRINTK("allocating p2m table\n");
-
     top_mfn = p2m_alloc_ptp(p2m, 4);
     if ( mfn_eq(top_mfn, INVALID_MFN) )
     {
         p2m_unlock(p2m);
         return -ENOMEM;
     }
+	p2m_spp = p2m_alloc_ptp(p2m, PGT_l4_page_table);
 
-    p2m->phys_table = pagetable_from_mfn(top_mfn);
+    tbitmap = (__u64*)map_domain_page(_mfn(p2m_spp));
+/**    for(i = 0; i < EPT_PAGETABLE_ENTRIES; i++){
+        printk("spp_table[i] = %lx\n", tbitmap[i]);
+    }
+**/    
+    
+    if ( mfn_eq(p2m_spp, INVALID_MFN)  )
+    {
+		printk("spp invalid %d\n", mfn_eq(p2m_spp, INVALID_MFN));
+        p2m_unlock(p2m);
+        return -ENOMEM;
+     }
 
+
+    p2m->phys_table = pagetable_from_mfn(top_mfn);
+ 	p2m->spp_phys_table = pagetable_from_mfn(p2m_spp);
     if ( hap_enabled(d) )
         iommu_share_p2m_table(d);
 
@@ -684,6 +700,7 @@
     p2m_lock(p2m);
     ASSERT(atomic_read(&d->shr_pages) == 0);
     p2m->phys_table = pagetable_null();
+    p2m->spp_phys_table = pagetable_null();
 
     while ( (pg = page_list_remove_head(&p2m->pages)) )
         d->arch.paging.free_page(d, pg);
diff -aur ./xen/arch/x86/mm/p2m-ept.c ./xen/arch/x86/mm/p2m-ept.c
--- ./xen/arch/x86/mm/p2m-ept.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/arch/x86/mm/p2m-ept.c	2021-05-07 17:25:28.000000000 +0200
@@ -38,6 +38,8 @@
 
 #define is_epte_present(ept_entry)      ((ept_entry)->epte & 0x7)
 #define is_epte_superpage(ept_entry)    ((ept_entry)->sp)
+#define is_sppt_present(spp_entry)      ((spp_entry)->spp & 0x1)
+
 static inline bool_t is_epte_valid(ept_entry_t *e)
 {
     /* suppress_ve alone is not considered valid, so mask it off */
@@ -212,6 +214,7 @@
             entry->x = 0;
             break;           
         case p2m_access_rwx:
+        case p2m_access_spp:
             break;
     }
     
@@ -253,6 +256,108 @@
     return 1;
 }
 
+static int spp_set_middle_entry(struct p2m_domain *p2m, spp_entry_t *spp_entry)
+{
+    mfn_t pg;
+
+    pg = p2m_alloc_ptp(p2m, 0);
+    if ( mfn_eq(pg, INVALID_MFN) )
+        return 0;
+
+    spp_entry->spp = 0;
+    spp_entry->mfn = mfn_x(pg);
+
+    spp_entry->present = 1;
+
+    return 1;
+}
+
+/* -------------------------------------------------------------------------------------------------------------------------------------------*/
+/* ajout de ma part */
+static int spp_get_next_level(struct p2m_domain *p2m,
+                          spp_entry_t **table, unsigned long *gfn_remainder,
+                          int next_level)
+{
+    unsigned long mfn;
+    spp_entry_t *spp_entry, e;
+    __u32 shift, index;
+
+   shift = next_level * EPT_TABLE_ORDER;
+
+    index = *gfn_remainder >> shift;
+
+    /* index must be falling into the page */
+    ASSERT(index < EPT_PAGETABLE_ENTRIES);
+
+    spp_entry = (*table) + index;
+
+    
+    e.spp = read_atomic(&(spp_entry->spp));
+
+    if ( !is_sppt_present(&e) )
+    {
+        printk("spp_get_next_level: spp not present\n");
+        return GUEST_TABLE_MAP_FAILED;
+    }
+
+    mfn = e.mfn;
+    unmap_domain_page(*table);
+    *table = map_domain_page(_mfn(mfn));
+    *gfn_remainder &= (1UL << shift) - 1;
+     return GUEST_TABLE_NORMAL_PAGE;
+}
+ 
+
+/* ajout de ma part fin */
+/* -------------------------------------------------------------------------------------------------------------------------------------------*/
+static int spp_next_level(struct p2m_domain *p2m,
+                          spp_entry_t **table, unsigned long *gfn_remainder,
+                          int next_level)
+{
+    unsigned long mfn;
+    u64* map;
+    spp_entry_t *spp_entry, e;
+    __u32 shift, index;
+    int i = 0;
+    u64 zero = (u64) 0;
+    int ret = GUEST_TABLE_NORMAL_PAGE;
+
+    shift = next_level * EPT_TABLE_ORDER;
+ 
+    index = *gfn_remainder >> shift;
+ 
+    /* index must be falling into the page */
+    ASSERT(index < EPT_PAGETABLE_ENTRIES);
+ 
+    spp_entry = (*table) + index;
+ 
+    e.spp = read_atomic(&(spp_entry->spp));
+ 
+    if ( !is_sppt_present(&e) )
+    {        
+        if ( !spp_set_middle_entry(p2m, spp_entry) )
+        {
+            return GUEST_TABLE_MAP_FAILED;
+        } else {
+            e.spp = read_atomic(&(spp_entry->spp));
+        }
+    }
+
+    mfn = e.mfn;
+    printk("spp_table %lx next_level %d\n", mfn, next_level);
+    unmap_domain_page(*table);
+    *table = map_domain_page(_mfn(mfn));
+    *gfn_remainder &= (1UL << shift) - 1;
+/*    if ( next_level == 1 ) {
+        map = (u64*) table;
+        for (i = 0; i < EPT_PAGETABLE_ENTRIES; i++) {
+            printk("spp_table[i] = %lx\n", map[i]);
+        }
+    }
+*/
+    return ret;
+}
+
 /* free ept sub tree behind an entry */
 static void ept_free_entry(struct p2m_domain *p2m, ept_entry_t *ept_entry, int level)
 {
@@ -323,6 +428,7 @@
     return rv;
 }
 
+
 /* Take the currently mapped table, find the corresponding gfn entry,
  * and map the next table, if available.  If the entry is empty
  * and read_only is set, 
@@ -367,8 +473,11 @@
         if ( read_only )
             return GUEST_TABLE_MAP_FAILED;
 
-        if ( !ept_set_middle_entry(p2m, ept_entry) )
+        if ( !ept_set_middle_entry(p2m, ept_entry) ) {
+            printk("guest table map failed\n");
             return GUEST_TABLE_MAP_FAILED;
+        }
+            
         else
             e = atomic_read_ept_entry(ept_entry); /* Refresh */
     }
@@ -667,6 +776,319 @@
     return spurious ? (rc >= 0) : (rc > 0);
 }
 
+static int
+ept_spp_update_wp(struct p2m_domain *p2m, unsigned long gfn, bool spp, bool w, bool change)
+{
+    ept_entry_t *table, *ept_entry = NULL;
+    unsigned long gfn_remainder = gfn;
+    ept_entry_t new_entry = { .epte = 0 };
+    struct ept_data *ept = &p2m->ept;
+    unsigned int i;
+    int ret, rc;
+
+    table = map_domain_page(_mfn(pagetable_get_pfn(p2m_get_pagetable(p2m))));
+    
+    ret = GUEST_TABLE_MAP_FAILED;
+    for ( i = ept->wl; i > 0; i-- )
+    {
+        ret = ept_next_level(p2m, 0, &table, &gfn_remainder, i);
+        if ( ret != GUEST_TABLE_NORMAL_PAGE )
+        {
+            printk("spp_update_wp: guest normal page failed %d\n", ret);
+            rc = -ENOENT;
+            goto out;
+        }
+    }
+
+    ept_entry = table + (gfn_remainder >> (i * EPT_TABLE_ORDER));
+    if ( !is_epte_present(ept_entry) )
+    {
+        printk("spp_update_wp: epte not present\n");
+        rc = -ENOENT;
+        goto out;
+    }
+
+    new_entry = atomic_read_ept_entry(ept_entry);
+    rc = new_entry.w;
+    if (change) {
+        new_entry.spp = spp;
+        new_entry.w = w;
+        new_entry.access = p2m_access_spp;
+        write_atomic(&(ept_entry->epte), new_entry.epte);
+    }
+    
+    if (rc == 1) goto new;
+    rc = 0;
+new:
+    ept_sync_domain(p2m);
+out:
+    unmap_domain_page(table);
+    return rc;
+}
+
+
+/* -------------------------------------------------------------------------------------------------------------------------------------------*/
+
+/* return 1 if succeed, O if failed */
+static int
+spp_get_entry(struct p2m_domain *p2m, unsigned long gfn, uint64_t* result)
+{
+    struct spp_data *spp = &p2m->spptp;
+    unsigned long gfn_remainder = gfn;
+    spp_entry_t *table;
+    __u64 *pspp_bitmap;
+    *result = 0;
+    unsigned int i;
+    int ret;
+    ASSERT(spp);
+    
+    table = map_domain_page(_mfn(pagetable_get_pfn(p2m_get_spp_pagetable(p2m))));
+
+    for ( i = 3; i > 0; i-- )
+    {
+        ret = spp_get_next_level(p2m, &table, &gfn_remainder, i);
+        if ( ret != GUEST_TABLE_NORMAL_PAGE )
+        {
+            printk("error level-%d\n", i);
+            goto out;
+        }
+    }  
+    pspp_bitmap = (__u64 *) (table + gfn_remainder);
+    *result = read_atomic(pspp_bitmap);
+out:
+    unmap_domain_page(table);
+    return ret;
+}
+
+static int
+spp_access_check(__u64 bitmap, __u64 gpa)
+{
+    /* on veut rcuprer l'offset: 12 bits de poids faible */
+    __u64 offset = gpa & 0xfff;
+    /* la subpage correspond au 5 bits de poids fort de l'offset */
+    __u64 subpage = offset >> 7;
+
+    /* on veut le bit qui correspond  la subpage */
+    __u64 access = bitmap >> 2*subpage;
+    return access & 0x1;
+}
+ 
+static int
+ept_spp_release_wp(struct p2m_domain *p2m, unsigned long gfn)
+{
+    ept_entry_t *table, *ept_entry = NULL;
+    unsigned long gfn_remainder = gfn;
+    ept_entry_t new_entry = { .epte = 0 };
+    struct ept_data *ept = &p2m->ept;
+    unsigned int i;
+    int ret, rc = 0;
+    table = map_domain_page(_mfn(pagetable_get_pfn(p2m_get_pagetable(p2m))));
+
+    ret = GUEST_TABLE_MAP_FAILED;
+    for ( i = ept->wl; i > 0; i-- )
+    {
+        ret = ept_next_level(p2m, 0, &table, &gfn_remainder, i);
+        if ( ret != GUEST_TABLE_NORMAL_PAGE )
+        {
+            rc = -ENOENT;
+            goto out;
+        }
+    }
+ 
+    ept_entry = table + (gfn_remainder >> (i * EPT_TABLE_ORDER));
+    if ( !is_epte_present(ept_entry) )
+    {
+        rc = -ENOENT;
+        goto out;
+    }
+ 
+    new_entry = atomic_read_ept_entry(ept_entry);
+    new_entry.w = 1;
+    write_atomic(&(ept_entry->epte), new_entry.epte);
+
+    ept_sync_domain(p2m);
+    rc = 0;
+out:
+    unmap_domain_page(table);
+    return rc;
+}
+
+int
+spp_release(struct p2m_domain *p2m, unsigned long gfn)
+{
+    mfn_t mfn;
+    p2m_access_t old_a;
+    int rc = -1;
+    p2m_type_t t;
+    p2m_lock(p2m);
+    mfn = p2m->get_entry(p2m, gfn, &t, &old_a, 0, NULL, NULL);
+    if( mfn_eq(mfn, INVALID_MFN) )
+    {
+		printk("invalid mfn %ld\n", mfn);
+        rc = -1;
+        goto unlock_exit;
+    }
+ 
+    rc = ept_spp_release_wp(p2m, gfn);
+ 
+unlock_exit:
+    p2m_unlock(p2m);
+    return rc;
+}
+
+static int
+spp_set_entry(struct p2m_domain *p2m, unsigned long gfn, u64 access)
+{
+    struct spp_data *spp = &p2m->spptp;
+    unsigned long gfn_remainder = gfn;
+    spp_entry_t *table;
+    u64 *pspp_bitmap;
+    u64 old_spp_bitmap;
+    unsigned int i;
+    int ret, rc = 0;
+
+    ASSERT(spp);
+    table = map_domain_page(_mfn(pagetable_get_pfn(p2m_get_spp_pagetable(p2m))));
+    printk("spp_set_entry: %lx\n", _mfn(pagetable_get_pfn(p2m_get_spp_pagetable(p2m))));
+    for ( i = 3; i > 0; i-- )
+    {
+        ret = spp_next_level(p2m, &table, &gfn_remainder, i);
+        if ( ret != GUEST_TABLE_NORMAL_PAGE )
+        {
+            printk("dazhang1 error oc ret = %x\n", ret);
+            rc = -1;
+            goto out;
+        }
+    }
+
+    pspp_bitmap = (u64 *) (table + gfn_remainder);
+    old_spp_bitmap = read_atomic(pspp_bitmap);
+    if( old_spp_bitmap != access )
+    {
+        write_atomic(pspp_bitmap, access);
+    }
+
+out:
+    unmap_domain_page(table);
+    return rc;
+}
+
+/* SPP: ept_get_spp returns ept_entry of the corresponding gfn */
+ 
+ 
+ /* Read ept p2m entries */
+static int ept_get_entry_spp(struct p2m_domain *p2m,
+                           gfn_t gfn_, p2m_type_t *t, p2m_access_t* a,
+                           p2m_query_t q, unsigned int *page_order,
+                            bool_t *sve)
+{
+    ept_entry_t *table =
+        map_domain_page(pagetable_get_mfn(p2m_get_pagetable(p2m)));
+    unsigned long gfn = gfn_x(gfn_);
+    unsigned long gfn_remainder = gfn;
+    ept_entry_t *ept_entry;
+    __u32 index;
+    int i;
+    int ret = 0;
+    bool_t recalc = 0;
+    mfn_t mfn = INVALID_MFN;
+    struct ept_data *ept = &p2m->ept;
+    *t = p2m_mmio_dm;
+    *a = p2m_access_n;
+    if ( sve )
+        *sve = 1;
+ 
+    /* This pfn is higher than the highest the p2m map currently holds */
+    if ( gfn > p2m->max_mapped_pfn )
+    {
+        for ( i = ept->wl; i > 0; --i )
+            if ( (gfn & ~((1UL << (i * EPT_TABLE_ORDER)) - 1)) >
+                p2m->max_mapped_pfn )
+                break;
+        goto out;
+    }
+
+    /* Should check if gfn obeys GAW here. */
+ 
+    for ( i = ept->wl; i > 0; i-- )
+    {
+    retry:
+        if ( table[gfn_remainder >> (i * EPT_TABLE_ORDER)].recalc )
+            recalc = 1;
+        ret = ept_next_level(p2m, 1, &table, &gfn_remainder, i);
+        if ( !ret )
+            goto out;
+        else if ( ret == GUEST_TABLE_POD_PAGE )
+        {
+            if ( !(q & P2M_ALLOC) )
+            {
+                *t = p2m_populate_on_demand;
+                goto out;
+            }
+ 
+            /* Populate this superpage */
+            ASSERT(i <= 2);
+
+            index = gfn_remainder >> ( i * EPT_TABLE_ORDER);
+            ept_entry = table + index;
+ 
+            if ( p2m_pod_demand_populate(p2m, gfn_, i * EPT_TABLE_ORDER) )
+                goto retry;
+            else
+                goto out;
+        }
+        else if ( ret == GUEST_TABLE_SUPER_PAGE )
+            break;
+    }
+
+    index = gfn_remainder >> (i * EPT_TABLE_ORDER);
+    ept_entry = table + index;
+    if ( ept_entry->sa_p2mt == p2m_populate_on_demand )
+    {
+        if ( !(q & P2M_ALLOC) )
+        {
+            *t = p2m_populate_on_demand;
+            goto out;
+        }
+
+        ASSERT(i == 0);
+         
+        if ( !p2m_pod_demand_populate(p2m, gfn_, PAGE_ORDER_4K) ){
+            goto out;
+    	}
+    }
+ 
+    if ( is_epte_valid(ept_entry) )
+    {
+        *t = p2m_recalc_type(recalc || ept_entry->recalc,
+                             ept_entry->sa_p2mt, p2m, gfn);
+        *a = ept_entry->access;
+        if ( sve )
+            *sve = ept_entry->suppress_ve;
+ 
+        mfn = _mfn(ept_entry->mfn);
+        if ( i )
+        {
+             /* 
+              * We may meet super pages, and to split into 4k pages
+              * to emulate p2m table
+             */
+            unsigned long split_mfn = mfn_x(mfn) +
+                (gfn_remainder &
+                ((1 << (i * EPT_TABLE_ORDER)) - 1));
+            mfn = _mfn(split_mfn);
+        }
+    }
+out:
+    if ( page_order )
+        *page_order = i * EPT_TABLE_ORDER;
+
+    unmap_domain_page(table);
+    return (ept_entry->spp);
+}
+
+
+
 /*
  * ept_set_entry() computes 'need_modify_vtd_table' for itself,
  * by observing whether any gfn->mfn translations are modified.
@@ -1247,6 +1669,7 @@
 
     p2m->set_entry = ept_set_entry;
     p2m->get_entry = ept_get_entry;
+    p2m->get_entry_spp = ept_get_entry_spp;
     p2m->recalc = resolve_misconfig;
     p2m->change_entry_type_global = ept_change_entry_type_global;
     p2m->change_entry_type_range = ept_change_entry_type_range;
@@ -1267,6 +1690,15 @@
         p2m->flush_hardware_cached_dirty = ept_flush_pml_buffers;
     }
 
+   p2m->update_ept_spp_wp = ept_spp_update_wp;
+   p2m->spp_set_entry = spp_set_entry;
+   p2m->spp_get_entry = spp_get_entry;
+   
+
+   /*** SPP_DEPRACATED
+   p2m->spp_release = spp_release;
+   p2m->spp_access_check = spp_access_check;
+    ***/
     if ( !zalloc_cpumask_var(&ept->invalidate) )
         return -ENOMEM;
 
diff -aur ./xen/arch/x86/mm/paging.c ./xen/arch/x86/mm/paging.c
--- ./xen/arch/x86/mm/paging.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/arch/x86/mm/paging.c	2020-11-13 20:14:48.000000000 +0100
@@ -30,6 +30,7 @@
 #include <xen/numa.h>
 #include <xsm/xsm.h>
 #include <public/sched.h> /* SHUTDOWN_suspend */
+#include <xen/sched.h> /* SHUTDOWN_suspend */
 
 #include "mm-locks.h"
 
@@ -53,6 +54,8 @@
 #undef page_to_mfn
 #define page_to_mfn(_pg) _mfn(__page_to_mfn(_pg))
 
+static bool_t vtf_cmd;
+
 /************************************************/
 /*              LOG DIRTY SUPPORT               */
 /************************************************/
@@ -84,6 +87,26 @@
     return mfn;
 }
 
+/* Alloc and init a new leaf with xxentries */
+// static mfn_t paging_new_log_dirty_leaf_long(struct domain *d)
+// {    
+//     mfn_t mfn = paging_new_log_dirty_page(d);//mfn2, 
+//     if ( mfn_valid(mfn) )
+//     {
+//         int i;
+//         mfn_t *node = map_domain_page(mfn);
+//         for ( i = 0; i < LOGDIRTY_LEAF_LONG_ENTRIES << 1; i++ )
+//         {
+//             /*mfn2=paging_new_log_dirty_page(d);
+//             if ( mfn_valid(mfn2) )
+//                 clear_domain_page(mfn2);*/
+//             node[i] = _mfn(INVALID_MFN);//mfn2;            
+//         }       
+//         unmap_domain_page(node);
+//     }  
+//     return mfn;
+// }
+
 /* Alloc and init a new non-leaf node */
 static mfn_t paging_new_log_dirty_node(struct domain *d)
 {
@@ -133,7 +156,7 @@
         ASSERT(rc <= 0);
         d->arch.paging.preempt.log_dirty.done = -rc;
     }
-    else if ( d->arch.paging.preempt.dom != current->domain ||
+    else if ( /*!vtf_cmd ||*/ d->arch.paging.preempt.dom != current->domain ||
               d->arch.paging.preempt.op != XEN_DOMCTL_SHADOW_OP_OFF )
     {
         paging_unlock(d);
@@ -217,7 +240,7 @@
 
 int paging_log_dirty_enable(struct domain *d, bool_t log_global)
 {
-    int ret;
+    int ret, paused=0;
 
     if ( need_iommu(d) && log_global )
     {
@@ -231,22 +254,33 @@
     if ( paging_mode_log_dirty(d) )
         return -EINVAL;
 
-    domain_pause(d);
+    if(!vtf_cmd){
+        domain_pause(d);
+        paused = 1;
+        printk("paused\n");
+    }    
+
     ret = d->arch.paging.log_dirty.ops->enable(d, log_global);
-    domain_unpause(d);
+    printk("enabled\n");
+    if(paused)
+        domain_unpause(d);
 
     return ret;
 }
 
 static int paging_log_dirty_disable(struct domain *d, bool_t resuming)
 {
-    int ret = 1;
+    int ret = 1, paused=0;
 
     if ( !resuming )
     {
-        domain_pause(d);
+        if(!vtf_cmd){
+            domain_pause(d);
+            paused = 1;
+        }      
+
         /* Safe because the domain is paused. */
-        if ( paging_mode_log_dirty(d) )
+        if ( paused && paging_mode_log_dirty(d) ) //we shall see how to disable without pausing - anyway we'll look at the fake enable and disable
         {
             ret = d->arch.paging.log_dirty.ops->disable(d);
             ASSERT(ret <= 0);
@@ -257,7 +291,8 @@
     if ( ret == -ERESTART )
         return ret;
 
-    domain_unpause(d);
+    if(paused)
+        domain_unpause(d);
 
     return ret;
 }
@@ -339,6 +374,117 @@
     paging_unlock(d);
     return;
 }
+// void paging_mark_pfn_dirty(struct domain *d, pfn_t pfn) //this one is for pml first work on
+// {
+//     mfn_t mfn, *l4, *l3, *l2;
+//     unsigned long *l1, *l0;
+//     unsigned int i1, i2, i3, i4, decalage;
+
+//     if ( !paging_mode_log_dirty(d) )
+//         return;
+
+//     /* Shared MFNs should NEVER be marked dirty */
+//     BUG_ON(paging_mode_translate(d) && SHARED_M2P(pfn_x(pfn)));
+
+//     /*
+//      * Values with the MSB set denote MFNs that aren't really part of the
+//      * domain's pseudo-physical memory map (e.g., the shared info frame).
+//      * Nothing to do here...
+//      */
+//     if ( unlikely(!VALID_M2P(pfn_x(pfn))) )
+//         return;
+
+//     i1 = L1_LOGDIRTY_IDX(pfn);
+//     i2 = L2_LOGDIRTY_IDX(pfn);
+//     i3 = L3_LOGDIRTY_IDX(pfn);
+//     i4 = L4_LOGDIRTY_IDX(pfn);
+
+//     /* Recursive: this is called from inside the shadow code */
+//     paging_lock_recursive(d);
+
+//     if ( unlikely(!mfn_valid(d->arch.paging.log_dirty.top)) ) 
+//     {
+//          d->arch.paging.log_dirty.top = paging_new_log_dirty_node(d);
+//          if ( unlikely(!mfn_valid(d->arch.paging.log_dirty.top)) )
+//              goto out;
+//     }
+
+//     l4 = paging_map_log_dirty_bitmap(d);
+//     mfn = l4[i4];
+//     if ( !mfn_valid(mfn) )
+//         l4[i4] = mfn = paging_new_log_dirty_node(d);
+//     unmap_domain_page(l4);
+//     if ( !mfn_valid(mfn) )
+//         goto out;
+
+//     l3 = map_domain_page(mfn);
+//     mfn = l3[i3];
+//     if ( !mfn_valid(mfn) )
+//         l3[i3] = mfn = paging_new_log_dirty_node(d);
+//     unmap_domain_page(l3);
+//     if ( !mfn_valid(mfn) )
+//         goto out;
+
+//     l2 = map_domain_page(mfn);
+//     mfn = l2[i2];
+//     if ( !mfn_valid(mfn) )
+//         l2[i2] = mfn = paging_new_log_dirty_leaf_long(d);
+//     unmap_domain_page(l2);
+//     if ( !mfn_valid(mfn) )
+//         goto out;
+
+//     l1 = map_domain_page(mfn);
+//     /*
+//     *On obtient le bloc de l1  partir d'o incrmenter
+//     */
+//     decalage = (i1 >> 9); //On fait i1:(PAGE_SIZE/sizeof(long)) et PAGE_SIZE(==1 << 12)/sizeof(long)(== 1 << 3) = (1 << 9)
+//     i1 %= (PAGE_SIZE >> 3);//(PAGE_SIZE/sizeof(long))
+
+//     mfn=l1[decalage];
+//     if ( !mfn_valid(mfn) ){
+//         l1[decalage] = mfn = paging_new_log_dirty_leaf(d);
+//     }
+//     //unmap_domain_page(l1);
+//     if ( !mfn_valid(mfn) )
+//         goto out;
+
+//     l0=map_domain_page(mfn);
+//     if(l0)
+//     {
+//         l0[i1]++;
+//         unmap_domain_page(l0);
+//     }
+
+//     /*
+//     *On obtient le bloc de l1  partir d'o insrer le pfn pris en paramtres
+//     */
+//     decalage += LOGDIRTY_LEAF_LONG_ENTRIES;
+//     mfn=l1[decalage];
+//     if ( !mfn_valid(mfn) ){
+//         l1[decalage] = mfn = paging_new_log_dirty_leaf(d);
+//     }
+//     //unmap_domain_page(l1);
+//     if ( !mfn_valid(mfn) )
+//         goto out;
+
+//     l0=map_domain_page(mfn);
+//     if(l0)
+//     {
+//         l0[i1] = pfn;
+//         //printk("%lx\n",pfn);
+//         unmap_domain_page(l0);
+//     }
+
+//     unmap_domain_page(l1);
+
+//     d->arch.paging.log_dirty.dirty_count++;
+
+// out:
+//     /* We've already recorded any failed allocations */
+//     paging_unlock(d);
+//     return;
+// }
+
 
 /* Mark a page as dirty */
 void paging_mark_dirty(struct domain *d, mfn_t gmfn)
@@ -592,6 +738,251 @@
     return rv;
 }
 
+// static int paging_log_dirty_op(struct domain *d,
+//                                struct xen_domctl_shadow_op *sc,
+//                                bool_t resuming)
+// {
+//     int rv = 0, clean = 0, peek = 1;
+//     unsigned long pages = 0;
+//     mfn_t *l4 = NULL, *l3 = NULL, *l2 = NULL;
+//     unsigned long *l1 = NULL, *l0=NULL;
+//     int i4, i3, i2, i1, i0=0, decalage, count=0;
+
+//     if ( !resuming )
+//     {
+//         /*
+//          * Mark dirty all currently write-mapped pages on e.g. the
+//          * final iteration of a save operation.
+//          */
+//         if ( is_hvm_domain(d) &&
+//              (sc->mode & XEN_DOMCTL_SHADOW_LOGDIRTY_FINAL) )
+//             hvm_mapped_guest_frames_mark_dirty(d);
+
+//         domain_pause(d);
+
+//         /*
+//          * Flush dirty GFNs potentially cached by hardware. Only need to flush
+//          * when not resuming, as domain was paused in resuming case therefore
+//          * it's not possible to have any new dirty pages.
+//          */
+//         p2m_flush_hardware_cached_dirty(d);
+//     }
+
+//     paging_lock(d);
+
+//     if ( !d->arch.paging.preempt.dom )
+//         memset(&d->arch.paging.preempt.log_dirty, 0,
+//                sizeof(d->arch.paging.preempt.log_dirty));
+//     else if ( d->arch.paging.preempt.dom != current->domain ||
+//               d->arch.paging.preempt.op != sc->op )
+//     {
+//         paging_unlock(d);
+//         ASSERT(!resuming);
+//         domain_unpause(d);
+//         return -EBUSY;
+//     }
+
+//     clean = (sc->op == XEN_DOMCTL_SHADOW_OP_CLEAN);
+
+//     PAGING_DEBUG(LOGDIRTY, "log-dirty %s: dom %u faults=%u dirty=%u\n",
+//                  (clean) ? "clean" : "peek",
+//                  d->domain_id,
+//                  d->arch.paging.log_dirty.fault_count,
+//                  d->arch.paging.log_dirty.dirty_count);
+
+//     sc->stats.fault_count = d->arch.paging.log_dirty.fault_count;
+//     sc->stats.dirty_count = d->arch.paging.log_dirty.dirty_count;
+
+//     if ( guest_handle_is_null(sc->dirty_bitmap) )
+//         /* caller may have wanted just to clean the state or access stats. */
+//         peek = 0;
+
+//     if ( unlikely(d->arch.paging.log_dirty.failed_allocs) ) {
+//         printk(XENLOG_WARNING
+//                "%u failed page allocs while logging dirty pages of d%d\n",
+//                d->arch.paging.log_dirty.failed_allocs, d->domain_id);
+//         rv = -ENOMEM;
+//         goto out;
+//     }
+
+//     l4 = paging_map_log_dirty_bitmap(d);
+//     i4 = d->arch.paging.preempt.log_dirty.i4;
+//     i3 = d->arch.paging.preempt.log_dirty.i3;
+//     pages = d->arch.paging.preempt.log_dirty.done;
+
+//     for ( ; (pages < sc->pages) && (i4 < LOGDIRTY_NODE_ENTRIES); i4++, i3 = 0 )
+//     {
+//         l3 = (l4 && mfn_valid(l4[i4])) ? map_domain_page(l4[i4]) : NULL;
+//         for ( ; (pages < sc->pages) && (i3 < LOGDIRTY_NODE_ENTRIES); i3++ )
+//         {
+//             l2 = ((l3 && mfn_valid(l3[i3])) ?
+//                   map_domain_page(l3[i3]) : NULL);
+//             for ( i2 = 0;
+//                   (pages < sc->pages) && (i2 < LOGDIRTY_NODE_ENTRIES);
+//                   i2++ )
+//             {
+//                 unsigned int bytes = PAGE_SIZE;
+//                 l1 = ((l2 && mfn_valid(l2[i2])) ?
+//                       map_domain_page(l2[i2]) : NULL);
+//                 if ( unlikely(((sc->pages - pages + 7) >> 3) < bytes) )
+//                     bytes = (unsigned int)((sc->pages - pages + 7) >> 3);
+//                 for ( i1 = 0; i1 < LOGDIRTY_LEAF_LONG_ENTRIES; i1++ )
+//                 {
+//                     if(clean)
+//                     {
+//                         l0 = ((l1 && mfn_valid(l1[i1])) ? map_domain_page(l1[i1]) : NULL);
+//                         if (l0)
+//                         {
+//                             clear_page(l0); 
+//                             unmap_domain_page(l0);
+//                         }
+//                         decalage = i1 + LOGDIRTY_LEAF_LONG_ENTRIES;
+//                         l0 = ((l1 && mfn_valid(l1[decalage])) ? map_domain_page(l1[decalage]) : NULL);
+//                         if (l0)
+//                         {
+//                             clear_page(l0); 
+//                             unmap_domain_page(l0);
+//                         }
+//                     }else
+//                     {
+//                         for( i0 = 0; i0 < LOGDIRTY_NODE_ENTRIES; i0++)
+//                         {
+//                             l0 = ((l1 && mfn_valid(l1[i1])) ?
+//                                  map_domain_page(l1[i1]) : NULL);
+//                             if(l0)
+//                             {
+//                                 if(l0[i0]!=0)
+//                                     //printk("(WSS) %lu : ", l0[i0]);
+                                
+//                                 unmap_domain_page(l0);
+//                             }
+
+//                             /**
+//                              * Ensuite on fait un dcalage pour se placer au dbut de la 
+//                              * liste des adresses
+//                              * */
+//                             decalage = i1 + LOGDIRTY_LEAF_LONG_ENTRIES;
+//                             /**
+//                              * Maintenant on rcupre les adresses elles-mmes
+//                              * */
+//                             l0 = ((l1 && mfn_valid(l1[decalage])) ?
+//                                  map_domain_page(l1[decalage]) : NULL);
+//                             if(l0)
+//                             {
+//                                 if(l0[i0]!=0)
+//                                 {
+//                                     count++;
+//                                     //printk("%lx\n", l0[i0]);
+//                                 } 
+//                                 unmap_domain_page(l0);
+//                             }
+//                         }
+
+//                     }
+//                 }
+//                 if ( likely(peek) )
+//                 {
+//                     if ( (l1 ? copy_to_guest_offset(sc->dirty_bitmap,
+//                                                     pages >> 3, (uint8_t *)l1,
+//                                                     bytes)
+//                              : clear_guest_offset(sc->dirty_bitmap,
+//                                                   pages >> 3, bytes)) != 0 )
+//                     {
+//                         rv = -EFAULT;
+//                         goto out;
+//                     }
+//                 }
+//                 pages += bytes << 3;
+//                 if ( l1 )
+//                 {
+//                     /*if ( clean )
+//                         clear_page(l1);*/
+//                     unmap_domain_page(l1);
+//                 }
+//             }
+//             if ( l2 )
+//                 unmap_domain_page(l2);
+
+//             if ( i3 < LOGDIRTY_NODE_ENTRIES - 1 && hypercall_preempt_check() )
+//             {
+//                 d->arch.paging.preempt.log_dirty.i4 = i4;
+//                 d->arch.paging.preempt.log_dirty.i3 = i3 + 1;
+//                 rv = -ERESTART;
+//                 break;
+//             }
+//         }
+//         if ( l3 )
+//             unmap_domain_page(l3);
+
+//         if ( !rv && i4 < LOGDIRTY_NODE_ENTRIES - 1 &&
+//              hypercall_preempt_check() )
+//         {
+//             d->arch.paging.preempt.log_dirty.i4 = i4 + 1;
+//             d->arch.paging.preempt.log_dirty.i3 = 0;
+//             rv = -ERESTART;
+//         }
+//         if ( rv )
+//             break;
+//     }
+//     //printk("[END_WSS]\n");
+//     printk("%d\n", count);
+
+//     if ( l4 )
+//         unmap_domain_page(l4);
+
+//     if ( !rv )
+//     {
+//         d->arch.paging.preempt.dom = NULL;
+//         if ( clean )
+//         {
+//             d->arch.paging.log_dirty.fault_count = 0;
+//             d->arch.paging.log_dirty.dirty_count = 0;
+//         }
+//     }
+//     else
+//     {
+//         d->arch.paging.preempt.dom = current->domain;
+//         d->arch.paging.preempt.op = sc->op;
+//         d->arch.paging.preempt.log_dirty.done = pages;
+//     }
+
+//     paging_unlock(d);
+
+//     if ( rv )
+//     {
+//         /* Never leave the domain paused on real errors. */
+//         ASSERT(rv == -ERESTART);
+//         return rv;
+//     }
+
+//     if ( pages < sc->pages )
+//         sc->pages = pages;
+//     if ( clean )
+//     {
+//         /* We need to further call clean_dirty_bitmap() functions of specific
+//          * paging modes (shadow or hap).  Safe because the domain is paused. */
+//         d->arch.paging.log_dirty.ops->clean(d);
+//     }
+//     domain_unpause(d);
+//     return rv;
+
+//  out:
+//     d->arch.paging.preempt.dom = NULL;
+//     paging_unlock(d);
+//     domain_unpause(d);
+
+//     if ( l1 )
+//         unmap_domain_page(l1);
+//     if ( l2 )
+//         unmap_domain_page(l2);
+//     if ( l3 )
+//         unmap_domain_page(l3);
+//     if ( l4 )
+//         unmap_domain_page(l4);
+
+//     return rv;
+// }
+
 void paging_log_dirty_range(struct domain *d,
                            unsigned long begin_pfn,
                            unsigned long nr,
@@ -667,7 +1058,7 @@
 /* vcpu paging struct initialization goes here */
 void paging_vcpu_init(struct vcpu *v)
 {
-    if ( hap_enabled(v->domain) )
+    if ( hap_enabled(v->domain) ) 
         hap_vcpu_init(v);
     else
         shadow_vcpu_init(v);
@@ -679,12 +1070,10 @@
                   bool_t resuming)
 {
     int rc;
-
-    if ( unlikely(d == current->domain) )
-    {
-        gdprintk(XENLOG_INFO, "Tried to do a paging op on itself.\n");
-        return -EINVAL;
-    }
+    struct xen_domctl curop, *op = &curop;
+   
+    if ( copy_from_guest(op, u_domctl, 1) )
+        return -EFAULT; 
 
     if ( unlikely(d->is_dying) )
     {
@@ -697,7 +1086,16 @@
     {
         gdprintk(XENLOG_DEBUG, "Paging op on a domain (%u) with no vcpus\n",
                  d->domain_id);
-        return -EINVAL;
+        return -EINVAL; 
+    }
+    
+    switch (op->cmd)
+    {
+    case XEN_DOMCTL_vtf:
+        printk("XEN_DOMCTL_vtf --- paging_domctl\n");
+        vtf_cmd = 1;
+        goto vtf_op;
+        break;
     }
 
     if ( resuming
@@ -706,6 +1104,7 @@
          : (d->arch.paging.preempt.dom &&
             sc->op != XEN_DOMCTL_SHADOW_OP_GET_ALLOCATION) )
     {
+        printk("resuming - %d\n", resuming);
         printk(XENLOG_G_DEBUG
                "%pv: Paging op %#x on Dom%u with unfinished prior op %#x by Dom%u\n",
                current, sc->op, d->domain_id, d->arch.paging.preempt.op,
@@ -714,8 +1113,14 @@
         return -EBUSY;
     }
 
+    if ( unlikely(d == current->domain) )
+    {
+        gdprintk(XENLOG_INFO, "Tried to do a paging op on itself.\n");
+        return -EINVAL;
+    }
+
     rc = xsm_shadow_control(XSM_HOOK, d, sc->op);
-    if ( rc )
+    if ( rc ) 
         return rc;
 
     /* Code to handle log-dirty. Note that some log dirty operations
@@ -725,23 +1130,28 @@
      * shadow code. For this reason, we need to further dispatch domctl
      * to next-level paging code (shadow or hap).
      */
+
+vtf_op:
     switch ( sc->op )
     {
 
     case XEN_DOMCTL_SHADOW_OP_ENABLE:
-        if ( !(sc->mode & XEN_DOMCTL_SHADOW_ENABLE_LOG_DIRTY) )
+        if ( !(sc->mode & XEN_DOMCTL_SHADOW_ENABLE_LOG_DIRTY) ) 
             break;
         /* Else fall through... */
     case XEN_DOMCTL_SHADOW_OP_ENABLE_LOGDIRTY:
+        printk("XEN_DOMCTL_SHADOW_OP_ENABLE_LOGDIRTY\n");
         return paging_log_dirty_enable(d, 1);
 
     case XEN_DOMCTL_SHADOW_OP_OFF:
+        printk("XEN_DOMCTL_SHADOW_OP_OFF\n");
         if ( (rc = paging_log_dirty_disable(d, resuming)) != 0 )
             return rc;
         break;
 
     case XEN_DOMCTL_SHADOW_OP_CLEAN:
     case XEN_DOMCTL_SHADOW_OP_PEEK:
+        printk("XEN_DOMCTL_SHADOW_OP_PEEK\n");
         if ( sc->mode & ~XEN_DOMCTL_SHADOW_LOGDIRTY_FINAL )
             return -EINVAL;
         return paging_log_dirty_op(d, sc, resuming);
@@ -759,7 +1169,7 @@
     struct xen_domctl op;
     struct domain *d;
     int ret;
-
+    
     if ( copy_from_guest(&op, u_domctl, 1) )
         return -EFAULT;
 
diff -aur ./xen/arch/x86/mm/shadow/common.c ./xen/arch/x86/mm/shadow/common.c
--- ./xen/arch/x86/mm/shadow/common.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/arch/x86/mm/shadow/common.c	2021-05-07 16:37:24.000000000 +0200
@@ -2536,11 +2536,93 @@
 }
 #endif
 
+//VMWare implementation -- Added from 4.2.0
 /**************************************************************************/
 /* Remove all mappings of a guest frame from the shadow tables.
  * Returns non-zero if we need to flush TLBs. */
 
-static int sh_remove_all_mappings(struct domain *d, mfn_t gmfn, gfn_t gfn)
+int sh_remove_all_mappings_vmware(struct vcpu *v, mfn_t gmfn)
+{
+    struct page_info *page = mfn_to_page(gmfn);
+
+    /* Dispatch table for getting per-type functions */
+    static const hash_domain_callback_t callbacks[SH_type_unused] = {
+        NULL, /* none    */
+        SHADOW_INTERNAL_NAME(sh_rm_mappings_from_l1, 2), /* l1_32   */
+        SHADOW_INTERNAL_NAME(sh_rm_mappings_from_l1, 2), /* fl1_32  */
+        NULL, /* l2_32   */
+        SHADOW_INTERNAL_NAME(sh_rm_mappings_from_l1, 3), /* l1_pae  */
+        SHADOW_INTERNAL_NAME(sh_rm_mappings_from_l1, 3), /* fl1_pae */
+        NULL, /* l2_pae  */
+        NULL, /* l2h_pae */
+#if CONFIG_PAGING_LEVELS >= 4
+        SHADOW_INTERNAL_NAME(sh_rm_mappings_from_l1, 4), /* l1_64   */
+        SHADOW_INTERNAL_NAME(sh_rm_mappings_from_l1, 4), /* fl1_64  */
+#else
+        NULL, /* l1_64   */
+        NULL, /* fl1_64  */
+#endif
+        NULL, /* l2_64   */
+        NULL, /* l2h_64  */
+        NULL, /* l3_64   */
+        NULL, /* l4_64   */
+        NULL, /* p2m     */
+        NULL  /* unused  */
+    };
+
+    static unsigned int callback_mask = 
+          1 << SH_type_l1_32_shadow
+        | 1 << SH_type_fl1_32_shadow
+        | 1 << SH_type_l1_pae_shadow
+        | 1 << SH_type_fl1_pae_shadow
+        | 1 << SH_type_l1_64_shadow
+        | 1 << SH_type_fl1_64_shadow
+        ;
+
+    perfc_incr(shadow_mappings);
+    if ( sh_check_page_has_no_refs(page) )
+        return 0;
+
+    /* Although this is an externally visible function, we do not know
+     * whether the paging lock will be held when it is called (since it
+     * can be called via put_page_type when we clear a shadow l1e).*/
+    paging_lock_recursive(v->domain);
+
+    /* XXX TODO: 
+     * Heuristics for finding the (probably) single mapping of this gmfn */
+    
+    /* Brute-force search of all the shadows, by walking the hash */
+    perfc_incr(shadow_mappings_bf);
+    hash_domain_foreach(v->domain, callback_mask, callbacks, gmfn);
+
+    /* If that didn't catch the mapping, something is very wrong */
+    if ( !sh_check_page_has_no_refs(page) )
+    {
+        /* Don't complain if we're in HVM and there are some extra mappings: 
+         * The qemu helper process has an untyped mapping of this dom's RAM 
+         * and the HVM restore program takes another. */
+        if ( !(shadow_mode_external(v->domain)
+               && (page->count_info & PGC_count_mask) <= 3
+               && (page->u.inuse.type_info & PGT_count_mask) == 0) )
+        {
+            SHADOW_ERROR("can't find all mappings of mfn %lx: "
+                          "c=%08lx t=%08lx\n", mfn_x(gmfn), 
+                          page->count_info, page->u.inuse.type_info);
+        }
+    }
+
+    paging_unlock(v->domain);
+
+    /* We killed at least one mapping, so must flush TLBs. */
+    return 1;
+}
+//
+
+/**************************************************************************/
+/* Remove all mappings of a guest frame from the shadow tables.
+ * Returns non-zero if we need to flush TLBs. */
+
+int sh_remove_all_mappings(struct domain *d, mfn_t gmfn, gfn_t gfn)
 {
     struct page_info *page = mfn_to_page(gmfn);
 
@@ -3068,6 +3150,7 @@
  * disabled.
  * Returns 0 for success, -errno for failure. */
 {
+    printk("shadow_enable\n");
     unsigned int old_pages;
     struct page_info *pg = NULL;
     uint32_t *e;
@@ -3333,6 +3416,7 @@
 static int shadow_one_bit_enable(struct domain *d, u32 mode)
 /* Turn on a single shadow mode feature */
 {
+    printk("shadow_one_bit_enable");
     ASSERT(paging_locked_by_me(d));
 
     /* Sanity check the call */
diff -aur ./xen/arch/x86/mm/shadow/multi.c ./xen/arch/x86/mm/shadow/multi.c
--- ./xen/arch/x86/mm/shadow/multi.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/arch/x86/mm/shadow/multi.c	2020-11-13 20:14:48.000000000 +0100
@@ -69,6 +69,8 @@
 #define FETCH_TYPE_PREFETCH 1
 #define FETCH_TYPE_DEMAND   2
 #define FETCH_TYPE_WRITE    4
+//#define NB_ELEMS(x)  (sizeof(x) / sizeof((x)[0]))
+
 typedef enum {
     ft_prefetch     = FETCH_TYPE_PREFETCH,
     ft_demand_read  = FETCH_TYPE_DEMAND,
@@ -3090,6 +3092,18 @@
     gfn = guest_walk_to_gfn(&gw);
     gmfn = get_gfn(d, gfn, &p2mt);
 
+    //VMWare implementation
+    for(unsigned int i = 0; i < d->tot_pages ; i++)//i<100 d->tot_pages
+    {
+        if(gmfn == d->ws->inv_pages[i] && d->ws->test_inv[i] == 0)
+        {
+        	//printk("matched page %u\n", d->ws->inv_pages[i]);
+            d->ws->test_inv[i] = 1;
+            d->ws->tot_access++;
+        }
+    }
+    //
+
     if ( shadow_mode_refcounts(d) &&
          ((!p2m_is_valid(p2mt) && !p2m_is_grant(p2mt)) ||
           (!p2m_is_mmio(p2mt) && !mfn_valid(gmfn))) )
diff -aur ./xen/arch/x86/mm.c ./xen/arch/x86/mm.c
--- ./xen/arch/x86/mm.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/arch/x86/mm.c	2020-11-13 20:14:48.000000000 +0100
@@ -4089,6 +4089,12 @@
             if ( idx == 0 )
                 mfn = _mfn(virt_to_mfn(d->shared_info));
             break;
+        case XENMAPSPACE_pml_shared_info:
+            mfn = mfn_add(_mfn(virt_to_mfn(d->vtf_info.pml)), idx);
+            /*printk(XENLOG_INFO "XENMAPSPACE_pml_shared_info for domain %d: idx=%lu, gpfn=%lu, mfn=%lu\n",
+                    d->domain_id, idx, gfn_x(gpfn), mfn_x(mfn));*/
+
+            break;
         case XENMAPSPACE_grant_table:
             rc = gnttab_map_frame(d, idx, gpfn, &mfn);
             if ( rc )
@@ -4138,7 +4144,7 @@
     }
     /* In the XENMAPSPACE_gmfn case we still hold a ref on the old page. */
     put_gfn(d, gfn_x(gpfn));
-
+    
     if ( rc )
         goto put_both;
 
@@ -4155,8 +4161,11 @@
         rc = guest_physmap_remove_page(d, _gfn(old_gpfn), mfn, PAGE_ORDER_4K);
 
     /* Map at new location. */
-    if ( !rc )
+    if ( !rc ){
         rc = guest_physmap_add_page(d, gpfn, mfn, PAGE_ORDER_4K);
+        /*if ( space == XENMAPSPACE_pml_shared_info )
+            d->vtf_info.pml[0] = 7777;*/
+    }
 
  put_both:
     /* In the XENMAPSPACE_gmfn, we took a ref of the gfn at the top */
Seulement dans ./xen/arch/x86: mm.c.bk
Seulement dans ./xen: bk_vmcs
Seulement dans ./xen/common/compat: .domain.o.d2
diff -aur ./xen/common/compat/kernel.c ./xen/common/compat/kernel.c
--- ./xen/common/compat/kernel.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/common/compat/kernel.c	2020-11-13 20:14:48.000000000 +0100
@@ -35,6 +35,9 @@
 #define xen_feature_info compat_feature_info
 #define xen_feature_info_t compat_feature_info_t
 
+#define xen_vtf_signal compat_vtf_signal
+#define xen_vtf_signal_t compat_vtf_signal_t
+
 CHECK_TYPE(domain_handle);
 
 #ifdef COMPAT_VM_ASSIST_VALID
Seulement dans ./xen/common/compat: .kernel.o.d2
Seulement dans ./xen/common/compat: .memory.o.d2
Seulement dans ./xen/common/compat: .multicall.o.d2
Seulement dans ./xen/common/compat: .tmem_xen.o.d2
Seulement dans ./xen/common/compat: .xlat.o.d2
diff -aur ./xen/common/domain.c ./xen/common/domain.c
--- ./xen/common/domain.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/common/domain.c	2020-11-13 20:14:48.000000000 +0100
@@ -41,7 +41,16 @@
 #include <xsm/xsm.h>
 #include <xen/trace.h>
 #include <xen/tmem.h>
-#include <asm/setup.h>
+#include <asm/setup.h> 
+//VMWare implementation
+#include <xen/random.h>
+#include <asm/shadow.h>
+#include <asm/random.h>
+
+#include <asm/hvm/vmx/vmx.h>
+#include <asm/hvm/vmx/vmcs.h>
+//
+#include <asm/paging.h>
 
 /* Linux config option: propageted to domain0 */
 /* xen_processor_pmbits: xen control Cx, Px, ... */
@@ -257,6 +266,68 @@
 }
 custom_param("extra_guest_irqs", parse_extra_guest_irqs);
 
+/*void ws_handler(void *var)
+{
+    struct domain *d = var;
+    unsigned int i = 0, teste;
+    struct page_info *page;
+    unsigned int mem;
+
+    if (d->domain_id <= 0 || d->domain_id > 20)
+        return;
+
+    mem = d->ws->tot_access  * 4 / 1024; //taille estime en MB de la vm
+    printk("working set =  %u access = %u\n", mem, d->ws->tot_access);
+
+    d->ws->tot_access = 0;
+    page_list_for_each(page, &d->page_list)
+    {
+        d->ws->inv_pages[i++] = page_to_mfn(page);
+        teste = sh_remove_all_mappings_vmware(d->vcpu[0], page_to_mfn(page));
+        d->ws->test_inv[i] = 0;
+    }
+    flush_tlb_all();
+    set_timer(d->ws->timer, NOW() + SECONDS(60));
+}*/
+
+//VMWare implementation
+void ws_handler(void * var)
+{
+    struct domain *d = var;
+    unsigned int i = 0, j, teste;
+    struct page_info *page;
+    unsigned long rand;
+    unsigned int mem;
+
+    if(d->domain_id <= 0 || d->domain_id>20)
+        return;
+        
+    mem = d->ws->tot_access*d->tot_pages*4/100; //taille estime en KB de la vm
+    printk("working set =  %u access = %u\n", mem, d->ws->tot_access);
+    
+    d->ws->tot_access = 0;
+    for(i=0; i<100; i++)
+    {
+        j =0;
+        rand = ((unsigned long)get_random()) % d->tot_pages;
+        page_list_for_each(page, &d->page_list)
+        {
+            if(rand == j)
+            {
+                d->ws->inv_pages[i++] = page_to_mfn(page);
+                teste = sh_remove_all_mappings_vmware(d->vcpu[0], page_to_mfn(page));
+                d->ws->test_inv[i] = 0;
+                break;
+            }
+            j++;
+        }
+    	//printk("rand = %lu\n", rand);
+    }
+    flush_tlb_all();
+    set_timer(d->ws->timer, NOW()+SECONDS(60)); 
+}
+//
+
 struct domain *domain_create(domid_t domid, unsigned int domcr_flags,
                              uint32_t ssidref,
                              struct xen_arch_domainconfig *config)
@@ -396,6 +467,18 @@
         spin_unlock(&domlist_update_lock);
     }
 
+    //VMWare implementation
+    /*working set initialization*/
+    /*if(domid > 0 && domid < 20)
+    {
+        printk("%u\n", domid);
+        d->ws = xzalloc(struct working_set);
+        d->ws->timer = xzalloc(struct timer);
+        init_timer(d->ws->timer, ws_handler, d, 0);
+        set_timer(d->ws->timer, NOW()+ SECONDS(30));
+    }*/
+    //
+
     return d;
 
  fail:
@@ -1331,6 +1414,68 @@
 
         break;
     }
+    
+    case VCPUOP_vtf_enable_pml:
+    {
+        struct vcpu_vtf_pml list_pid;
+        struct p2m_domain *p2m = p2m_get_hostp2m(d);
+
+        if ( copy_from_guest(&list_pid, arg, 1) )
+            return -EFAULT;
+           
+        if ( ! atomic_cmpxchg(&d->vtf_pml_flag, 0, 1) )
+        {
+           domain_pause_by_systemcontroller_nosync(d);
+            
+           if ( p2m->enable_hardware_log_dirty )
+                p2m->enable_hardware_log_dirty(p2m);
+            
+            d->is_vtf = 1;
+            rc = d->arch.paging.log_dirty.ops->enable(d, 1);
+
+            printk("VCPUOP_vtf_enable_pml: PML enabled for domaine %d? : %d - received : %d\n", d->domain_id,
+                vmx_domain_pml_enabled(d), list_pid.pid);
+
+            domain_unpause_by_systemcontroller(d);
+
+            atomic_set(&d->vtf_pml_flag, 0);
+        }
+
+        break;
+    }
+
+    case VCPUOP_vtf_disable_pml:
+    {
+        struct vcpu_vtf_pml list_pid;
+        struct p2m_domain *p2m = p2m_get_hostp2m(d);
+
+        if ( copy_from_guest(&list_pid, arg, 1) )
+            return -EFAULT;
+
+        printk("PML enabled? %d\n",
+                vmx_domain_pml_enabled(d));
+
+        if ( vmx_domain_pml_enabled(d) &&
+                ! atomic_cmpxchg(&d->vtf_pml_flag, 0, 1) )
+        {
+            domain_pause_by_systemcontroller_nosync(d);
+            
+            if ( p2m->disable_hardware_log_dirty )
+                p2m->disable_hardware_log_dirty(p2m);
+
+            rc = d->arch.paging.log_dirty.ops->disable(d);
+            d->is_vtf = 0;
+
+            printk("VCPUOP_vtf_disable_pml: PML enabled? %d\n",
+                vmx_domain_pml_enabled(d));
+
+            domain_unpause_by_systemcontroller(d);
+
+            atomic_set(&d->vtf_pml_flag, 0);
+        }
+
+        break;
+    }
 
     case VCPUOP_stop_periodic_timer:
         v->periodic_period = 0;
diff -aur ./xen/common/domctl.c ./xen/common/domctl.c
--- ./xen/common/domctl.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/common/domctl.c	2020-11-13 20:14:48.000000000 +0100
@@ -379,16 +379,48 @@
 
 long do_domctl(XEN_GUEST_HANDLE_PARAM(xen_domctl_t) u_domctl)
 {
-    long ret = 0;
+    long ret = 0; int i=0;
     bool_t copyback = 0;
-    struct xen_domctl curop, *op = &curop;
-    struct domain *d;
+    struct xen_domctl curop, *op = &curop; 
+    struct domain *d = NULL;
 
     if ( copy_from_guest(op, u_domctl, 1) )
         return -EFAULT;
-
+    
     if ( op->interface_version != XEN_DOMCTL_INTERFACE_VERSION )
         return -EACCES;
+    
+    switch (op->cmd)
+    {
+    case XEN_DOMCTL_vtf:
+        op->domain = current->domain->domain_id;
+
+        if (op->domain != 0)
+        {
+            d = rcu_lock_domain_by_id(op->domain);
+            if (!d)
+                return -ESRCH;
+                
+            /*if ( !domctl_lock_acquire() )
+            {
+                if ( d )
+                    rcu_unlock_domain(d);
+                return hypercall_create_continuation(
+                    __HYPERVISOR_domctl, "h", u_domctl); 
+            }*/
+            
+            d->is_vtf = 1; 
+            memcpy(d->vtf_pids, op->u.vtf.pids, 25*sizeof(op->u.vtf.pids[0]));
+            do{
+                printk("%d\n", d->vtf_pids[i++]);
+            }while(d->vtf_pids[i]);
+            
+            ret = arch_do_domctl(op, d, u_domctl);
+        }
+
+        goto domctl_out_unlock_domonly;
+        break;
+    }
 
     switch ( op->cmd )
     {
@@ -396,11 +428,11 @@
         if ( op->domain == DOMID_INVALID )
         {
     case XEN_DOMCTL_createdomain:
-    case XEN_DOMCTL_gdbsx_guestmemio:
+    case XEN_DOMCTL_gdbsx_guestmemio: 
             d = NULL;
             break;
-        }
-        /* fall through */
+        }    
+    /* fall through */
     default:
         d = rcu_lock_domain_by_id(op->domain);
         if ( !d && op->cmd != XEN_DOMCTL_getdomaininfo )
@@ -1162,7 +1194,7 @@
 
     domctl_lock_release();
 
- domctl_out_unlock_domonly:
+domctl_out_unlock_domonly:
     if ( d )
         rcu_unlock_domain(d);
 
diff -aur ./xen/common/event_channel.c ./xen/common/event_channel.c
--- ./xen/common/event_channel.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/common/event_channel.c	2020-11-13 20:14:48.000000000 +0100
@@ -105,6 +105,7 @@
     case VIRQ_DEBUG:
     case VIRQ_XENOPROF:
     case VIRQ_XENPMU:
+    case VIRQ_VTF_PML:
         rc = 0;
         break;
     case VIRQ_ARCH_0 ... VIRQ_ARCH_7:
diff -aur ./xen/common/kernel.c ./xen/common/kernel.c
--- ./xen/common/kernel.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/common/kernel.c	2020-11-13 20:14:48.000000000 +0100
@@ -321,6 +321,7 @@
         safe_strcpy(extraversion, deny ? xen_deny() : xen_extra_version());
         if ( copy_to_guest(arg, extraversion, ARRAY_SIZE(extraversion)) )
             return -EFAULT;
+
         return 0;
     }
 
@@ -414,7 +415,7 @@
 #endif
             break;
         default:
-            return -EINVAL;
+            return -EINVAL; 
         }
 
         if ( __copy_to_guest(arg, &fi, 1) )
@@ -423,9 +424,36 @@
     }
 
     case XENVER_pagesize:
-        if ( deny )
+    {
+        /*xen_feature_info_t fi;
+
+        if ( copy_from_guest(&fi, arg, 1) )
+        {
+            printk("unable to copy from guest!\n");
+            return PAGE_SIZE;
+        }
+        else
+        {
+            printk("pid sent : %d\n", fi.submap_idx);
+        }
+
+        xen_vtf_signal_t *pid;
+        memset(&pid, 0, sizeof(pid));
+     
+        if (copy_from_guest(&pid, arg, 0))
+        {
+            printk("unable to copy from guest!\n");
+            return PAGE_SIZE;
+        }
+        else
+        {
+            printk("pid sent : %d\n", pid->pid_signal);
+        }*/
+        if (deny)
             return 0;
+        
         return (!guest_handle_is_null(arg) ? -EINVAL : PAGE_SIZE);
+    }
 
     case XENVER_guest_handle:
     {
diff -aur ./xen/common/memory.c ./xen/common/memory.c
--- ./xen/common/memory.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/common/memory.c	2021-05-07 15:55:10.000000000 +0200
@@ -749,12 +749,42 @@
     long rc = 0;
     union xen_add_to_physmap_batch_extra extra;
 
+    struct page_info *page;
+    unsigned int i, order;
+
+    if (xatp->space == XENMAPSPACE_pml_shared_info) {//
+        if(!d->vtf_info.pml){
+            order = get_order_from_pages(xatp->size);
+            if ( (d->vtf_info.pml = alloc_xenheap_pages(order, 0)) == NULL )
+                return -ENOMEM;
+
+            d->vtf_info.pml_page_order = order;
+            d->vtf_info.nr_pml_entries = (1u << order) * PAGE_SIZE / sizeof(unsigned long);
+            
+            printk(XENLOG_INFO "Init VTF shared info for domain %d: page order=%u, nr_pml_entries=%u, address=%p\n", d->domain_id,
+                            d->vtf_info.pml_page_order,
+                            d->vtf_info.nr_pml_entries, d->vtf_info.pml);
+
+            page = virt_to_page(d->vtf_info.pml);
+
+            for (i = 0; i < (1u << order); i++) {
+
+                //printk(XENLOG_INFO "Init VTF shared info: i=%u, mfn=%lu\n",
+                    //          i, mfn_x(page_to_mfn(page+i)));
+
+                clear_page(page_to_virt(page+i));
+                share_xen_page_with_guest(page+i, d, XENSHARE_writable);
+            }
+        }
+    }
+
     if ( xatp->space != XENMAPSPACE_gmfn_foreign )
         extra.res0 = 0;
     else
         extra.foreign_domid = DOMID_INVALID;
 
-    if ( xatp->space != XENMAPSPACE_gmfn_range )
+    if ( xatp->space != XENMAPSPACE_gmfn_range &&
+            xatp->space != XENMAPSPACE_pml_shared_info)
         return xenmem_add_to_physmap_one(d, xatp->space, extra,
                                          xatp->idx, _gfn(xatp->gpfn));
 
@@ -766,7 +796,7 @@
     xatp->size -= start;
 
 #ifdef CONFIG_HAS_PASSTHROUGH
-    if ( need_iommu(d) )
+    if ( need_iommu(d) && xatp->space != XENMAPSPACE_pml_shared_info)
         this_cpu(iommu_dont_flush_iotlb) = 1;
 #endif
 
@@ -780,6 +810,11 @@
         xatp->idx++;
         xatp->gpfn++;
 
+        if (xatp->space == XENMAPSPACE_pml_shared_info) {
+            done++;
+            continue;
+        }
+
         /* Check for continuation if it's not the last iteration. */
         if ( xatp->size > ++done && hypercall_preempt_check() )
         {
@@ -789,7 +824,7 @@
     }
 
 #ifdef CONFIG_HAS_PASSTHROUGH
-    if ( need_iommu(d) )
+    if ( need_iommu(d) && xatp->space != XENMAPSPACE_pml_shared_info)
     {
         int ret;
 
@@ -1419,7 +1454,6 @@
 void clear_domain_page(mfn_t mfn)
 {
     void *ptr = map_domain_page(mfn);
-
     clear_page(ptr);
     unmap_domain_page(ptr);
 }
Seulement dans ./xen/common: memory.c.bk
diff -aur ./xen/common/sysctl.c ./xen/common/sysctl.c
--- ./xen/common/sysctl.c	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/common/sysctl.c	2020-11-13 20:14:48.000000000 +0100
@@ -28,23 +28,117 @@
 #include <xen/pmstat.h>
 #include <xen/livepatch.h>
 #include <xen/gcov.h>
+#include <asm/hvm/vmx/vmcs.h>
+
+long get_physinfo(XEN_GUEST_HANDLE_PARAM(xen_sysctl_t) u_sysctl, struct xen_sysctl *op)
+{
+    struct xen_sysctl_physinfo *pi = &op->u.physinfo;
+    long ret = 0;
+
+    memset(pi, 0, sizeof(*pi));
+    pi->threads_per_core =
+        cpumask_weight(per_cpu(cpu_sibling_mask, 0));
+    pi->cores_per_socket =
+        cpumask_weight(per_cpu(cpu_core_mask, 0)) / pi->threads_per_core;
+    pi->nr_cpus = num_online_cpus();
+    pi->nr_nodes = num_online_nodes();
+    pi->max_node_id = MAX_NUMNODES-1;
+    pi->max_cpu_id = nr_cpu_ids - 1;
+    pi->total_pages = total_pages;
+    /* Protected by lock */
+    get_outstanding_claims(&pi->free_pages, &pi->outstanding_pages);
+    pi->scrub_pages = 0;
+    pi->cpu_khz = cpu_khz;
+    pi->max_mfn = get_upper_mfn_bound();
+    arch_do_physinfo(pi);
+
+    if ( copy_to_guest(u_sysctl, op, 1) ){
+        ret = -EFAULT;
+        printk("get_physinfo ret = %ld\n", ret);
+    }
+    
+    return ret;
+}
+
+long do_vtfctl(struct xen_sysctl *op)
+{
+    long ret = 0;
+    struct xen_sysctl_vtf_getcpuinfo info;
+    static DEFINE_SPINLOCK(sysctl_lock);
+    
+    switch (op->u.vtf.cmd.action)
+    {
+    case XEN_SYSCTL_vtf_action_list:
+        get_vtf_cpuinfo(&info); 
+        if ( copy_to_guest_offset(op->u.vtf.buffer,
+                                      0, &info, 1) )
+            {
+                ret = -EFAULT;
+                printk("Error while copying to guest offset!!\n");
+                break;
+            }
+        //printk("copy pased!!\n");
+        break;
+    
+    default:
+        break;
+    }
+    //printk("info.pml=%d, info.ept=%d\n",info.pml, info.ept);
+
+    spin_unlock(&sysctl_lock);
+    return ret;
+}
 
 long do_sysctl(XEN_GUEST_HANDLE_PARAM(xen_sysctl_t) u_sysctl)
 {
     long ret = 0;
-    int copyback = -1;
+    int copyback = -1, rc=0;
     struct xen_sysctl curop, *op = &curop;
     static DEFINE_SPINLOCK(sysctl_lock);
 
-    if ( copy_from_guest(op, u_sysctl, 1) )
-        return -EFAULT;
+    if ( copy_from_guest(op, u_sysctl, 1) ){
+        ret = -EFAULT;
+        printk("copy_from_guest  op->cmd = %d - op->u.vtf.check = %d\n",  op->cmd, op->u.vtf.check);
+        printk("copy_from_guest  ret = %ld\n",  ret);
+    }
 
-    if ( op->interface_version != XEN_SYSCTL_INTERFACE_VERSION )
+    if ( op->interface_version != XEN_SYSCTL_INTERFACE_VERSION ){
+        printk("interface_version  op->interface_version = %d\n",  op->interface_version);
         return -EACCES;
+    }
+
+    /*vtf vtf*/
+    switch ( op->cmd )
+    {
+        case XEN_SYSCTL_vtf:
+            ret = do_vtfctl(op);
+            rc=1;
+            printk("----case XEN_SYSCTL_vtf---\n");
+            break;
+
+        case XEN_SYSCTL_physinfo:
+            if(op->u.vtf.check) {
+                //printk("%d\n",op->u.vtf.check);
+                ret = get_physinfo(u_sysctl, op);
+                printk("----case XEN_SYSCTL_physinfo---\n");
+                rc = 1;
+            }
+            break;
+    
+        default:
+            break;
+    }
+
+    if( rc )
+        return ret;
+    /***/
 
     ret = xsm_sysctl(XSM_PRIV, op->cmd);
-    if ( ret )
+    if ( ret ){
+        printk("xsm_sysctl  op->cmd = %d - op->u.vtf.check = %d\n",  op->cmd, op->u.vtf.check);
+        printk("xsm_sysctl  xsm_ret = %ld\n",  ret);
         return ret;
+    }
 
     /*
      * Trylock here avoids deadlock with an existing sysctl critical section
@@ -250,27 +344,9 @@
 
     case XEN_SYSCTL_physinfo:
     {
-        struct xen_sysctl_physinfo *pi = &op->u.physinfo;
+    
+        ret = get_physinfo(u_sysctl, op);
 
-        memset(pi, 0, sizeof(*pi));
-        pi->threads_per_core =
-            cpumask_weight(per_cpu(cpu_sibling_mask, 0));
-        pi->cores_per_socket =
-            cpumask_weight(per_cpu(cpu_core_mask, 0)) / pi->threads_per_core;
-        pi->nr_cpus = num_online_cpus();
-        pi->nr_nodes = num_online_nodes();
-        pi->max_node_id = MAX_NUMNODES-1;
-        pi->max_cpu_id = nr_cpu_ids - 1;
-        pi->total_pages = total_pages;
-        /* Protected by lock */
-        get_outstanding_claims(&pi->free_pages, &pi->outstanding_pages);
-        pi->scrub_pages = 0;
-        pi->cpu_khz = cpu_khz;
-        pi->max_mfn = get_upper_mfn_bound();
-        arch_do_physinfo(pi);
-
-        if ( copy_to_guest(u_sysctl, op, 1) )
-            ret = -EFAULT;
     }
     break;
 
Seulement dans ./xen: .config
diff -aur ./xen/include/asm-x86/hvm/hvm.h ./xen/include/asm-x86/hvm/hvm.h
--- ./xen/include/asm-x86/hvm/hvm.h	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/include/asm-x86/hvm/hvm.h	2021-04-07 16:53:18.000000000 +0200
@@ -80,6 +80,8 @@
 #define HVM_EVENT_VECTOR_UNSET    (-1)
 #define HVM_EVENT_VECTOR_UPDATING (-2)
 
+#define HVM_SPP_WRITE_PROTECTED 2
+void register_gfn(gfn_t gfn);
 /*
  * The hardware virtual machine (HVM) interface abstracts away from the
  * x86/x86_64 CPU virtualization assist specifics. Currently this interface
Seulement dans ./xen/include/asm-x86/hvm/vmx: hashtab.h
diff -aur ./xen/include/asm-x86/hvm/vmx/vmcs.h ./xen/include/asm-x86/hvm/vmx/vmcs.h
--- ./xen/include/asm-x86/hvm/vmx/vmcs.h	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/include/asm-x86/hvm/vmx/vmcs.h	2020-11-13 20:14:48.000000000 +0100
@@ -21,6 +21,7 @@
 #include <asm/hvm/io.h>
 #include <irq_vectors.h>
 
+
 extern void vmcs_dump_vcpu(struct vcpu *v);
 extern void setup_vmcs_dump(void);
 extern int  vmx_cpu_up_prepare(unsigned int cpu);
@@ -57,6 +58,16 @@
     cpumask_var_t invalidate;
 };
 
+struct spp_data {
+   union {
+        struct {
+            u32 reserved:12;
+            u64 mfn:52;
+        };
+        u64 sppt_point;
+   };
+};
+
 #define _VMX_DOMAIN_PML_ENABLED    0
 #define VMX_DOMAIN_PML_ENABLED     (1ul << _VMX_DOMAIN_PML_ENABLED)
 struct vmx_domain {
@@ -248,6 +259,7 @@
 #define SECONDARY_EXEC_ENABLE_PML               0x00020000
 #define SECONDARY_EXEC_ENABLE_VIRT_EXCEPTIONS   0x00040000
 #define SECONDARY_EXEC_XSAVES                   0x00100000
+#define SECONDARY_EXEC_ENABLE_SPP               0x00800000
 #define SECONDARY_EXEC_TSC_SCALING              0x02000000
 extern u32 vmx_secondary_exec_control;
 
@@ -325,6 +337,8 @@
     (vmx_secondary_exec_control & SECONDARY_EXEC_XSAVES)
 #define cpu_has_vmx_tsc_scaling \
     (vmx_secondary_exec_control & SECONDARY_EXEC_TSC_SCALING)
+#define cpu_has_vmx_ept_spp \
+    (vmx_secondary_exec_control & SECONDARY_EXEC_ENABLE_SPP)
 
 #define VMCS_RID_TYPE_MASK              0x80000000
 
@@ -401,6 +415,7 @@
     VMWRITE_BITMAP                  = 0x00002028,
     VIRT_EXCEPTION_INFO             = 0x0000202a,
     XSS_EXIT_BITMAP                 = 0x0000202c,
+    SPPT_POINT                      = 0x00002030,
     TSC_MULTIPLIER                  = 0x00002032,
     GUEST_PHYSICAL_ADDRESS          = 0x00002400,
     VMCS_LINK_POINTER               = 0x00002800,
@@ -580,6 +595,104 @@
 void vmx_domain_flush_pml_buffers(struct domain *d);
 
 void vmx_domain_update_eptp(struct domain *d);
+void get_vtf_cpuinfo(struct xen_sysctl_vtf_getcpuinfo *info); 
+
+/*
+ *For the hashtable
+ */
+#ifndef _SS_HASHTAB_H_
+#define _SS_HASHTAB_H_
+
+#define HASHTAB_MAX_NODES    0xffffffff
+
+struct hashtab {
+    struct hashtab_node **htable;    /* hash table */
+    u32 size;            /* number of slots in hash table */
+    u32 nel;            /* number of elements in hash table */
+    u32 (*hash_value)(struct hashtab *h, const void *key);
+                    /* hash function */
+    int (*keycmp)(struct hashtab *h, const void *key1, const void *key2);
+                    /* key comparison function */
+};
+
+struct hashtab_info {
+    u32 slots_used;
+    u32 max_chain_len;
+};
+
+/*
+ * Creates a new hash table with the specified characteristics.
+ *
+ * Returns NULL if insufficent space is available or
+ * the new hash table otherwise.
+ */
+struct hashtab *hashtab_create(u32 (*hash_value)(struct hashtab *h,
+						 const void *key),
+            int (*keycmp)(struct hashtab *h, const void *key1,
+			  const void *key2), u32 size);
+
+/*
+ * Inserts the specified (key, datum) pair into the specified hash table.
+ *
+ * Returns -ENOMEM on memory allocation error,
+ * -EEXIST if there is already an entry with the same key,
+ * -EINVAL for general errors or
+ * 0 otherwise.
+ */
+int hashtab_insert(struct hashtab *h, void *k, void *d);
+
+/*
+ * Searches for the entry with the specified key in the hash table.
+ *
+ * Returns NULL if no entry has the specified key or
+ * the datum of the entry otherwise.
+ */
+void *hashtab_search(struct hashtab *h, const void *k);
+
+/*
+ * Destroys the specified hash table.
+ */
+void hashtab_destroy(struct hashtab *h);
+
+/*
+ * Applies the specified apply function to (key,datum,args)
+ * for each entry in the specified hash table.
+ *
+ * The order in which the function is applied to the entries
+ * is dependent upon the internal structure of the hash table.
+ *
+ * If apply returns a non-zero status, then hashtab_map will cease
+ * iterating through the hash table and will propagate the error
+ * return to its caller.
+ */
+int hashtab_map(struct hashtab *h,
+                        int (*apply)(void *k, void *d, void *args), void *args);
+
+/* Fill info with some hash table statistics */
+void hashtab_stat(struct hashtab *h, struct hashtab_info *info);
+
+struct data {
+    uint32_t idx;    
+    struct page_info *pg;
+};
+
+//struct data *new_data (uint32_t idx, struct page_info *pg);
+
+unsigned int vtf_hash(struct hashtab *h, const void *key);
+
+int vtf_cmp(struct hashtab *h, const void *key1, const void *key2);
+
+struct hashtab *vtf_hashmap_init(void);
+
+struct hashtab_node {
+    void *key;
+    void *datum;
+    struct hashtab_node *next;
+};
+
+#endif    /* _SS_HASHTAB_H */
+/*
+ */
 
 #endif /* ASM_X86_HVM_VMX_VMCS_H__ */
 
diff -aur ./xen/include/asm-x86/hvm/vmx/vmx.h ./xen/include/asm-x86/hvm/vmx/vmx.h
--- ./xen/include/asm-x86/hvm/vmx/vmx.h	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/include/asm-x86/hvm/vmx/vmx.h	2020-11-13 20:14:48.000000000 +0100
@@ -42,8 +42,9 @@
         snp         :   1,  /* bit 11 - VT-d snoop control in shared
                                EPT/VT-d usage */
         mfn         :   40, /* bits 51:12 - Machine physical frame number */
-        sa_p2mt     :   6,  /* bits 57:52 - Software available 2 */
-        access      :   4,  /* bits 61:58 - p2m_access_t */
+        sa_p2mt     :   5,  /* bits 56:52 - Software available 2 */
+        access      :   4,  /* bits 60:57 - p2m_access_t */
+        spp         :   1,  /* bits 61 - SPP flags */
         tm          :   1,  /* bit 62 - VT-d transient-mapping hint in
                                shared EPT/VT-d usage */
         suppress_ve :   1;  /* bit 63 - suppress #VE */
@@ -51,6 +52,16 @@
     u64 epte;
 } ept_entry_t;
 
+typedef union {
+    struct {
+        u64 present     :   1,  /* bit 0 - spp middle table is present */
+        reserved        :   11, /* bit 1:11 - reserved */
+        mfn             :   40, /* bit 12:51 - Machine physical frame number */
+        reserved2       :   12; /* bit 52:63 - reserved */
+    };
+    u64 spp;
+} spp_entry_t;
+
 typedef struct {
     /*use lxe[0] to save result */
     ept_entry_t lxe[5];
@@ -218,6 +229,7 @@
 #define EXIT_REASON_PML_FULL            62
 #define EXIT_REASON_XSAVES              63
 #define EXIT_REASON_XRSTORS             64
+#define EXIT_REASON_SPP                 66
 
 /*
  * Interruption-information format
@@ -621,6 +633,16 @@
     };
 } __transparent__ ept_qual_t;
 
+/* SPP induced vmexit qualifications definitions */
+typedef union spp_qual {
+    unsigned long raw;
+    struct {
+        unsigned long reserved   :11;
+        bool sppt_miss_type      :1;
+        unsigned long reserved2  :52;
+    };
+} __transparent__ spp_qual_t;
+
 #define EPT_L4_PAGETABLE_SHIFT      39
 #define EPT_PAGETABLE_ENTRIES       512
 
diff -aur ./xen/include/asm-x86/p2m.h ./xen/include/asm-x86/p2m.h
--- ./xen/include/asm-x86/p2m.h	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/include/asm-x86/p2m.h	2021-04-29 16:09:50.000000000 +0200
@@ -34,6 +34,10 @@
 
 extern bool_t opt_hap_1gb, opt_hap_2mb;
 
+#define ACCESS_GRANTED 1
+#define ACCES_DENIED 0
+
+
 /*
  * The upper levels of the p2m pagetable always contain full rights; all 
  * variation in the access control bits is made in the level-1 PTEs.
@@ -193,6 +197,8 @@
     /* Shadow translated domain: p2m mapping */
     pagetable_t        phys_table;
 
+    pagetable_t        spp_phys_table;
+
     /* Same as domain_dirty_cpumask but limited to
      * this p2m and those physical cpus whose vcpu's are in
      * guestmode.
@@ -265,6 +271,25 @@
                                           unsigned long gfn, l1_pgentry_t *p,
                                           l1_pgentry_t new, unsigned int level);
     long               (*audit_p2m)(struct p2m_domain *p2m);
+    int                (*update_ept_spp_wp)(struct p2m_domain *p2m,
+                                 unsigned long gfn, bool spp, bool w, bool change);
+    int                (*spp_set_entry)(struct p2m_domain *p2m,
+                                unsigned long gfn,
+                                u64 access);
+
+    int              (*get_entry_spp)(struct p2m_domain *p2m,
+                                    gfn_t gfn,
+                                    p2m_type_t *p2mt,
+                                    p2m_access_t *p2ma,
+                                    p2m_query_t q,
+                                    unsigned int *page_order,
+                                    bool_t *sve);
+/* mem access controler */
+    int                (* spp_release)(struct p2m_domain *p2m,
+                                unsigned long gfn);
+    int                (*spp_get_entry)(struct p2m_domain *p2m,
+                                unsigned long gfn, uint64_t* result);
+    int                  (*spp_access_check)(__u64 bitmap, paddr_t gpa);
 
     /*
      * P2M updates may require TLBs to be flushed (invalidated).
@@ -340,6 +365,9 @@
         struct ept_data ept;
         /* NPT-equivalent structure could be added here. */
     };
+    union {
+        struct spp_data spptp;
+    };
 
      struct {
          spinlock_t lock;
@@ -392,7 +420,8 @@
     return p2m->p2m_class == p2m_alternate;
 }
 
-#define p2m_get_pagetable(p2m)  ((p2m)->phys_table)
+#define p2m_get_pagetable(p2m)      ((p2m)->phys_table)
+#define p2m_get_spp_pagetable(p2m)  ((p2m)->spp_phys_table)
 
 /*
  * Ensure any deferred p2m TLB flush has been completed on all VCPUs.
diff -aur ./xen/include/asm-x86/paging.h ./xen/include/asm-x86/paging.h
--- ./xen/include/asm-x86/paging.h	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/include/asm-x86/paging.h	2020-11-13 20:14:48.000000000 +0100
@@ -171,6 +171,7 @@
  * TODO2: Abstract out the radix-tree mechanics?
  */
 #define LOGDIRTY_NODE_ENTRIES (1 << PAGETABLE_ORDER)
+#define LOGDIRTY_LEAF_LONG_ENTRIES (1 << PAGETABLE_ORDER_LONG)
 #define L1_LOGDIRTY_IDX(pfn) (pfn_x(pfn) & ((1 << (PAGE_SHIFT + 3)) - 1))
 #define L2_LOGDIRTY_IDX(pfn) ((pfn_x(pfn) >> (PAGE_SHIFT + 3)) & \
                               (LOGDIRTY_NODE_ENTRIES-1))
diff -aur ./xen/include/asm-x86/shadow.h ./xen/include/asm-x86/shadow.h
--- ./xen/include/asm-x86/shadow.h	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/include/asm-x86/shadow.h	2020-11-13 20:14:48.000000000 +0100
@@ -54,6 +54,28 @@
  * paging_vcpu_init() in paging.c */
 void shadow_vcpu_init(struct vcpu *v);
 
+//VMWare implementation -- Added from 4.2.0
+/* Remove all mappings of the guest page from the shadows. 
+ * This is called from common code.  It does not flush TLBs. */
+int sh_remove_all_mappings(struct domain *d, mfn_t target_mfn, gfn_t gfn);
+static inline void 
+shadow_drop_references(struct domain *d, struct page_info *p)
+{
+    if ( unlikely(shadow_mode_enabled(d)) )
+        /* See the comment about locking in sh_remove_all_mappings */
+        sh_remove_all_mappings(d, _mfn(page_to_mfn(p)),0);
+}
+
+int sh_remove_all_mappings_vmware(struct vcpu *v, mfn_t target_mfn);
+static inline void 
+shadow_drop_references_vmware(struct domain *d, struct page_info *p)
+{
+    if ( unlikely(shadow_mode_enabled(d)) )
+        /* See the comment about locking in sh_remove_all_mappings */
+        sh_remove_all_mappings_vmware(d->vcpu[0], _mfn(page_to_mfn(p)));
+}
+//
+
 #ifdef CONFIG_SHADOW_PAGING
 
 /* Enable an arbitrary shadow mode.  Call once at domain creation. */
diff -aur ./xen/include/asm-x86/x86_64/page.h ./xen/include/asm-x86/x86_64/page.h
--- ./xen/include/asm-x86/x86_64/page.h	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/include/asm-x86/x86_64/page.h	2020-11-13 20:14:48.000000000 +0100
@@ -11,6 +11,7 @@
 #define ROOT_PAGETABLE_SHIFT    L4_PAGETABLE_SHIFT
 
 #define PAGETABLE_ORDER         9
+#define PAGETABLE_ORDER_LONG    6
 #define L1_PAGETABLE_ENTRIES    (1<<PAGETABLE_ORDER)
 #define L2_PAGETABLE_ENTRIES    (1<<PAGETABLE_ORDER)
 #define L3_PAGETABLE_ENTRIES    (1<<PAGETABLE_ORDER)
diff -aur ./xen/include/public/domctl.h ./xen/include/public/domctl.h
--- ./xen/include/public/domctl.h	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/include/public/domctl.h	2020-11-13 20:14:48.000000000 +0100
@@ -1105,6 +1105,36 @@
                                  */
 };
 
+typedef enum { 
+    False = 0,
+    True,
+} boolean_t;
+
+/*struct  xen_domctl_vtf_action { 
+    uint32_t action;
+    #define XEN_DOMCTL_vtf_action_enable     1
+    #define XEN_DOMCTL_vtf_action_disable    2
+    uint32_t pid;
+};
+typedef struct xen_domctl_vtf_action xen_domctl_vtf_action_t;
+DEFINE_XEN_GUEST_HANDLE(xen_domctl_vtf_action_t);
+
+struct xen_domctl_vtf_pids {
+    uint32_t *list;
+};
+typedef struct xen_domctl_vtf_pids xen_domctl_vtf_pids_t;*/
+
+struct xen_domctl_vtf {
+    //boolean_t check;
+    uint32_t hw;
+    #define XEN_DOMCTL_vtf_hw_PML        1
+    #define XEN_DOMCTL_vtf_hw_EPT        2  
+    uint32_t pids[25];
+   // xen_domctl_vtf_action_t cmd;  
+};
+typedef struct xen_domctl_vtf xen_domctl_vtf_t;
+DEFINE_XEN_GUEST_HANDLE(xen_domctl_vtf_t);
+
 struct xen_domctl {
     uint32_t cmd;
 #define XEN_DOMCTL_createdomain                   1
@@ -1184,6 +1214,7 @@
 #define XEN_DOMCTL_soft_reset                    79
 #define XEN_DOMCTL_set_gnttab_limits             80
 #define XEN_DOMCTL_vuart_op                      81
+#define XEN_DOMCTL_vtf                           82
 #define XEN_DOMCTL_gdbsx_guestmemio            1000
 #define XEN_DOMCTL_gdbsx_pausevcpu             1001
 #define XEN_DOMCTL_gdbsx_unpausevcpu           1002
@@ -1248,6 +1279,7 @@
         struct xen_domctl_psr_cat_op        psr_cat_op;
         struct xen_domctl_set_gnttab_limits set_gnttab_limits;
         struct xen_domctl_vuart_op          vuart_op;
+        struct xen_domctl_vtf               vtf;
         uint8_t                             pad[128];
     } u;
 };
diff -aur ./xen/include/public/hvm/hvm_op.h ./xen/include/public/hvm/hvm_op.h
--- ./xen/include/public/hvm/hvm_op.h	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/include/public/hvm/hvm_op.h	2021-04-23 14:08:11.000000000 +0200
@@ -170,7 +170,7 @@
  * the pointer pair gets read atomically:
  */
 #define HVM_IOREQSRV_BUFIOREQ_ATOMIC 2
-
+ 
 #endif /* defined(__XEN__) || defined(__XEN_TOOLS__) */
 
 #if defined(__i386__) || defined(__x86_64__)
@@ -197,6 +197,9 @@
 /* HVMOP_altp2m: perform altp2m state operations */
 #define HVMOP_altp2m 25
 
+/*vtf - HVMOP_vtf_context_switch*/
+/*#define HVMOP_vtf_context_switch 26*/
+
 #define HVMOP_ALTP2M_INTERFACE_VERSION 0x00000001
 
 struct xen_hvm_altp2m_domain_state {
@@ -205,6 +208,18 @@
 };
 typedef struct xen_hvm_altp2m_domain_state xen_hvm_altp2m_domain_state_t;
 DEFINE_XEN_GUEST_HANDLE(xen_hvm_altp2m_domain_state_t);
+#define HVMOP_set_subpage          26
+struct xen_hvm_subpage {
+    domid_t  domid;
+    uint64_t dest_gfn;
+    uint64_t src_gfn;
+    uint32_t subpage;
+    uint32_t op;
+};
+typedef struct xen_hvm_subpage xen_hvm_subpage_t;
+DEFINE_XEN_GUEST_HANDLE(xen_hvm_subpage_t);
+
+#define HVMOP_release_subpage 27
 
 struct xen_hvm_altp2m_vcpu_enable_notify {
     uint32_t vcpu_id;
diff -aur ./xen/include/public/memory.h ./xen/include/public/memory.h
--- ./xen/include/public/memory.h	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/include/public/memory.h	2020-11-13 20:14:48.000000000 +0100
@@ -228,7 +228,7 @@
                                       Inner/Outer Write-Back Cacheable
                                       memory attribute. */
 /* ` } */
-
+#define XENMAPSPACE_pml_shared_info 30
 /*
  * Sets the GPFN at which a particular page appears in the specified guest's
  * pseudophysical address space.
diff -aur ./xen/include/public/sysctl.h ./xen/include/public/sysctl.h
--- ./xen/include/public/sysctl.h	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/include/public/sysctl.h	2020-11-13 20:14:48.000000000 +0100
@@ -65,7 +65,7 @@
     /* IN variables */
 #define XEN_SYSCTL_TBUFOP_get_info     0
 #define XEN_SYSCTL_TBUFOP_set_cpu_mask 1
-#define XEN_SYSCTL_TBUFOP_set_evt_mask 2
+#define XEN_SYSCTL_TBUFOP_set_evt_mask 2 
 #define XEN_SYSCTL_TBUFOP_set_size     3
 #define XEN_SYSCTL_TBUFOP_enable       4
 #define XEN_SYSCTL_TBUFOP_disable      5
@@ -78,6 +78,11 @@
     uint32_t size;  /* Also an IN variable! */
 };
 
+/*typedef enum {
+    False = 0,
+    True,
+} boolean_t;*/
+
 /*
  * Get physical information about the host machine
  */
@@ -89,6 +94,7 @@
 #define _XEN_SYSCTL_PHYSCAP_hvm_directio 1
 #define XEN_SYSCTL_PHYSCAP_hvm_directio  (1u<<_XEN_SYSCTL_PHYSCAP_hvm_directio)
 struct xen_sysctl_physinfo {
+    boolean_t vtf_cmd;
     uint32_t threads_per_core;
     uint32_t cores_per_socket;
     uint32_t nr_cpus;     /* # CPUs currently online */
@@ -1044,6 +1050,30 @@
     uint16_t size;                          /* IN: size of parameters. */
     uint16_t pad[3];                        /* IN: MUST be zero. */
 };
+ 
+struct xen_sysctl_vtf_getcpuinfo {
+    uint32_t ept:1;
+    uint32_t pml:1;
+};
+typedef struct xen_sysctl_vtf_getcpuinfo xen_sysctl_vtf_getcpuinfo_t; 
+DEFINE_XEN_GUEST_HANDLE(xen_sysctl_vtf_getcpuinfo_t);
+
+struct xen_sysctl_vtf_action { 
+    uint32_t action;
+    #define XEN_SYSCTL_vtf_action_list       1
+    #define XEN_SYSCTL_vtf_action_help       2
+    uint32_t pid;
+};
+typedef struct xen_sysctl_vtf_action xen_sysctl_vtf_action_t;
+DEFINE_XEN_GUEST_HANDLE(xen_sysctl_vtf_action_t);
+
+struct xen_sysctl_vtf {
+    boolean_t check; 
+    xen_sysctl_vtf_action_t cmd;  
+    XEN_GUEST_HANDLE_64(xen_sysctl_vtf_getcpuinfo_t) buffer;
+};
+//typedef struct xen_sysctl_vtf xen_sysctl_vtf_t;
+//DEFINE_XEN_GUEST_HANDLE(xen_sysctl_vtf_t);
 
 struct xen_sysctl {
     uint32_t cmd;
@@ -1074,6 +1104,7 @@
 #define XEN_SYSCTL_get_cpu_featureset            26
 #define XEN_SYSCTL_livepatch_op                  27
 #define XEN_SYSCTL_set_parameter                 28
+#define XEN_SYSCTL_vtf                           29
     uint32_t interface_version; /* XEN_SYSCTL_INTERFACE_VERSION */
     union {
         struct xen_sysctl_readconsole       readconsole;
@@ -1103,6 +1134,7 @@
         struct xen_sysctl_cpu_featureset    cpu_featureset;
         struct xen_sysctl_livepatch_op      livepatch;
         struct xen_sysctl_set_parameter     set_parameter;
+        struct xen_sysctl_vtf               vtf;
         uint8_t                             pad[128];
     } u;
 };
diff -aur ./xen/include/public/vcpu.h ./xen/include/public/vcpu.h
--- ./xen/include/public/vcpu.h	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/include/public/vcpu.h	2020-11-13 20:14:48.000000000 +0100
@@ -235,6 +235,14 @@
 typedef struct vcpu_register_time_memory_area vcpu_register_time_memory_area_t;
 DEFINE_XEN_GUEST_HANDLE(vcpu_register_time_memory_area_t);
 
+#define VCPUOP_vtf_enable_pml       14
+#define VCPUOP_vtf_disable_pml      15
+struct vcpu_vtf_pml {
+	uint32_t pid;
+};
+typedef struct vcpu_vtf_pml vcpu_vtf_pml_t;
+DEFINE_XEN_GUEST_HANDLE(vcpu_vtf_pml_t);
+
 #endif /* __XEN_PUBLIC_VCPU_H__ */
 
 /*
diff -aur ./xen/include/public/version.h ./xen/include/public/version.h
--- ./xen/include/public/version.h	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/include/public/version.h	2020-11-13 20:14:48.000000000 +0100
@@ -77,6 +77,10 @@
 
 /* arg == NULL; returns host memory page size. */
 #define XENVER_pagesize 7
+struct xen_vtf_signal {
+    unsigned int pid_signal; 
+};
+typedef struct xen_vtf_signal xen_vtf_signal_t;
 
 /* arg == xen_domain_handle_t.
  *
diff -aur ./xen/include/public/xen.h ./xen/include/public/xen.h
--- ./xen/include/public/xen.h	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/include/public/xen.h	2020-11-13 20:14:48.000000000 +0100
@@ -181,6 +181,7 @@
 #define VIRQ_XC_RESERVED 11 /* G. Reserved for XenClient                     */
 #define VIRQ_ENOMEM     12 /* G. (DOM0) Low on heap memory       */
 #define VIRQ_XENPMU     13 /* V.  PMC interrupt                              */
+#define VIRQ_VTF_PML	14
 
 /* Architecture-specific VIRQ definitions. */
 #define VIRQ_ARCH_0    16
@@ -692,6 +693,13 @@
 typedef struct vcpu_info vcpu_info_t;
 #endif
 
+struct vtf_info {
+	uint32_t pml_page_order;
+	uint32_t nr_pml_entries;
+	unsigned long *pml;
+};
+typedef struct vtf_info vtf_info_t;
+
 /*
  * `incontents 200 startofday_shared Start-of-day shared data structure
  * Xen/kernel shared data -- pointer provided in start_info.
@@ -753,7 +761,7 @@
 #endif
 
     struct arch_shared_info arch;
-
+    uint32_t vcpu_pml_info;
 };
 #ifndef __XEN__
 typedef struct shared_info shared_info_t;
diff -aur ./xen/include/xen/mem_access.h ./xen/include/xen/mem_access.h
--- ./xen/include/xen/mem_access.h	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/include/xen/mem_access.h	2021-04-07 16:59:10.000000000 +0200
@@ -54,10 +54,19 @@
     p2m_access_n2rwx = 9, /* Special: page goes from N to RWX on access, *
                            * generates an event but does not pause the
                            * vcpu */
+    p2m_access_spp = 0x0d,
 
     /* NOTE: Assumed to be only 4 bits right now on x86. */
 } p2m_access_t;
 
+int p2m_copy_subpage(struct domain *d, gfn_t dest, gfn_t src);
+
+
+int p2m_unset_subpage(struct domain *d, gfn_t gfn, uint32_t access_map);
+ 
+
+int p2m_reset_subpage(struct domain *d, gfn_t gfn);
+int p2m_release_subpage(struct domain *d, gfn_t gfn);
 /*
  * Set access type for a region of gfns.
  * If gfn == INVALID_GFN, sets the default access type.
@@ -78,6 +87,8 @@
  */
 int p2m_get_mem_access(struct domain *d, gfn_t gfn, xenmem_access_t *access);
 
+int p2m_set_subpage(struct domain *d, gfn_t gfn, uint32_t access_map);
+
 #ifdef CONFIG_HAS_MEM_ACCESS
 int mem_access_memop(unsigned long cmd,
                      XEN_GUEST_HANDLE_PARAM(xen_mem_access_op_t) arg);
diff -aur ./xen/include/xen/sched.h ./xen/include/xen/sched.h
--- ./xen/include/xen/sched.h	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/include/xen/sched.h	2020-11-13 20:14:48.000000000 +0100
@@ -146,6 +146,9 @@
     int              processor;
 
     vcpu_info_t     *vcpu_info;
+    
+    /*spinlock_t vtf_pml_lock;
+    vtf_info_t vtf_info;*/
 
     struct domain   *domain;
 
@@ -302,15 +305,35 @@
     guest_type_pv, guest_type_hvm
 };
 
+//VMWare implementation
+/*working set struct*/
+struct working_set
+{
+   unsigned int  inv_pages[100];//100-vmware default, 131072-to work on every pages for 512Mo
+   unsigned int  test_inv[100];
+   //Here we invalidate almost all memory pages
+   //unsigned int  inv_pages[300000];//100-vmware default, 131072-to work on every pages for 512Mo
+   //unsigned int  test_inv[300000];
+   unsigned int  tot_access;
+   struct timer *timer;
+};
+//
+
 struct domain
 {
     domid_t          domain_id;
 
     unsigned int     max_vcpus;
+    unsigned int     vtf_pids[25];
+    bool     is_vtf;
     struct vcpu    **vcpu;
 
     shared_info_t   *shared_info;     /* shared data area */
 
+    spinlock_t vtf_pml_lock;
+    vtf_info_t vtf_info;
+    atomic_t vtf_pml_flag;
+
     spinlock_t       domain_lock;
 
     spinlock_t       page_alloc_lock; /* protects all the following fields  */
@@ -322,7 +345,11 @@
     unsigned int     max_pages;       /* maximum value for tot_pages        */
     atomic_t         shr_pages;       /* number of shared pages             */
     atomic_t         paged_pages;     /* number of paged-out pages          */
-
+     
+    //VMWare implementation
+    /*working set*/
+    struct working_set *ws;
+    
     /* Scheduling. */
     void            *sched_priv;    /* scheduler-specific data */
     struct cpupool  *cpupool;
diff -aur ./xen/Rules.mk ./xen/Rules.mk
--- ./xen/Rules.mk	2017-12-13 12:37:59.000000000 +0100
+++ ./xen/Rules.mk	2021-04-07 17:03:17.000000000 +0200
@@ -47,7 +47,7 @@
 endif
 
 CFLAGS += -nostdinc -fno-builtin -fno-common
-CFLAGS += -Werror -Wredundant-decls -Wno-pointer-arith
+CFLAGS +=  -Wredundant-decls -Wno-pointer-arith
 CFLAGS += -pipe -g -D__XEN__ -include $(BASEDIR)/include/xen/config.h
 CFLAGS += '-D__OBJECT_FILE__="$@"'
 
Seulement dans ./xen: ..xen.efi.0r.o.d2
Seulement dans ./xen: ..xen.efi.0s.o.d2
Seulement dans ./xen: ..xen.efi.1r.o.d2
Seulement dans ./xen: ..xen.efi.1s.o.d2
Seulement dans ./xen: ..xen-syms.0.o.d2
Seulement dans ./xen: ..xen-syms.1.o.d2
Seulement dans ./: xen-pml.patch
